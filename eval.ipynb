{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:21:11.973731Z",
     "start_time": "2022-04-26T10:21:11.034274Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:28:04.871466Z",
     "start_time": "2022-04-26T10:22:47.434579Z"
    }
   },
   "outputs": [],
   "source": [
    "spxEM = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300_em.txt'\n",
    "spxEM_model = KeyedVectors.load_word2vec_format(spxEM, binary=False)\n",
    "w2v = '/home/manni/embs/en_wiki_w2v_mc100_epoch5_300.txt'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v, binary=False)\n",
    "spx = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300.txt'\n",
    "spx_model = KeyedVectors.load_word2vec_format(spx, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:28:04.878192Z",
     "start_time": "2022-04-26T10:28:04.874230Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [w2v_model,spx_model,spxEM_model]\n",
    "model_names = ['Word2vec','EWEM-MIX','EWEM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:21:06.046153Z",
     "start_time": "2022-04-26T10:21:06.046141Z"
    }
   },
   "outputs": [],
   "source": [
    "spxEM = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300_em_w1.txt'\n",
    "spxEM_model = KeyedVectors.load_word2vec_format(spxEM, binary=False)\n",
    "w2v = '/home/manni/embs/en_wiki_w2v_mc100_epoch5_300_w1.txt'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T06:50:25.871025Z",
     "start_time": "2022-04-26T06:50:25.870996Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [w2v_model,spxEM_model]\n",
    "model_names = ['Word2vec','EWEM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:28:04.897095Z",
     "start_time": "2022-04-26T10:28:04.879848Z"
    }
   },
   "outputs": [],
   "source": [
    "scws_file = '/home/manni/data/wordsim/SCWS/ratings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:28:04.933811Z",
     "start_time": "2022-04-26T10:28:04.899828Z"
    }
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "with open(scws_file) as fin:\n",
    "    lines = fin.readlines()\n",
    "    for l in lines:\n",
    "        l = l.lower().split('\\t')\n",
    "        w1 = l[1]\n",
    "        w2 = l[3]\n",
    "        c1 = l[5]\n",
    "        c2 = l[6]\n",
    "        score = float(l[7])\n",
    "        data.append([w1,w2,c1,c2,score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:28:04.944892Z",
     "start_time": "2022-04-26T10:28:04.935439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['israel',\n",
       " 'israeli',\n",
       " 'pathogens are attached to silver and gold nanowires . in the netherlands , the company tno has designed bioaerosol single particle recognition equipment ( biosparq ) . this system would be implemented into the national response plan for bioweapons attacks in the netherlands . researchers at ben gurion university in <b> israel </b> are developing a different device called the biopen , essentially a \" lab-in-a-pen \" , which can detect known biological agents in under 20 minutes using an adaptation of the elisa , a similar widely employed immunological technique , that in this case incorporates fiber optics . list of',\n",
       " '1995 , israeli folk singer miri aloni sang the israeli pop song \" shir lashalom \" ( song for peace ) . this song , originally written in 1969 and performed extensively at the time by an israeli military performing group , has become one of the anthems of the <b> israeli </b> peace camp . during the arab uprising known as the first intifada , israeli singer si heyman sang \" yorim vebokhim \" ( shoot and weep ) , written by shalom hanoch , to protest israeli policy in the territories . this song was banned from the radio for',\n",
       " 8.1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T11:34:08.208988Z",
     "start_time": "2022-04-26T11:34:08.180604Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_sent(sent):\n",
    "    '''\n",
    "    parameters:\n",
    "        sent: str\n",
    "    returns:\n",
    "        tokens: list(str)     \n",
    "    '''\n",
    "    return [word for word in sent.split() if word not in stop_words]\n",
    "\n",
    "def sent_words(sent):\n",
    "    '''\n",
    "    parameters:\n",
    "        sent: str\n",
    "    returns:\n",
    "        tokens: list(str) \n",
    "    '''\n",
    "    sent = re.sub(r'[^\\w\\s]', '', sent)\n",
    "    left = sent.split('<b>')[0]\n",
    "    right = sent.split('</b>')[-1]\n",
    "    sentA = clean_sent(left)[-10:]\n",
    "    sentB = clean_sent(right)[:10]\n",
    "    return sentA+sentB\n",
    "\n",
    "def reducer(wrd,lst,model):\n",
    "    out = set()\n",
    "    for word in lst:\n",
    "        top = [tup[0] for tup in model.most_similar(word,topn=100)]\n",
    "        out.update(set(top)&set(lst))\n",
    "    out.add(wrd)\n",
    "    if wrd+'#E' in model.vocab:\n",
    "        out.add(wrd+'#E')\n",
    "    return out\n",
    "\n",
    "def avgsim(w1,w2,c1,c2,score,model,reduce=False,verbose=False):\n",
    "    '''\n",
    "    Computes average similarity score.\n",
    "\n",
    "    parameters:\n",
    "        w1 : str\n",
    "        w2 : str\n",
    "        c1 : str\n",
    "        c2 : str\n",
    "        model : gensim.keyedvectors\n",
    "    returns:\n",
    "        score : float\n",
    "    '''\n",
    "    if w1 not in model.vocab or w2 not in model.vocab:\n",
    "        return None\n",
    "    a = [w1] + sent_words(c1)\n",
    "    _a = [word+'#E' for word in a] \n",
    "    a+=_a\n",
    "    b = [w2] + sent_words(c2)\n",
    "    _b = [word+'#E' for word in b] \n",
    "    b+=_b\n",
    "    a = [word for word in a if word in model.vocab]\n",
    "    b = [word for word in b if word in model.vocab]\n",
    "    if reduce:\n",
    "        a = reducer(w1,a,model)\n",
    "        b = reducer(w2,b,model)    \n",
    "    if verbose:\n",
    "        print(a)\n",
    "        print(b)\n",
    "    div = len(a)*len(b)\n",
    "    sims = 0\n",
    "    for i in a:\n",
    "        for j in b:\n",
    "            sim = model.similarity(i,j)\n",
    "            if verbose:\n",
    "                print(i,j,sim)\n",
    "            sims+= sim\n",
    "    return (sims/div,score)\n",
    "\n",
    "def _avgvec(lst,model):\n",
    "    vec = np.zeros(model.vector_size)\n",
    "    for word in lst:\n",
    "        if word in model:\n",
    "            vec = np.add(vec,model.get_vector(word))\n",
    "    return vec  \n",
    "    \n",
    "def avgvec(w1,w2,c1,c2,score,model,reduce=False,verbose=False):\n",
    "    if w1 not in model.vocab or w2 not in model.vocab:\n",
    "        return None\n",
    "    a = [w1] + sent_words(c1)\n",
    "    _a = [word+'#E' for word in a] \n",
    "    a+=_a\n",
    "    b = [w2] + sent_words(c2)\n",
    "    _b = [word+'#E' for word in b] \n",
    "    b+=_b\n",
    "    a = [word for word in a if word in model.vocab]\n",
    "    b = [word for word in b if word in model.vocab]\n",
    "    if reduce:\n",
    "        a = reducer(w1,a,model)\n",
    "        b = reducer(w2,b,model) \n",
    "    if verbose:\n",
    "        print(a)\n",
    "        print(b) \n",
    "    v1 = _avgvec(a,model)\n",
    "    v2 = _avgvec(b,model)\n",
    "    return (model.cosine_similarities(v1,[v2])[0],score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:43:47.329164Z",
     "start_time": "2022-04-26T10:43:47.315676Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_corr(model,method='asim',reduce=False):\n",
    "    sims = list()\n",
    "    scores = list()\n",
    "    for dat in tqdm(data,position=0):\n",
    "        if method == 'asim':\n",
    "            sim = avgsim(dat[0],dat[1],dat[2],dat[3],dat[4],model,reduce=reduce)\n",
    "        if method == 'avg':\n",
    "            sim = avgvec(dat[0],dat[1],dat[2],dat[3],dat[4],model,reduce=reduce)\n",
    "        if sim:\n",
    "            sims.append(sim[0])\n",
    "            scores.append(sim[1])\n",
    "    corr, _ = pearsonr(sims, scores)\n",
    "    print('%.2f &' % (corr*100),end=' ')\n",
    "    corr, _ = spearmanr(sims, scores)\n",
    "    print('%.2f' % (corr*100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:43:48.291949Z",
     "start_time": "2022-04-26T10:43:47.889954Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [00:00<00:00, 8461.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.69 & 61.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [00:00<00:00, 29723.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.45 & 65.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [00:00<00:00, 26045.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.92 & 63.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_corr(spxEM_model)\n",
    "get_corr(spx_model)\n",
    "get_corr(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:43:48.805736Z",
     "start_time": "2022-04-26T10:43:48.369657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [00:00<00:00, 12052.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.88 & 61.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [00:00<00:00, 16184.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.45 & 65.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [00:00<00:00, 16474.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.92 & 63.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_corr(spxEM_model,method='avg')\n",
    "get_corr(spx_model,method='avg')\n",
    "get_corr(w2v_model,method='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:06:16.604452Z",
     "start_time": "2022-04-26T10:06:16.589679Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def get_corr_parallel(model,method='asim',reduce=False):\n",
    "    if __name__==\"__main__\":\n",
    "        pool = Pool(processes=40)\n",
    "        sims = list()\n",
    "        scores = list()\n",
    "        for dat in tqdm(data,position=0):\n",
    "            if method == 'asim':\n",
    "                sim = pool.apply_async(func=avgsim, args=(dat[0],dat[1],dat[2],dat[3],dat[4],model,reduce)) \n",
    "            if method == 'avg':\n",
    "                sim = pool.apply_async(func=avgvec, args=(dat[0],dat[1],dat[2],dat[3],dat[4],model,reduce)) \n",
    "            sim = sim.get()\n",
    "            if sim:\n",
    "                sims.append(sim[0])\n",
    "                scores.append(sim[1])\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        corr, _ = pearsonr(sims, scores)\n",
    "        print('Pearsons correlation: %.2f' % (corr*100))\n",
    "        corr, _ = spearmanr(sims, scores)\n",
    "        print('Spearmans correlation: %.2f' % (corr*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T10:07:14.087876Z",
     "start_time": "2022-04-26T10:06:17.633469Z"
    }
   },
   "outputs": [],
   "source": [
    "get_corr_parallel(spxEM_model,reduce=True)\n",
    "get_corr_parallel(spx_model,reduce=True)\n",
    "get_corr_parallel(w2v_model,reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T12:50:26.071467Z",
     "start_time": "2022-04-26T11:34:16.000631Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [41:46<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.67 & 30.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                     | 1114/2003 [10:01<07:55,  1.87it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_corr(spxEM_model,reduce=True)\n",
    "get_corr(spx_model,reduce=True)\n",
    "get_corr(w2v_model,reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T14:05:15.215153Z",
     "start_time": "2022-04-26T12:50:26.075990Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2003/2003 [40:47<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.83 & 29.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████████████████████████████████████████▋                                                                             | 1016/2003 [08:53<08:06,  2.03it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_corr(spxEM_model,method='avg',reduce=True)\n",
    "get_corr(spx_model,method='avg',reduce=True)\n",
    "get_corr(w2v_model,method='avg',reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:16.448562Z",
     "start_time": "2022-04-26T07:02:16.440159Z"
    }
   },
   "outputs": [],
   "source": [
    "print(w2v_model.similarity('brazil','nut'))\n",
    "print(spx_model.similarity('brazil','nut'))\n",
    "print(spxEM_model.similarity('brazil','nut'))\n",
    "print(spxEM_model.similarity('brazil#E','nut#E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:17.568594Z",
     "start_time": "2022-04-26T07:02:17.559976Z"
    }
   },
   "outputs": [],
   "source": [
    "print(spx_model.similarity('new','york'))\n",
    "print(w2v_model.similarity('new','york'))\n",
    "print(spxEM_model.similarity('new','york'))\n",
    "print(spxEM_model.similarity('new#E','york#E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:27.519284Z",
     "start_time": "2022-04-26T07:02:27.469994Z"
    }
   },
   "outputs": [],
   "source": [
    "avgsim(data[0][0],data[0][1],data[0][2],data[0][3],w2v_model,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:32:19.076265Z",
     "start_time": "2022-04-26T07:32:19.070050Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ['brazil', 'bahia', 'instance', 'never', 'gap', 'income', 'blacks', 'nonwhites', 'relatively', 'brazil#E', 'bahia#E', 'instance#E', 'never#E', 'gap#E', 'income#E', 'blacks#E', 'relatively#E']\n",
    "y = ['nut', 'player', 'turns', 'change', 'string', 'tension', 'neck', 'bridge', 'pickups', 'features', 'found', 'nut#E', 'player#E', 'turns#E', 'change#E', 'string#E', 'tension#E', 'neck#E', 'bridge#E', 'pickups#E', 'features#E', 'found#E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:41:22.883729Z",
     "start_time": "2022-04-26T07:41:22.875463Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ['brazil', 'population', 'black', 'politicians', 'city', 'salvador', 'bahia', 'instance', 'never', 'gap', 'income', 'blacks', 'nonwhites', 'relatively', 'small', 'compared', 'large', 'gap', 'whites', 'brazil#E', 'population#E', 'black#E', 'politicians#E', 'city#E', 'salvador#E', 'bahia#E', 'instance#E', 'never#E', 'gap#E', 'income#E', 'blacks#E', 'relatively#E', 'small#E', 'compared#E', 'large#E', 'gap#E', 'whites#E']\n",
    "y = ['nut', 'machine', 'heads', 'worm', 'gears', 'player', 'turns', 'change', 'string', 'tension', 'neck', 'bridge', 'pickups', 'features', 'found', 'almost', 'every', 'guitar', 'photo', 'shows', 'nut#E', 'machine#E', 'heads#E', 'worm#E', 'gears#E', 'player#E', 'turns#E', 'change#E', 'string#E', 'tension#E', 'neck#E', 'bridge#E', 'pickups#E', 'features#E', 'found#E', 'almost#E', 'every#E', 'guitar#E', 'photo#E', 'shows#E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:32:50.036474Z",
     "start_time": "2022-04-26T07:32:50.029886Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ['israel', 'case', 'incorporates', 'fiber', 'optics', 'list', 'pathogens', 'attached', 'silver', 'gold', 'nanowires', 'israel#E', 'case#E', 'fiber#E', 'optics#E', 'list#E', 'pathogens#E', 'attached#E', 'silver#E', 'gold#E']\n",
    "y = ['israeli', 'policy', 'territories', 'song', 'banned', 'radio', 'israeli', 'folk', 'singer', 'miri', 'israeli#E', 'policy#E', 'territories#E', 'song#E', 'banned#E', 'radio#E', 'israeli#E', 'folk#E', 'singer#E', 'miri#E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:43:42.944207Z",
     "start_time": "2022-04-26T07:43:42.935182Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ['israel', 'similar', 'widely', 'employed', 'immunological', 'technique', 'case', 'incorporates', 'fiber', 'optics', 'list', 'pathogens', 'attached', 'silver', 'gold', 'nanowires', 'netherlands', 'company', 'tno', 'designed', 'israel#E', 'similar#E', 'widely#E', 'employed#E', 'immunological#E', 'technique#E', 'case#E', 'fiber#E', 'optics#E', 'list#E', 'pathogens#E', 'attached#E', 'silver#E', 'gold#E', 'netherlands#E', 'company#E', 'tno#E', 'designed#E']\n",
    "y = ['israeli', 'written', 'shalom', 'hanoch', 'protest', 'israeli', 'policy', 'territories', 'song', 'banned', 'radio', 'israeli', 'folk', 'singer', 'miri', 'aloni', 'sang', 'israeli', 'pop', 'song', 'israeli#E', 'written#E', 'shalom#E', 'hanoch#E', 'protest#E', 'israeli#E', 'policy#E', 'territories#E', 'song#E', 'banned#E', 'radio#E', 'israeli#E', 'folk#E', 'singer#E', 'miri#E', 'aloni#E', 'sang#E', 'israeli#E', 'pop#E', 'song#E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:32:50.510282Z",
     "start_time": "2022-04-26T07:32:50.504728Z"
    }
   },
   "outputs": [],
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:43:45.023898Z",
     "start_time": "2022-04-26T07:43:45.015302Z"
    }
   },
   "outputs": [],
   "source": [
    "v1 = get_avgvec(x,w2v_model)\n",
    "v2 = get_avgvec(y,w2v_model)\n",
    "\n",
    "w2v_model.cosine_similarities(v1,[v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:43:45.338440Z",
     "start_time": "2022-04-26T07:43:45.330079Z"
    }
   },
   "outputs": [],
   "source": [
    "v1 = get_avgvec(x,spx_model)\n",
    "v2 = get_avgvec(y,spx_model)\n",
    "\n",
    "spx_model.cosine_similarities(v1,[v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:43:45.719545Z",
     "start_time": "2022-04-26T07:43:45.709758Z"
    }
   },
   "outputs": [],
   "source": [
    "v1 = get_avgvec(x,spxEM_model)\n",
    "v2 = get_avgvec(y,spxEM_model)\n",
    "\n",
    "spxEM_model.cosine_similarities(v1,[v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:07:05.748858Z",
     "start_time": "2022-04-26T07:07:05.690365Z"
    }
   },
   "outputs": [],
   "source": [
    "avgsim(data[0][0],data[0][1],data[0][2],data[0][3],spx_model,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:40:06.287516Z",
     "start_time": "2022-04-26T07:40:05.429860Z"
    }
   },
   "outputs": [],
   "source": [
    "avgsim(data[0][0],data[0][1],data[0][2],data[0][3],spxEM_model,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:37:37.625444Z",
     "start_time": "2022-04-26T07:37:37.175029Z"
    }
   },
   "outputs": [],
   "source": [
    "avgsim(data[6][0],data[6][1],data[6][2],data[6][3],spxEM_model,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in model.vocab:\n",
    "    if '#' in w:\n",
    "        print(w)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wiki as w\n",
    "import sys\n",
    "sys.path.append(\"../../imports/\")\n",
    "import saver as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sv.load(\"wiki_sentences_spx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "    print(sent[:105])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][0])\n",
    "print(sent_words(data[0][2]))\n",
    "print(data[0][1])\n",
    "print(sent_words(data[0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spxEM_model.similarity('brazil','nut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spxEM_model.similarity('brazil#E','nut#E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.similarity('brazil','nut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_words(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-context similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws353A = '/home/manni/data/wordsim/EN-WS353.txt'\n",
    "ws353R = '/home/manni/data/wordsim/EN-WSR353.txt'\n",
    "ws353S = '/home/manni/data/wordsim/EN-WSS353.txt'\n",
    "rw = '/home/manni/data/wordsim/rw.txt'\n",
    "sim999 = '/home/manni/data/wordsim/EN-SIM999.txt'\n",
    "turk = '/home/manni/data/wordsim/EN_TRUK.txt'\n",
    "mturk = '/home/manni/data/wordsim/MTURK-771.csv'\n",
    "rg = '/home/manni/data/wordsim/EN-RG-65.txt'\n",
    "men = '/home/manni/data/wordsim/EN-MEN-LEM.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sim999) as fin:\n",
    "    lines = fin.readlines()\n",
    "    with open(sim999+'_new','w') as fout:\n",
    "        for line in lines:\n",
    "            line = line.split('\\t')\n",
    "            try:\n",
    "                float(line[3])\n",
    "                fout.write(\"{} {} {} \\n\".format(line[0],line[1],line[3])) \n",
    "            except:\n",
    "                continue   \n",
    "sim999 = sim999+'_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mturk) as fin:\n",
    "    lines = fin.readlines()\n",
    "    with open(mturk+'_new','w') as fout:\n",
    "        for line in lines:\n",
    "            line = line.split(',')\n",
    "            try:\n",
    "                fout.write(\"{} {} {} \\n\".format(line[0],line[1],line[2])) \n",
    "            except:\n",
    "                continue   \n",
    "mturk = mturk+'_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(men) as fin:\n",
    "    lines = fin.readlines()\n",
    "    with open(men+'_new','w') as fout:\n",
    "        for line in lines:\n",
    "            line = line.split()\n",
    "            try:\n",
    "                fout.write(\"{} {} {} \\n\".format(line[0].split('-')[0],line[1].split('-')[0],line[2])) \n",
    "            except:\n",
    "                continue   \n",
    "men = men+'_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "with open(mturk) as fin:\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line= line.split()\n",
    "        print(line)\n",
    "        continue\n",
    "        try:\n",
    "            if line[0] in model.vocab and line[1] in model.vocab:\n",
    "                continue\n",
    "        except:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ws353A,ws353R,ws353S,rw,sim999,turk,mturk,rg,men]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sim(w1,w2,model):\n",
    "    s1 = [w1,w1+'#E']\n",
    "    s2 = [w2,w2+'#E']\n",
    "    a = [w for w in s1 if w in model.vocab]\n",
    "    b = [w for w in s2 if w in model.vocab]\n",
    "    div = len(a)*len(b)\n",
    "    sims = 0\n",
    "    for i in a:\n",
    "        for j in b:\n",
    "            sims+=model.similarity(i,j)\n",
    "    return sims/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ds in datasets:\n",
    "    name = ds.split('/')[-1].split('.')[0]\n",
    "    print(r'\\begin{subsection}{'+name+r'}')\n",
    "    print(r'\\begin{table}[!h]')\n",
    "    print(r'\\begin{tabular}{|l|c|c|}')\n",
    "    print('\\hline')\n",
    "    print(\"Model & Pearsons & Spearmans\"+r\"\\\\\")\n",
    "    print('\\hline')\n",
    "    with open(ds) as fin:\n",
    "        lines = fin.readlines()\n",
    "        for i, model in enumerate(models):\n",
    "            print(model_names[i],end=' & ')\n",
    "            sims = list()\n",
    "            scores = list()\n",
    "            for line in lines:\n",
    "                line = line.split()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if line[0] in model.vocab and line[1] in model.vocab:\n",
    "                    sim = avg_sim(line[0],line[1],model) \n",
    "                else:\n",
    "                    continue\n",
    "                if sim:\n",
    "                    score = float(line[2])\n",
    "                    sims.append(sim)\n",
    "                    scores.append(score)\n",
    "            corr, _ = pearsonr(sims, scores)\n",
    "            print('%.2f' % (corr*100),end=' & ')\n",
    "            corr, _ = spearmanr(sims, scores)\n",
    "            print('%.2f' % (corr*100),end=r'\\\\') \n",
    "            print()\n",
    "    print('\\hline')\n",
    "    print('\\end{tabular}')\n",
    "    print('\\end{table}')\n",
    "    print(r'\\end{subsection}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
