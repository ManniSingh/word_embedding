{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3615c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:42.886609Z",
     "start_time": "2022-09-30T11:21:42.737178Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dc861d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:13:43.757899Z",
     "start_time": "2022-10-14T09:13:43.745520Z"
    }
   },
   "outputs": [],
   "source": [
    "glove = '/home/manni/embs/gloveW2V.6B.300d.txt'\n",
    "w2v = '/home/manni/embs/word2vec-google-news-300.gz'\n",
    "wiki2v = '/home/manni/embs/enwiki_20180420_300d.txt.bz2'\n",
    "dconf = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300d722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T04:50:42.200250Z",
     "start_time": "2022-09-03T04:47:33.538927Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format(glove, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "686d3459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:17:31.430443Z",
     "start_time": "2022-10-14T09:13:45.885091Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(w2v, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d3518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T03:30:54.721721Z",
     "start_time": "2022-09-06T02:46:26.849131Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_model = KeyedVectors.load_word2vec_format(wiki2v, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8658b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:52:59.801518Z",
     "start_time": "2022-09-06T10:52:50.331181Z"
    }
   },
   "outputs": [],
   "source": [
    "words = wiki_model.most_similar('bank',topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0100f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:53:05.579984Z",
     "start_time": "2022-09-06T10:53:05.365775Z"
    }
   },
   "outputs": [],
   "source": [
    "wiki_model.most_similar('bank',topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93435fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:54:49.109053Z",
     "start_time": "2022-09-06T10:54:49.099681Z"
    }
   },
   "outputs": [],
   "source": [
    "def total_overlap(word,model,topn=100):\n",
    "    overlap_matrix = np.zeros((topn,topn),dtype=np.int8)\n",
    "    words = model.most_similar(word,topn=topn)\n",
    "    words = set([i[0] for i in words])\n",
    "    nns = dict()\n",
    "    for word in words:\n",
    "        _words = model.most_similar(word,topn=5)\n",
    "        _words = set([i[0] for i in _words])\n",
    "        nns[word]=_words\n",
    "    for i,(k,a) in enumerate(nns.items()):\n",
    "        for j,(kk,b) in enumerate(nns.items()):\n",
    "            if k == kk:\n",
    "                overlap_matrix[i][j]=1\n",
    "                continue\n",
    "            overlap = len(a & b)\n",
    "            overlap_matrix[i][j]=overlap\n",
    "    return nns,overlap_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1c0f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:56:53.394146Z",
     "start_time": "2022-09-06T10:56:33.802453Z"
    }
   },
   "outputs": [],
   "source": [
    "nns,ovm = total_overlap('bank',glove_model,topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22597047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T11:04:30.598682Z",
     "start_time": "2022-09-05T11:04:30.593698Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_closer(n):\n",
    "    print(voc[n])\n",
    "    print(':::::')\n",
    "    nn = set()\n",
    "    for i,val in enumerate(ovm[n]>0):\n",
    "        if val:\n",
    "            print(i,voc[i])\n",
    "            nn.add(voc[i])\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c412a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T11:07:31.737434Z",
     "start_time": "2022-09-05T11:07:31.730802Z"
    }
   },
   "outputs": [],
   "source": [
    "a = print_closer(3)\n",
    "b = print_closer(15)\n",
    "print(a&b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725ca37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:57:04.205686Z",
     "start_time": "2022-09-06T10:57:03.054048Z"
    }
   },
   "outputs": [],
   "source": [
    "clusters = dict()\n",
    "voc = list(nns.keys())\n",
    "for v in voc:\n",
    "    clusters[v]=-1\n",
    "c = 0\n",
    "for i in range(len(ovm)):\n",
    "    for j in range(len(ovm)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        vec = ovm[i]\n",
    "        vec = vec>0\n",
    "        vec_ = ovm[j]\n",
    "        vec_= vec_>0\n",
    "        list_a = [voc[i_] for i_,x in enumerate(vec) if x]\n",
    "        list_b = [voc[i_] for i_,x in enumerate(vec_) if x]\n",
    "        overlap = len(set(list_a) & set(list_b))\n",
    "        if overlap>3:\n",
    "            #print(i,':',voc[i],j,':',voc[j])\n",
    "            #if i == 10 or j == 10:\n",
    "            #    print(i,j,clusters[voc[i]],clusters[voc[j]])\n",
    "            if clusters[voc[i]]>-1 and clusters[voc[j]]>-1:\n",
    "                c_ = min(clusters[voc[i]],clusters[voc[j]])\n",
    "                clusters[voc[i]]=c_\n",
    "                clusters[voc[j]]=c_\n",
    "            elif clusters[voc[i]]>-1:\n",
    "                clusters[voc[j]]=clusters[voc[i]]\n",
    "            elif clusters[voc[j]]>-1:\n",
    "                clusters[voc[i]]=clusters[voc[j]]\n",
    "            else:\n",
    "                clusters[voc[i]]=c\n",
    "                clusters[voc[j]]=c\n",
    "                c+=1\n",
    "            #if i == 10 or j == 10:\n",
    "            #    print(i,j,clusters[voc[i]],clusters[voc[j]])\n",
    "        #if np.array_equal(vec,vec_):\n",
    "        #    print(i,':',voc[i],j,':',voc[j])\n",
    "    #print('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62aa363",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_ = dict()\n",
    "for i,c in enumerate(clusters.values()):\n",
    "    if c == -1:\n",
    "        continue\n",
    "    if c in clusters_:\n",
    "        clusters_[c].append(voc[i])\n",
    "    else:\n",
    "        clusters_[c] = [voc[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2c6e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:57:08.838657Z",
     "start_time": "2022-09-06T10:57:08.835017Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_matrix(model,vocab):\n",
    "    matrix = list()\n",
    "    for word in vocab:\n",
    "        vec = model.get_vector(word)\n",
    "        matrix.append(vec)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c396b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72fe17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:57:09.590216Z",
     "start_time": "2022-09-06T10:57:09.586470Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix = get_matrix(glove_model,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02783965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-06T10:57:10.202341Z",
     "start_time": "2022-09-06T10:57:10.199456Z"
    }
   },
   "outputs": [],
   "source": [
    "matrix = np.asarray(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d26c4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# validate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677ee7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5d38942",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9dec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:57:26.230716Z",
     "start_time": "2022-09-04T08:57:26.227804Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91eec4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:57:53.105922Z",
     "start_time": "2022-09-04T08:57:53.101094Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.4,min_samples=2,metric='cosine').fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd163cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:57:54.152284Z",
     "start_time": "2022-09-04T08:57:54.147759Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = db.labels_\n",
    "clusters = dict()\n",
    "for i,c in enumerate(labels):\n",
    "    if c == -1:\n",
    "        continue\n",
    "    if c in clusters:\n",
    "        clusters[c].append(vocab[i])\n",
    "    else:\n",
    "        clusters[c] = [vocab[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9b4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:57:54.422562Z",
     "start_time": "2022-09-04T08:57:54.416438Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f4809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T13:36:38.213641Z",
     "start_time": "2022-09-03T13:36:38.206152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe464db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-04T08:34:40.641537Z",
     "start_time": "2022-09-04T08:34:40.633434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = [[1, 2], [2, 2], [2, 3],[8, 7], [8, 8], [25, 80]]\n",
    "clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9627e0",
   "metadata": {},
   "source": [
    "# wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42953c73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:20:55.773477Z",
     "start_time": "2022-09-30T11:20:55.770488Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde97549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:20:56.741203Z",
     "start_time": "2022-09-30T11:20:56.737477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52286d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('dog')[0].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('dog.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('frump.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synset('dog.n.03').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "dog.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('bank')[9].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6ad014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:13.031742Z",
     "start_time": "2022-09-30T11:21:02.952860Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = list(wn.all_synsets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a200e81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:13.037986Z",
     "start_time": "2022-09-30T11:21:13.033940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117659"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ddfb46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:13.215531Z",
     "start_time": "2022-09-30T11:21:13.039416Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_ = set()\n",
    "for ss in vocab:\n",
    "    word = ss.name().split('.')[0]\n",
    "    if '_' in word:\n",
    "        continue\n",
    "    vocab_.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba28f8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:13.221693Z",
     "start_time": "2022-09-30T11:21:13.217774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58736"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9726cc64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:13.240293Z",
     "start_time": "2022-09-30T11:21:13.223330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'abelmosk',\n",
       " 'waterdog',\n",
       " 'aspidophoroides',\n",
       " 'massenet',\n",
       " 'dolefully',\n",
       " 'unoiled',\n",
       " 'infomercial',\n",
       " 'paradoxical',\n",
       " 'inability']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e48968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:25.780117Z",
     "start_time": "2022-09-30T11:21:25.776515Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_uniques(input_list):\n",
    "    uniques = set()\n",
    "    for k,v in Counter(input_list).items():\n",
    "        if v>1:\n",
    "            continue\n",
    "        uniques.add(k)\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61536d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:30.636184Z",
     "start_time": "2022-09-30T11:21:26.017778Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 12:21:27.003676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-30 12:21:28.716575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-30 12:21:28.717119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:08:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-09-30 12:21:28.717464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-09-30 12:21:28.717798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: \n",
      "pciBusID: 0000:16:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-09-30 12:21:28.718126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: \n",
      "pciBusID: 0000:19:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-09-30 12:21:28.718158: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-30 12:21:28.720586: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-30 12:21:28.778960: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-30 12:21:28.779331: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-30 12:21:28.781879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-30 12:21:28.783524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-30 12:21:28.789197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-30 12:21:28.791747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d81659fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T11:22:18.626222Z",
     "start_time": "2022-10-01T11:22:17.211538Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 58736/58736 [00:01<00:00, 41739.81it/s]\n"
     ]
    }
   ],
   "source": [
    "worddesc_raw = dict()\n",
    "for _word in tqdm(vocab_,position=0):\n",
    "    word = lemmatizer.lemmatize(_word)\n",
    "    synsets = wn.synsets(word)\n",
    "    for synset in synsets:\n",
    "        txt = synset.definition().lower()\n",
    "        if word in worddesc_raw:\n",
    "            worddesc_raw[word].append(txt)\n",
    "        else:\n",
    "            worddesc_raw[word]=[txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2044460d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-01T11:22:33.295797Z",
     "start_time": "2022-10-01T11:22:33.112475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the data\n"
     ]
    }
   ],
   "source": [
    "sv.save(worddesc_raw,'worddesc_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c099fbc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:21:33.035364Z",
     "start_time": "2022-09-30T11:21:33.032483Z"
    }
   },
   "outputs": [],
   "source": [
    "nouns = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267455b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:22:02.748792Z",
     "start_time": "2022-09-30T11:21:50.898350Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 58736/58736 [00:11<00:00, 4963.10it/s]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "#ps = PorterStemmer()\n",
    "stops = set(stopwords.words('english'))\n",
    "word_desc = dict()\n",
    "for _word in tqdm(vocab_,position=0):\n",
    "    word = lemmatizer.lemmatize(_word)\n",
    "    synsets = wn.synsets(word)\n",
    "    for synset in synsets:\n",
    "        txt = synset.definition().lower()\n",
    "        if nouns:\n",
    "            doc = nlp(txt)\n",
    "            try:\n",
    "                txt = [token.text for token in doc if token.pos_=='NOUN']\n",
    "                txt = ' '.join(txt)\n",
    "            except:\n",
    "                print(txt)\n",
    "                sys.exit()\n",
    "        txt = re.sub(r'\\W+', ' ', txt)\n",
    "        words = [w for w in txt.split()]\n",
    "        #txts = synset.examples()\n",
    "        #txt = ' '.join(txts)\n",
    "        #txt = re.sub(r'\\W+', ' ', txt)\n",
    "        #words_ = [w for w in txt.split()]\n",
    "        #words = words + words_\n",
    "        hypo = synset.hyponyms()\n",
    "        hypo_words = [ss.name().split('.')[0] for ss in hypo]\n",
    "        hyper = synset.hypernyms()\n",
    "        hyper_words = [ss.name().split('.')[0] for ss in hyper]\n",
    "        _words = words+hypo_words+hyper_words\n",
    "        words = list()\n",
    "        for w in _words:\n",
    "            words.extend(w.split('_'))\n",
    "        words = [lemmatizer.lemmatize(w) for w in words if w not in stops]\n",
    "        words = set(words)\n",
    "        #add to dict\n",
    "        if word in word_desc:\n",
    "            word_desc[word].append(words)\n",
    "        else:\n",
    "            word_desc[word]=[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced8139d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:22:02.756004Z",
     "start_time": "2022-09-30T11:22:02.751366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_desc['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0344dbbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-02T11:31:05.801625Z",
     "start_time": "2022-10-02T11:31:04.120637Z"
    }
   },
   "outputs": [],
   "source": [
    "word2desc = dict()\n",
    "for k,v in word_desc.items():\n",
    "    word2desc[k] = list()\n",
    "    all_words = [item for sublist in v for item in sublist]\n",
    "    #uniques = get_uniques(all_words)\n",
    "    for words in v:\n",
    "        words = set(words)\n",
    "        #word2desc[k].append(words&uniques)\n",
    "        word2desc[k].append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63c29f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T12:09:30.973474Z",
     "start_time": "2022-09-30T12:09:30.967386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'amelogenesis',\n",
       "  'angiogenesis',\n",
       "  'apposition',\n",
       "  'auxesis',\n",
       "  'biological',\n",
       "  'biology',\n",
       "  'blossoming',\n",
       "  'cenogenesis',\n",
       "  'changing',\n",
       "  'cohesion',\n",
       "  'cultivation',\n",
       "  'culture',\n",
       "  'cycle',\n",
       "  'cytogenesis',\n",
       "  'event',\n",
       "  'foliation',\n",
       "  'fructification',\n",
       "  'gametogenesis',\n",
       "  'germination',\n",
       "  'gradually',\n",
       "  'habit',\n",
       "  'individual',\n",
       "  'infructescence',\n",
       "  'intussusception',\n",
       "  'involved',\n",
       "  'juvenescence',\n",
       "  'level',\n",
       "  'life',\n",
       "  'masculinization',\n",
       "  'morphogenesis',\n",
       "  'myelinization',\n",
       "  'neurogenesis',\n",
       "  'organic',\n",
       "  'organically',\n",
       "  'organism',\n",
       "  'palingenesis',\n",
       "  'psychogenesis',\n",
       "  'psychomotor',\n",
       "  'psychosexual',\n",
       "  'purely',\n",
       "  'rooting',\n",
       "  'simple',\n",
       "  'suppression',\n",
       "  'teething',\n",
       "  'teratogenesis',\n",
       "  'unfolding'},\n",
       " {'form', 'progression', 'simpler'},\n",
       " {'accession',\n",
       "  'accretion',\n",
       "  'becoming',\n",
       "  'growth',\n",
       "  'important',\n",
       "  'larger',\n",
       "  'longer',\n",
       "  'multiplication',\n",
       "  'numerous',\n",
       "  'population',\n",
       "  'pullulation',\n",
       "  'relaxation',\n",
       "  'widening'},\n",
       " set(),\n",
       " {'beginning', 'coming', 'forth', 'gradual', 'rise'},\n",
       " {'abnormal',\n",
       "  'excrescence',\n",
       "  'exostosis',\n",
       "  'hamartoma',\n",
       "  'illness',\n",
       "  'pathology',\n",
       "  'peduncle',\n",
       "  'polyp',\n",
       "  'tissue',\n",
       "  'tumor'},\n",
       " {'ingrowth', 'object', 'something'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2desc['growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a89b94e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-30T11:22:35.717080Z",
     "start_time": "2022-09-30T11:22:35.706391Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../imports/\")\n",
    "import saver as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b413aa5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-02T11:31:58.942313Z",
     "start_time": "2022-10-02T11:31:58.434868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the data\n"
     ]
    }
   ],
   "source": [
    "sv.save(word2desc,\"word2desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2desc['anarchism'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2desc['fast'])\n",
    "print(len(word2desc['fast']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869391d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    for synset in synsets:\n",
    "        txt = synset.definition().lower()\n",
    "        txt = re.sub(r'\\W+', ' ', txt)\n",
    "        print(txt)\n",
    "        hyper = synset.hypernyms()\n",
    "        hyper_words = [ss.name().split('.')[0] for ss in hyper]\n",
    "        print(hyper_words)\n",
    "        hypo = synset.hyponyms()\n",
    "        hypo_words = [ss.name().split('.')[0] for ss in hypo]\n",
    "        print(hypo_words)\n",
    "        print('______')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e157428",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"faster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aebca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"a part of a river where the current is very fast\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599aff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose('dogging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose('rapid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed804de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2desc['rapid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2desc['fast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ed08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap(a,b):\n",
    "    a = word2desc[a]\n",
    "    b = word2desc[b]\n",
    "    overlap = 0\n",
    "    match = None\n",
    "    for i,x in enumerate(a):\n",
    "        for j,y in enumerate(b):\n",
    "            if len(x & y) > overlap:\n",
    "                overlap = len(x & y)\n",
    "                match = (i,j)\n",
    "    return match, overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd32326",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_overlap('fast','rapid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem('moving'))\n",
    "print(lemmatizer.lemmatize('moving'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2desc['authority'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fd815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5897f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c2546",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(vocab_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dd621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3cc89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vocab_[100:110]:\n",
    "    print(i)\n",
    "    txt = i.definition().lower()\n",
    "    print(txt)\n",
    "    txt = re.sub(r'\\W+', ' ', txt)\n",
    "    print(txt)\n",
    "    words = [word for word in txt.split() if word not in stops]\n",
    "    print(set(words))\n",
    "    word = i.name().split('.')[0]\n",
    "    print(wn.synsets(word))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4209df",
   "metadata": {},
   "source": [
    "# odd one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d35fc52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T10:53:44.337783Z",
     "start_time": "2022-10-14T10:53:44.328752Z"
    }
   },
   "outputs": [],
   "source": [
    "def odd_word_out(input_words,model):\n",
    "    '''The function accepts a list of word and returns the odd word.'''\n",
    "     \n",
    "    # Generate all word embeddings for the given list of words\n",
    "    vocab = model.vocab\n",
    "     \n",
    "    whole_word_vectors = [model.get_vector(i) for i in input_words if i in vocab]\n",
    "     \n",
    "    # average vector for all word vectors\n",
    "    mean_vector = np.mean(whole_word_vectors,axis=0)\n",
    "     \n",
    "    # Iterate over every word and find similarity\n",
    "    odd_word = None\n",
    "    minimum_similarity = 99999.0 # Can be any very high value\n",
    "     \n",
    "    for i in input_words:\n",
    "        if i in model.vocab:\n",
    "            similarity = model.cosine_similarities(model.get_vector(i),[mean_vector])\n",
    "            if similarity < minimum_similarity:\n",
    "                minimum_similarity = similarity\n",
    "                odd_word = i\n",
    "\n",
    "            print(\"cosine similarity score between %s and mean_vector is %.3f\"%(i,similarity))\n",
    "     \n",
    "    print(\"\\nThe odd word is: \"+odd_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1092b320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T10:53:45.174107Z",
     "start_time": "2022-10-14T10:53:45.167981Z"
    }
   },
   "outputs": [],
   "source": [
    "input_words = {'current', 'fast', 'part', 'river', 'waterway'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df8727bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T10:53:45.731388Z",
     "start_time": "2022-10-14T10:53:45.726232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity score between river and mean_vector is 0.797\n",
      "cosine similarity score between waterway and mean_vector is 0.795\n",
      "cosine similarity score between current and mean_vector is 0.298\n",
      "cosine similarity score between fast and mean_vector is 0.428\n",
      "cosine similarity score between part and mean_vector is 0.375\n",
      "\n",
      "The odd word is: current\n"
     ]
    }
   ],
   "source": [
    "odd_word_out(input_words,w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f29ead22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T11:01:12.947716Z",
     "start_time": "2022-10-14T11:01:12.625219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Current', 0.5574568510055542),\n",
       " ('currrent', 0.512985348701477),\n",
       " ('thecurrent', 0.49619051814079285),\n",
       " ('curent', 0.4640691876411438),\n",
       " ('future', 0.462577223777771),\n",
       " ('existing', 0.44827771186828613),\n",
       " ('new', 0.4458693861961365),\n",
       " ('previous', 0.4399641454219818),\n",
       " ('normalized_FFO_guidance', 0.41918817162513733),\n",
       " ('prevailing', 0.4187409281730652),\n",
       " ('currently', 0.40886324644088745),\n",
       " ('speaker_Rauhi_Fattouh', 0.40469616651535034),\n",
       " ('NeoPharm_anticipates', 0.40467962622642517),\n",
       " ('changesin', 0.40295684337615967),\n",
       " ('instrument_SHORT_TERM', 0.39964842796325684),\n",
       " ('the', 0.3985964059829712),\n",
       " ('examines_Chinas', 0.3956565856933594),\n",
       " ('Visit_www.otc_advisors.com', 0.3910021185874939),\n",
       " ('coincident_index_measuring', 0.3904479146003723),\n",
       " ('assumes_noobligation', 0.38776859641075134),\n",
       " ('continuation', 0.3865417242050171),\n",
       " ('Dr_Dulare', 0.3858053386211395),\n",
       " ('xi_unanticipated', 0.3855990767478943),\n",
       " ('projected', 0.38018572330474854),\n",
       " ('regarding_Bachoco', 0.37681156396865845),\n",
       " ('present', 0.37672844529151917),\n",
       " ('####-####', 0.3761169910430908),\n",
       " ('presently', 0.3752506375312805),\n",
       " ('reflect_PREIT', 0.3752226233482361),\n",
       " ('latest', 0.37488874793052673)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.similar_by_word('current',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc735cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
