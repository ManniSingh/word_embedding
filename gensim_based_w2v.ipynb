{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T10:37:26.239974Z",
     "start_time": "2022-09-29T10:37:24.170536Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "#import wiki_old as w # old wiki\n",
    "import wiki as w \n",
    " \n",
    "#from gensim.models import word2vec # for orignal w2v\n",
    "from localgensim.gensim2.models import word2vec \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from gensim.models.fasttext import FastText\n",
    "#from gensim.models.word2vec import Word2Vec # not in use\n",
    "#from localgensim.gensim2.models.word2vec import Word2Vec # not in use\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "WIKIXML = '/home/manni/data/wiki/en-28102022.bz2'\n",
    "#WIKIXML = '/home/manni/data/wiki/enwiki-20211120-pages-articles-multistream1.xml-p1p41242.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T10:37:29.369500Z",
     "start_time": "2022-09-29T10:37:29.366161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manni/ner-s2s/word_embedding/wiki.py\n",
      "/home/manni/ner-s2s/word_embedding/localgensim/gensim2/models/word2vec.py\n"
     ]
    }
   ],
   "source": [
    "print(w.__file__)\n",
    "print(word2vec.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T10:37:32.706932Z",
     "start_time": "2022-09-29T10:37:32.704476Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../imports/\")\n",
    "import saver as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T10:37:33.045286Z",
     "start_time": "2022-09-29T10:37:33.042417Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] %(message)s', level=logging.INFO)\n",
    "os.makedirs('data/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences = MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T13:25:05.774307Z",
     "start_time": "2020-10-25T13:25:05.608721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logging.info('Training model %s', 'word2vec')\n",
    "model = Word2Vec(sentences, window=5, sg=1, hs=0, negative=10, size=300, sample=0, \n",
    "                 workers=1, iter=1, min_count=1)\n",
    "\n",
    "logging.info('Training done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T13:48:45.834994Z",
     "start_time": "2020-10-25T13:47:14.780675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences = w.WikiSentences(WIKIXML, 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Conll corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences = sv.load(\"conll_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T13:52:12.732111Z",
     "start_time": "2020-10-25T13:48:45.838043Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(sentences, window=5, sg=1, hs=0, negative=5, size=300, sample=0, workers=1, iter=1, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/conll_spx2g.txt'\n",
    "emb_file = '/mnt/nfs/resdata0/manni/wiki/conll_w2v.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logging.info('Save trained word vectors')\n",
    "with open(emb_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('%d %d\\n' % (len(model.wv.vocab), 300))\n",
    "    for word in tqdm(model.wv.vocab):\n",
    "        f.write('%s %s\\n' % (word, ' '.join([str(v) for v in model.wv[word]])))\n",
    "logging.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip if sentence made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T14:54:01.529935Z",
     "start_time": "2022-09-29T10:37:52.759819Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 11:37:52,761] Parsing wiki corpus Altered...\n",
      "[2022-09-29 11:38:00,198] adding document #0 to Dictionary(0 unique tokens: [])\n",
      "[2022-09-29 11:39:15,232] adding document #10000 to Dictionary(558662 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:40:20,604] adding document #20000 to Dictionary(776301 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:41:18,449] adding document #30000 to Dictionary(938856 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:42:09,855] adding document #40000 to Dictionary(1075117 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:44:33,415] adding document #90000 to Dictionary(1314523 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:45:21,496] adding document #100000 to Dictionary(1428812 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:46:04,298] adding document #110000 to Dictionary(1521678 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:46:47,411] adding document #120000 to Dictionary(1614137 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:47:26,528] adding document #130000 to Dictionary(1686530 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:48:07,668] adding document #140000 to Dictionary(1776644 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:48:44,988] adding document #150000 to Dictionary(1864419 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:49:25,057] adding document #160000 to Dictionary(1939982 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:50:06,180] discarding 8951 tokens: [('burchenal', 1), ('cheatem', 1), ('detillo', 1), ('dujmovic', 1), ('jebidiha', 1), ('kopus', 1), ('muffterson', 1), ('pintero', 1), ('schannault', 1), ('shockerfest', 1)]...\n",
      "[2022-09-29 11:50:06,183] keeping 2000000 tokens which were in no less than 0 and no more than 170000 (=100.0%) documents\n",
      "[2022-09-29 11:50:09,418] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:50:09,440] adding document #170000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:50:46,631] discarding 61969 tokens: [('太興', 1), ('威名未著', 1), ('帝初鎮江東', 1), ('敦與從弟導等同心翼戴', 1), ('時人為之語曰', 1), ('景文', 1), ('王敦傳', 1), ('王與馬', 1), ('門閥政治格局的形成', 1), ('blackslash', 1)]...\n",
      "[2022-09-29 11:50:46,633] keeping 2000000 tokens which were in no less than 0 and no more than 180000 (=100.0%) documents\n",
      "[2022-09-29 11:50:50,978] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:50:51,042] adding document #180000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:51:27,757] discarding 61244 tokens: [('nsttf', 1), ('rispasso', 1), ('shouhang', 1), ('solnova', 1), ('techscope', 1), ('torresol', 1), ('congenials', 1), ('schmidmaier', 1), ('belalı', 1), ('cerēt', 1)]...\n",
      "[2022-09-29 11:51:27,759] keeping 2000000 tokens which were in no less than 0 and no more than 190000 (=100.0%) documents\n",
      "[2022-09-29 11:51:32,514] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:51:32,577] adding document #190000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:52:10,555] discarding 66797 tokens: [('同歸域', 1), ('城东', 1), ('姚公殉难处碑', 1), ('沈家门港区', 1), ('王錫朋', 1), ('环南', 1), ('盐仓', 1), ('祖印寺', 1), ('老塘山港区', 1), ('舟山市', 1)]...\n",
      "[2022-09-29 11:52:10,558] keeping 2000000 tokens which were in no less than 0 and no more than 200000 (=100.0%) documents\n",
      "[2022-09-29 11:52:15,006] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:52:15,071] adding document #200000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:52:50,877] discarding 56626 tokens: [('tiedexen', 1), ('tiedexer', 1), ('vardeilsen', 1), ('vogelbeck', 1), ('voldagsen', 1), ('wenzen', 1), ('volvo_', 1), ('an_der_stadtmauer_dassel', 1), ('baldertower', 1), ('blankschmiede', 1)]...\n",
      "[2022-09-29 11:52:50,879] keeping 2000000 tokens which were in no less than 0 and no more than 210000 (=100.0%) documents\n",
      "[2022-09-29 11:52:53,971] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:52:54,016] adding document #210000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:53:30,900] discarding 61446 tokens: [('coeurnelle', 1), ('cfoam', 1), ('corriboard', 1), ('geobond', 1), ('fidyka', 1), ('spinalcord', 1), ('angelyn', 1), ('lcwr', 1), ('nlrcm', 1), ('parater', 1)]...\n",
      "[2022-09-29 11:53:30,902] keeping 2000000 tokens which were in no less than 0 and no more than 220000 (=100.0%) documents\n",
      "[2022-09-29 11:53:33,978] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:53:34,024] adding document #220000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:54:10,078] discarding 60374 tokens: [('ongoujou', 1), ('ouallah', 1), ('ouhozi', 1), ('ounkazi', 1), ('ourovéni', 1), ('ousivo', 1), ('ouzinii', 1), ('ouzioini', 1), ('ouéllah', 1), ('pidjani', 1)]...\n",
      "[2022-09-29 11:54:10,080] keeping 2000000 tokens which were in no less than 0 and no more than 230000 (=100.0%) documents\n",
      "[2022-09-29 11:54:14,454] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:54:14,520] adding document #230000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:54:51,126] discarding 53424 tokens: [('ikkada', 1), ('janiva', 1), ('jiteya', 1), ('jithe', 1), ('jorsey', 1), ('kafila', 1), ('kajrare', 1), ('khauff', 1), ('khayega', 1), ('khelungi', 1)]...\n",
      "[2022-09-29 11:54:51,128] keeping 2000000 tokens which were in no less than 0 and no more than 240000 (=100.0%) documents\n",
      "[2022-09-29 11:54:55,132] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:54:55,177] adding document #240000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:55:30,965] discarding 59309 tokens: [('litahrir', 1), ('mahber', 1), ('nidemokirasini', 1), ('pfdjህግንፍ', 1), ('teame', 1), ('tegadelo', 1), ('tuamzghi', 1), ('ēritira', 1), ('ḥadineti', 1), ('ḥarineti', 1)]...\n",
      "[2022-09-29 11:55:30,966] keeping 2000000 tokens which were in no less than 0 and no more than 250000 (=100.0%) documents\n",
      "[2022-09-29 11:55:34,028] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:55:34,073] adding document #250000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:56:10,129] discarding 54901 tokens: [('dabaka', 1), ('diphupar', 1), ('doyang', 1), ('drouyer', 1), ('ethasü', 1), ('jessami', 1), ('jotsoma', 1), ('khaibong', 1), ('kheza', 1), ('kigwema', 1)]...\n",
      "[2022-09-29 11:56:10,131] keeping 2000000 tokens which were in no less than 0 and no more than 260000 (=100.0%) documents\n",
      "[2022-09-29 11:56:14,880] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:56:14,947] adding document #260000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 11:57:01,129] discarding 59394 tokens: [('penumalli', 1), ('pinrayi', 1), ('polba', 1), ('radhakrishnamurthy', 1), ('satgachhia', 1), ('sorbhog', 1), ('spectaculated', 1), ('surthi', 1), ('tammineni', 1), ('theog', 1)]...\n",
      "[2022-09-29 11:57:01,131] keeping 2000000 tokens which were in no less than 0 and no more than 270000 (=100.0%) documents\n",
      "[2022-09-29 11:57:04,410] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:57:04,457] adding document #270000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:57:37,581] discarding 56204 tokens: [('立命館', 1), ('経営学研究科', 1), ('経営学部', 1), ('経営管理研究科', 1), ('経済学研究科', 1), ('経済学部', 1), ('言語教育情報研究科', 1), ('groutwork', 1), ('ungrouted', 1), ('washup#0', 1)]...\n",
      "[2022-09-29 11:57:37,583] keeping 2000000 tokens which were in no less than 0 and no more than 280000 (=100.0%) documents\n",
      "[2022-09-29 11:57:42,180] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:57:42,255] adding document #280000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:58:17,553] discarding 62662 tokens: [('harnaſch', 1), ('haÿde', 1), ('hiute', 1), ('hochalemannisch', 1), ('hochpreußisch', 1), ('iemer', 1), ('iunge', 1), ('jehent', 1), ('juncvorouwen', 1), ('jŭnckfrawen', 1)]...\n",
      "[2022-09-29 11:58:17,555] keeping 2000000 tokens which were in no less than 0 and no more than 290000 (=100.0%) documents\n",
      "[2022-09-29 11:58:22,141] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:58:22,233] adding document #290000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:58:54,730] discarding 58551 tokens: [('noribergensis', 1), ('openemblem', 1), ('picinelli', 1), ('pulter', 1), ('raspathe', 1), ('schäufelin', 1), ('simbolico', 1), ('sinnbildkunst', 1), ('sinnn', 1), ('stronks', 1)]...\n",
      "[2022-09-29 11:58:54,732] keeping 2000000 tokens which were in no less than 0 and no more than 300000 (=100.0%) documents\n",
      "[2022-09-29 11:58:59,408] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:58:59,478] adding document #300000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:59:34,005] discarding 61626 tokens: [('eustacie', 1), ('konstanza', 1), ('commmittee', 1), ('müdâfaa', 1), ('ulusalcı', 1), ('ulusalcılık', 1), ('nenohi', 1), ('sabok', 1), ('shokyu', 1), ('dragnet#1', 1)]...\n",
      "[2022-09-29 11:59:34,007] keeping 2000000 tokens which were in no less than 0 and no more than 310000 (=100.0%) documents\n",
      "[2022-09-29 11:59:37,290] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 11:59:37,340] adding document #310000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:00:09,310] discarding 52995 tokens: [('prash', 1), ('odourant', 1), ('iphc', 1), ('jotabeche', 1), ('spiritlife', 1), ('burianová', 1), ('digesture', 1), ('marstaller', 1), ('westerouen', 1), ('aathbiskot', 1)]...\n",
      "[2022-09-29 12:00:09,311] keeping 2000000 tokens which were in no less than 0 and no more than 320000 (=100.0%) documents\n",
      "[2022-09-29 12:00:12,519] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:00:12,567] adding document #320000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:00:44,810] discarding 49278 tokens: [('tanrenga', 1), ('triparshva', 1), ('tsukeai', 1), ('tsukeku', 1), ('tōba', 1), ('ushin', 1), ('utakotoba', 1), ('wakiku', 1), ('yukiyō', 1), ('zuinō', 1)]...\n",
      "[2022-09-29 12:00:44,812] keeping 2000000 tokens which were in no less than 0 and no more than 330000 (=100.0%) documents\n",
      "[2022-09-29 12:00:49,211] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:00:49,281] adding document #330000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:01:20,224] discarding 46770 tokens: [('zaklyuchennyi', 1), ('zaumnyy', 1), ('zemlyachestvo', 1), ('znamennoe', 1), ('ìzba', 1), ('ʂɐˈraʂkə', 1), ('автома', 1), ('агита', 1), ('агитпро', 1), ('активные', 1)]...\n",
      "[2022-09-29 12:01:20,226] keeping 2000000 tokens which were in no less than 0 and no more than 340000 (=100.0%) documents\n",
      "[2022-09-29 12:01:23,313] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:01:23,360] adding document #340000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:01:54,239] discarding 44870 tokens: [('wyomambuja', 1), ('śivasaṃhitā', 1), ('bajranglal', 1), ('bankidas', 1), ('barhath', 1), ('bhatiyani', 1), ('bhogilal', 1), ('bokadia', 1), ('budania', 1), ('chundawat', 1)]...\n",
      "[2022-09-29 12:01:54,241] keeping 2000000 tokens which were in no less than 0 and no more than 350000 (=100.0%) documents\n",
      "[2022-09-29 12:01:59,026] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:01:59,096] adding document #350000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:02:30,805] discarding 45651 tokens: [('elmazi', 1), ('engjell', 1), ('enkelejd', 1), ('eralda', 1), ('fation', 1), ('ferdinad', 1), ('florion', 1), ('florjon', 1), ('frrokaj', 1), ('gjekmarkaj', 1)]...\n",
      "[2022-09-29 12:02:30,807] keeping 2000000 tokens which were in no less than 0 and no more than 360000 (=100.0%) documents\n",
      "[2022-09-29 12:02:35,235] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:02:35,304] adding document #360000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:03:07,425] discarding 51029 tokens: [('partiynykh', 1), ('pesochniy', 1), ('privorotskaya', 1), ('proverke', 1), ('ryadov', 1), ('ukrainizatsiya', 1), ('lobblies', 1), ('mergenthwerker', 1), ('mergenthwirker', 1), ('bydogoszcz', 1)]...\n",
      "[2022-09-29 12:03:07,427] keeping 2000000 tokens which were in no less than 0 and no more than 370000 (=100.0%) documents\n",
      "[2022-09-29 12:03:11,859] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:03:11,931] adding document #370000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:03:47,428] discarding 44512 tokens: [('halyrudhous', 1), ('honorablie', 1), ('inclosit', 1), ('lordis', 1), ('otheris', 1), ('quhilke', 1), ('raisit', 1), ('respectis', 1), ('roring', 1), ('solempnitie', 1)]...\n",
      "[2022-09-29 12:03:47,430] keeping 2000000 tokens which were in no less than 0 and no more than 380000 (=100.0%) documents\n",
      "[2022-09-29 12:03:51,900] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:03:51,969] adding document #380000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:04:23,423] discarding 48106 tokens: [('kartendokumentation', 1), ('landstadt', 1), ('lechleite', 1), ('mozartin', 1), ('ottoried', 1), ('pallottiner', 1), ('rederzhausen', 1), ('rinnenthal', 1), ('skatertag', 1), ('stadtbegiet', 1)]...\n",
      "[2022-09-29 12:04:23,425] keeping 2000000 tokens which were in no less than 0 and no more than 390000 (=100.0%) documents\n",
      "[2022-09-29 12:04:27,896] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:04:27,966] adding document #390000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:04:59,383] discarding 52992 tokens: [('rihmer', 1), ('saxonorum', 1), ('slashchyov', 1), ('carpintis', 1), ('greifvogelvorführung', 1), ('ppark', 1), ('copwen', 1), ('eaglesworth', 1), ('facejacker', 1), ('abhisares', 1)]...\n",
      "[2022-09-29 12:04:59,385] keeping 2000000 tokens which were in no less than 0 and no more than 400000 (=100.0%) documents\n",
      "[2022-09-29 12:05:02,516] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:05:02,565] adding document #400000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:05:32,928] discarding 52379 tokens: [('perverseraph', 1), ('cueller', 1), ('gaide', 1), ('calymmatobacterium', 1), ('dentocariosa', 1), ('extroquens', 1), ('faceium', 1), ('maloratus', 1), ('noguchii', 1), ('trachomae', 1)]...\n",
      "[2022-09-29 12:05:32,929] keeping 2000000 tokens which were in no less than 0 and no more than 410000 (=100.0%) documents\n",
      "[2022-09-29 12:05:37,307] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:05:37,378] adding document #410000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:06:08,236] discarding 47421 tokens: [('ессей', 1), ('илирней', 1), ('ильмень', 1), ('имандра', 1), ('иони', 1), ('исинга', 1), ('капылюши', 1), ('кезеной', 1), ('кенон', 1), ('кизи', 1)]...\n",
      "[2022-09-29 12:06:08,238] keeping 2000000 tokens which were in no less than 0 and no more than 420000 (=100.0%) documents\n",
      "[2022-09-29 12:06:12,672] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:06:12,742] adding document #420000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:06:42,497] discarding 52102 tokens: [('klepaski', 1), ('kyui', 1), ('namchal', 1), ('tsendaiush', 1), ('karamatsu', 1), ('nishidake', 1), ('rechtschaffner', 1), ('prosiness', 1), ('skooma', 1), ('depop', 1)]...\n",
      "[2022-09-29 12:06:42,499] keeping 2000000 tokens which were in no less than 0 and no more than 430000 (=100.0%) documents\n",
      "[2022-09-29 12:06:45,735] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:06:45,785] adding document #430000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:07:15,470] discarding 47160 tokens: [('årsband', 1), ('ghumaisa', 1), ('spbe', 1), ('الغميصاء', 1), ('yooseop', 1), ('gerideau', 1), ('liveandirect', 1), ('nrgise', 1), ('cyberjack', 1), ('wincomm', 1)]...\n",
      "[2022-09-29 12:07:15,471] keeping 2000000 tokens which were in no less than 0 and no more than 440000 (=100.0%) documents\n",
      "[2022-09-29 12:07:19,920] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:07:19,990] adding document #440000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:07:49,479] discarding 51139 tokens: [('cybercore', 1), ('duoworld', 1), ('sinistron', 1), ('turboedge', 1), ('turboforce', 1), ('vasteel', 1), ('handerhan', 1), ('orndroff', 1), ('luckycorner', 1), ('chaucesel', 1)]...\n",
      "[2022-09-29 12:07:49,481] keeping 2000000 tokens which were in no less than 0 and no more than 450000 (=100.0%) documents\n",
      "[2022-09-29 12:07:52,821] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:07:52,877] adding document #450000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:08:21,179] discarding 41178 tokens: [('walltowers', 1), ('zernand', 1), ('dfebel', 1), ('meandrov', 1), ('ofitser', 1), ('ostfliegerstaffel', 1), ('shapalov', 1), ('vlasovtsy', 1), ('landways', 1), ('rurización', 1)]...\n",
      "[2022-09-29 12:08:21,181] keeping 2000000 tokens which were in no less than 0 and no more than 460000 (=100.0%) documents\n",
      "[2022-09-29 12:08:24,479] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:08:24,535] adding document #460000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:08:54,414] discarding 49560 tokens: [('castledaly', 1), ('gcearr', 1), ('kiloutou', 1), ('moyvoughly', 1), ('nunsturgesius', 1), ('rathowen', 1), ('riplica', 1), ('aschkenazy', 1), ('baxis', 1), ('doshenko', 1)]...\n",
      "[2022-09-29 12:08:54,416] keeping 2000000 tokens which were in no less than 0 and no more than 470000 (=100.0%) documents\n",
      "[2022-09-29 12:08:57,663] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:08:57,713] adding document #470000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:09:26,956] discarding 44461 tokens: [('chialà', 1), ('chludovianus', 1), ('croecker', 1), ('dânêl', 1), ('dûdâêl', 1), ('eermans', 1), ('erläuternden', 1), ('excursen', 1), ('ezenna', 1), ('ezêqêêl', 1)]...\n",
      "[2022-09-29 12:09:26,958] keeping 2000000 tokens which were in no less than 0 and no more than 480000 (=100.0%) documents\n",
      "[2022-09-29 12:09:31,416] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:09:31,487] adding document #480000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:10:01,395] discarding 48639 tokens: [('tijdorde', 1), ('tooneelspel', 1), ('torensluis', 1), ('vorstenschool', 1), ('hoebuk', 1), ('hoein', 1), ('myeonn', 1), ('naesonngni', 1), ('oesongni', 1), ('chaylou', 1)]...\n",
      "[2022-09-29 12:10:01,396] keeping 2000000 tokens which were in no less than 0 and no more than 490000 (=100.0%) documents\n",
      "[2022-09-29 12:10:04,578] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:10:04,630] adding document #490000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:10:38,345] discarding 46754 tokens: [('jedworð', 1), ('jethart', 1), ('azenar', 1), ('adamolekun', 1), ('algéro', 1), ('ambitous', 1), ('campboiro', 1), ('candéa', 1), ('coranique', 1), ('dramouss', 1)]...\n",
      "[2022-09-29 12:10:38,348] keeping 2000000 tokens which were in no less than 0 and no more than 500000 (=100.0%) documents\n",
      "[2022-09-29 12:10:42,969] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:10:43,043] adding document #500000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:11:13,378] discarding 48847 tokens: [('nooraki', 1), ('ozwords', 1), ('pallidurgbarrans', 1), ('arughtai', 1), ('chunjingxian', 1), ('chūzonmon', 1), ('gongdingli', 1), ('gongrangzhang', 1), ('gongshunchong', 1), ('rongsixian', 1)]...\n",
      "[2022-09-29 12:11:13,380] keeping 2000000 tokens which were in no less than 0 and no more than 510000 (=100.0%) documents\n",
      "[2022-09-29 12:11:17,891] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:11:17,965] adding document #510000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:11:48,192] discarding 44502 tokens: [('proslavil', 1), ('xxph', 1), ('zingaresca', 1), ('čaroděj', 1), ('francoforum', 1), ('kachanoski', 1), ('munfla', 1), ('oerc', 1), ('provehito', 1), ('nindawayma', 1)]...\n",
      "[2022-09-29 12:11:48,194] keeping 2000000 tokens which were in no less than 0 and no more than 520000 (=100.0%) documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:11:51,412] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:11:51,463] adding document #520000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:12:21,285] discarding 50284 tokens: [('hochzeitsstück', 1), ('waldmärchen', 1), ('fixaren', 1), ('grundeler', 1), ('phillipsons', 1), ('tabbouli', 1), ('cyberbombs', 1), ('dellah', 1), ('theatrology', 1), ('timeonic', 1)]...\n",
      "[2022-09-29 12:12:21,293] keeping 2000000 tokens which were in no less than 0 and no more than 530000 (=100.0%) documents\n",
      "[2022-09-29 12:12:25,917] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:12:25,991] adding document #530000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:12:56,362] discarding 44793 tokens: [('dębieńsko', 1), ('eingedeutschte', 1), ('familoki', 1), ('rückgedeutschte', 1), ('volksdeutcher', 1), ('pietrzkowice', 1), ('falsificate', 1), ('lasiszka', 1), ('lazyska', 1), ('berouna', 1)]...\n",
      "[2022-09-29 12:12:56,363] keeping 2000000 tokens which were in no less than 0 and no more than 540000 (=100.0%) documents\n",
      "[2022-09-29 12:12:59,599] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:12:59,650] adding document #540000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:13:28,222] discarding 45382 tokens: [('katynia', 1), ('kotwic', 1), ('kościerzyce', 1), ('lokators', 1), ('lompy', 1), ('małkowice', 1), ('mossora', 1), ('myśliborze', 1), ('mąkoszyce', 1), ('nadodrzański', 1)]...\n",
      "[2022-09-29 12:13:28,224] keeping 2000000 tokens which were in no less than 0 and no more than 550000 (=100.0%) documents\n",
      "[2022-09-29 12:13:31,478] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:13:31,530] adding document #550000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:13:59,464] discarding 42171 tokens: [('baekdeoksan', 1), ('baekdunbong', 1), ('baekhwasan', 1), ('baekseoksan', 1), ('baekunsan', 1), ('bakdalbong', 1), ('bakdalsan', 1), ('bakjisan', 1), ('bakjwibong', 1), ('balgyosan', 1)]...\n",
      "[2022-09-29 12:13:59,466] keeping 2000000 tokens which were in no less than 0 and no more than 560000 (=100.0%) documents\n",
      "[2022-09-29 12:14:03,582] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:14:03,658] adding document #560000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:14:31,294] discarding 39822 tokens: [('okdae', 1), ('ongam', 1), ('pyeongeun', 1), ('saenghyeon', 1), ('sangmang', 1), ('sangseok', 1), ('seokgyo', 1), ('seonggok', 1), ('seungmun', 1), ('sinjeon', 1)]...\n",
      "[2022-09-29 12:14:31,296] keeping 2000000 tokens which were in no less than 0 and no more than 570000 (=100.0%) documents\n",
      "[2022-09-29 12:14:35,353] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:14:35,426] adding document #570000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:15:03,170] discarding 46787 tokens: [('pavaikka', 1), ('pavakai', 1), ('pepóni', 1), ('pikró', 1), ('pāgarkāy', 1), ('pāvakāy', 1), ('pāvaykka', 1), ('sopropo', 1), ('tetor', 1), ('thuvaran', 1)]...\n",
      "[2022-09-29 12:15:03,172] keeping 2000000 tokens which were in no less than 0 and no more than 580000 (=100.0%) documents\n",
      "[2022-09-29 12:15:06,400] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:15:06,452] adding document #580000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:15:35,057] discarding 44078 tokens: [('순창나들목', 1), ('지리산나들목', 1), ('지리산휴게소', 1), ('함양나들목', 1), ('함양분기점', 1), ('해인사나들목', 1), ('haengdam', 1), ('haengdamdo', 1), ('muchangpo', 1), ('onlygangneung', 1)]...\n",
      "[2022-09-29 12:15:35,058] keeping 2000000 tokens which were in no less than 0 and no more than 590000 (=100.0%) documents\n",
      "[2022-09-29 12:15:39,354] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:15:39,428] adding document #590000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:16:09,290] discarding 44857 tokens: [('chuntov', 1), ('dabov', 1), ('elenov', 1), ('tzotchev', 1), ('aegyptaiaca', 1), ('bellong', 1), ('labunskaya', 1), ('maitreyananda', 1), ('nezlobina', 1), ('strakaty', 1)]...\n",
      "[2022-09-29 12:16:09,292] keeping 2000000 tokens which were in no less than 0 and no more than 600000 (=100.0%) documents\n",
      "[2022-09-29 12:16:13,932] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:16:14,014] adding document #600000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:16:41,362] discarding 41670 tokens: [('wrotethat', 1), ('alphataurus', 1), ('andreabocellimar', 1), ('autarchia', 1), ('bidente', 1), ('bidentina', 1), ('concertoggi', 1), ('concertoranges', 1), ('coreutico', 1), ('estatica', 1)]...\n",
      "[2022-09-29 12:16:41,364] keeping 2000000 tokens which were in no less than 0 and no more than 610000 (=100.0%) documents\n",
      "[2022-09-29 12:16:46,191] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:16:46,274] adding document #610000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:17:14,414] discarding 45357 tokens: [('woolwichsouth', 1), ('agentsmade', 1), ('irfanulla', 1), ('monowing', 1), ('operationcoupled', 1), ('typeif', 1), ('cmoapi', 1), ('hesitancy§', 1), ('milligramm', 1), ('tadacip', 1)]...\n",
      "[2022-09-29 12:17:14,416] keeping 2000000 tokens which were in no less than 0 and no more than 620000 (=100.0%) documents\n",
      "[2022-09-29 12:17:18,989] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:17:19,066] adding document #620000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:17:47,552] discarding 43687 tokens: [('daidža', 1), ('daidžinica', 1), ('daidžić', 1), ('daidžišnja', 1), ('dajdža', 1), ('dajdžinica', 1), ('dajnica', 1), ('kćer', 1), ('kćerka', 1), ('maćeha', 1)]...\n",
      "[2022-09-29 12:17:47,554] keeping 2000000 tokens which were in no less than 0 and no more than 630000 (=100.0%) documents\n",
      "[2022-09-29 12:17:50,782] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:17:50,836] adding document #630000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:18:17,558] discarding 41188 tokens: [('чоравац', 1), ('dievaite', 1), ('djurdjić', 1), ('djurdjo', 1), ('iťь', 1), ('jarog', 1), ('otiousus', 1), ('panicz', 1), ('perkune', 1), ('raragas', 1)]...\n",
      "[2022-09-29 12:18:17,559] keeping 2000000 tokens which were in no less than 0 and no more than 640000 (=100.0%) documents\n",
      "[2022-09-29 12:18:20,778] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:18:20,830] adding document #640000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:18:46,018] discarding 52376 tokens: [('bluster#1', 1), ('marlein', 1), ('rrfl', 1), ('thebaei', 1), ('thebanorum', 1), ('inruled', 1), ('mcgarrahan', 1), ('repstage', 1), ('ritsch', 1), ('stackner', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:18:46,020] keeping 2000000 tokens which were in no less than 0 and no more than 650000 (=100.0%) documents\n",
      "[2022-09-29 12:18:50,657] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:18:50,737] adding document #650000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:19:16,779] discarding 39507 tokens: [('berthelseni', 1), ('biarritziana', 1), ('bramensis', 1), ('branscombensis', 1), ('bueltenensis', 1), ('calveti', 1), ('camillae', 1), ('caminosa', 1), ('canalifera', 1), ('capillimargo', 1)]...\n",
      "[2022-09-29 12:19:16,781] keeping 2000000 tokens which were in no less than 0 and no more than 660000 (=100.0%) documents\n",
      "[2022-09-29 12:19:20,083] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:19:20,140] adding document #660000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:19:47,504] discarding 39492 tokens: [('primarypurpose', 1), ('sakibe', 1), ('sefurisan', 1), ('shikotsuko', 1), ('shinodayama', 1), ('shinyamashita', 1), ('ukibaru', 1), ('yausubetsu', 1), ('yokawame', 1), ('guettent', 1)]...\n",
      "[2022-09-29 12:19:47,506] keeping 2000000 tokens which were in no less than 0 and no more than 670000 (=100.0%) documents\n",
      "[2022-09-29 12:19:52,497] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:19:52,574] adding document #670000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:20:17,521] discarding 39584 tokens: [('gohman', 1), ('grundleshotz', 1), ('haltsburg', 1), ('hamleton', 1), ('jabenis', 1), ('kolpé', 1), ('kretzmera', 1), ('lœb', 1), ('mackes', 1), ('mutrox', 1)]...\n",
      "[2022-09-29 12:20:17,523] keeping 2000000 tokens which were in no less than 0 and no more than 680000 (=100.0%) documents\n",
      "[2022-09-29 12:20:20,829] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:20:20,882] adding document #680000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:20:48,319] discarding 59327 tokens: [('horlovono', 1), ('pedriola', 1), ('quarazza', 1), ('tieschtbach', 1), ('vispu', 1), ('argondizzo', 1), ('baitieri', 1), ('barilaro', 1), ('bertogna', 1), ('birighitti', 1)]...\n",
      "[2022-09-29 12:20:48,322] keeping 2000000 tokens which were in no less than 0 and no more than 690000 (=100.0%) documents\n",
      "[2022-09-29 12:20:53,014] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:20:53,099] adding document #690000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:21:20,997] discarding 40437 tokens: [('villefranches', 1), ('viscounty#0§', 1), ('gilmored', 1), ('irrates', 1), ('kuschner', 1), ('marquont', 1), ('tohokumainline', 1), ('tokaidomainline', 1), ('yamanoteline', 1), ('原宿', 1)]...\n",
      "[2022-09-29 12:21:20,999] keeping 2000000 tokens which were in no less than 0 and no more than 700000 (=100.0%) documents\n",
      "[2022-09-29 12:21:24,791] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:21:24,868] adding document #700000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:21:51,858] discarding 42451 tokens: [('kelamah', 1), ('maloi', 1), ('nerasau', 1), ('nismilan', 1), ('nscmh', 1), ('selemak', 1), ('semerbok', 1), ('sepri', 1), ('sombilan', 1), ('temuans', 1)]...\n",
      "[2022-09-29 12:21:51,860] keeping 2000000 tokens which were in no less than 0 and no more than 710000 (=100.0%) documents\n",
      "[2022-09-29 12:21:55,231] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:21:55,286] adding document #710000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:22:25,368] discarding 40697 tokens: [('jewing', 1), ('ʻor', 1), ('הטאליבן', 1), ('נשות', 1), ('chekisms', 1), ('yurasovo', 1), ('чекизмы', 1), ('aggressionist', 1), ('gromyki', 1), ('sjeljutov', 1)]...\n",
      "[2022-09-29 12:22:25,370] keeping 2000000 tokens which were in no less than 0 and no more than 720000 (=100.0%) documents\n",
      "[2022-09-29 12:22:29,904] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:22:29,958] adding document #720000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:22:57,628] discarding 40606 tokens: [('благородный', 1), ('пансион', 1), ('absolvents', 1), ('akadémiya', 1), ('blumentrost', 1), ('iskran', 1), ('kotyukov', 1), ('naúk', 1), ('rossíiskaya', 1), ('vingoradov', 1)]...\n",
      "[2022-09-29 12:22:57,630] keeping 2000000 tokens which were in no less than 0 and no more than 730000 (=100.0%) documents\n",
      "[2022-09-29 12:23:02,008] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:23:02,066] adding document #730000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:23:28,541] discarding 39427 tokens: [('alvesb', 1), ('alvesc', 1), ('alvesw', 1), ('andrioletti', 1), ('arterc', 1), ('arterf', 1), ('aukthunklaus', 1), ('baylorsteward', 1), ('baylortrevor', 1), ('beconi', 1)]...\n",
      "[2022-09-29 12:23:28,543] keeping 2000000 tokens which were in no less than 0 and no more than 740000 (=100.0%) documents\n",
      "[2022-09-29 12:23:33,262] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:23:33,340] adding document #740000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:24:00,400] discarding 42804 tokens: [('florjana', 1), ('saint_florian_statue', 1), ('verschon', 1), ('digitalmill', 1), ('isokatu', 1), ('farnberger', 1), ('feuerwehrzeughaus', 1), ('jagdmuseum', 1), ('sumerauerhof', 1), ('cincpachyderm', 1)]...\n",
      "[2022-09-29 12:24:00,402] keeping 2000000 tokens which were in no less than 0 and no more than 750000 (=100.0%) documents\n",
      "[2022-09-29 12:24:05,165] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:24:05,244] adding document #750000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:24:32,293] discarding 37548 tokens: [('hēimò', 1), ('jiàodīng', 1), ('jūnrú', 1), ('kuāxī', 1), ('liuqian', 1), ('liùlǐ', 1), ('luòdōng', 1), ('mubian', 1), ('mémá', 1), ('nàhé', 1)]...\n",
      "[2022-09-29 12:24:32,295] keeping 2000000 tokens which were in no less than 0 and no more than 760000 (=100.0%) documents\n",
      "[2022-09-29 12:24:37,128] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:24:37,207] adding document #760000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:25:01,971] discarding 38937 tokens: [('yourkeyturkey', 1), ('araliifolia', 1), ('carpometacarpi', 1), ('caruncular', 1), ('héguerty', 1), ('microsofttranslator', 1), ('baerida', 1), ('calcareans', 1), ('calcaronea', 1), ('calcinea', 1)]...\n",
      "[2022-09-29 12:25:01,973] keeping 2000000 tokens which were in no less than 0 and no more than 770000 (=100.0%) documents\n",
      "[2022-09-29 12:25:05,314] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:25:05,369] adding document #770000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:25:32,786] discarding 43946 tokens: [('tetraconodontinae', 1), ('warthog#0§', 1), ('waterybutts', 1), ('folnog', 1), ('geartoglu', 1), ('trhovište', 1), ('turnulchindiei', 1), ('târgovişteincludes', 1), ('viglu', 1), ('трговиште', 1)]...\n",
      "[2022-09-29 12:25:32,788] keeping 2000000 tokens which were in no less than 0 and no more than 780000 (=100.0%) documents\n",
      "[2022-09-29 12:25:37,586] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:25:37,665] adding document #780000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:26:05,092] discarding 40626 tokens: [('ελευθερούπολης', 1), ('ελευσίνας', 1), ('εξαμιλίων', 1), ('εξαρχείων', 1), ('εορδαϊκός', 1), ('επανομής', 1), ('επιταλίου', 1), ('εράνη', 1), ('ερέτριας', 1), ('εργοτέλης', 1)]...\n",
      "[2022-09-29 12:26:05,094] keeping 2000000 tokens which were in no less than 0 and no more than 790000 (=100.0%) documents\n",
      "[2022-09-29 12:26:08,402] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:26:08,455] adding document #790000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:26:35,020] discarding 38061 tokens: [('torsbäcken', 1), ('torshagsån', 1), ('torsjöån', 1), ('torsmovasseln', 1), ('torvsjöån', 1), ('torvån', 1), ('torån', 1), ('toskbäcken', 1), ('tranebergsälven', 1), ('trankvillsån', 1)]...\n",
      "[2022-09-29 12:26:35,022] keeping 2000000 tokens which were in no less than 0 and no more than 800000 (=100.0%) documents\n",
      "[2022-09-29 12:26:40,114] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:26:40,192] adding document #800000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:27:05,656] discarding 44206 tokens: [('götån', 1), ('habbestorpebäcken', 1), ('haddängsån', 1), ('hagaån', 1), ('hagbyån', 1), ('haggeån', 1), ('hagälven', 1), ('hagån', 1), ('hajumsälven', 1), ('hakerudsälven', 1)]...\n",
      "[2022-09-29 12:27:05,658] keeping 2000000 tokens which were in no less than 0 and no more than 810000 (=100.0%) documents\n",
      "[2022-09-29 12:27:09,015] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:27:09,069] adding document #810000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:27:34,440] discarding 40189 tokens: [('kmwr', 1), ('kmwv', 1), ('kncp', 1), ('kqcf', 1), ('kqdl', 1), ('kqhr', 1), ('kqmi', 1), ('kqoc', 1), ('kshl', 1), ('ksxm', 1)]...\n",
      "[2022-09-29 12:27:34,441] keeping 2000000 tokens which were in no less than 0 and no more than 820000 (=100.0%) documents\n",
      "[2022-09-29 12:27:39,196] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:27:39,276] adding document #820000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:28:05,705] discarding 37743 tokens: [('cruciferorum', 1), ('cruciferos', 1), ('denunciatorium', 1), ('dictos', 1), ('solvendis', 1), ('thepersonandthechallenges', 1), ('upjp', 1), ('wladimiri', 1), ('wlodkowic', 1), ('włodko', 1)]...\n",
      "[2022-09-29 12:28:05,707] keeping 2000000 tokens which were in no less than 0 and no more than 830000 (=100.0%) documents\n",
      "[2022-09-29 12:28:10,585] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:28:10,665] adding document #830000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:28:36,404] discarding 42306 tokens: [('adultg', 1), ('adwoman', 1), ('bondware', 1), ('chibibel', 1), ('dazstudio', 1), ('efrontier', 1), ('genetation', 1), ('gizmoz', 1), ('hivewire', 1), ('koshini', 1)]...\n",
      "[2022-09-29 12:28:36,405] keeping 2000000 tokens which were in no less than 0 and no more than 840000 (=100.0%) documents\n",
      "[2022-09-29 12:28:40,734] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:28:40,814] adding document #840000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:29:05,154] discarding 39619 tokens: [('felelősség', 1), ('külgazdaság', 1), ('magánjog', 1), ('országokban', 1), ('vékás', 1), ('összehasonlító', 1), ('útjain', 1), ('ariyamett', 1), ('binly', 1), ('buddhamamakaram', 1)]...\n",
      "[2022-09-29 12:29:05,156] keeping 2000000 tokens which were in no less than 0 and no more than 850000 (=100.0%) documents\n",
      "[2022-09-29 12:29:09,080] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:29:09,135] adding document #850000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:29:33,858] discarding 37091 tokens: [('bruchstedt', 1), ('haussömmern', 1), ('herbsleben', 1), ('hornsömmern', 1), ('marolterode', 1), ('mittelsömmern', 1), ('oppershausen', 1), ('südeichsfeld', 1), ('tawuia', 1), ('visingö', 1)]...\n",
      "[2022-09-29 12:29:33,860] keeping 2000000 tokens which were in no less than 0 and no more than 860000 (=100.0%) documents\n",
      "[2022-09-29 12:29:38,642] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:29:38,723] adding document #860000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:30:04,641] discarding 42679 tokens: [('yearsan', 1), ('chaikovskij', 1), ('chŏl', 1), ('kallicrates', 1), ('mussorgskij', 1), ('rajnis', 1), ('rūdaki', 1), ('thākur', 1), ('mcgunagle', 1), ('spountain', 1)]...\n",
      "[2022-09-29 12:30:04,643] keeping 2000000 tokens which were in no less than 0 and no more than 870000 (=100.0%) documents\n",
      "[2022-09-29 12:30:08,080] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:30:08,136] adding document #870000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:30:34,122] discarding 35966 tokens: [('frankenblick', 1), ('föritztal', 1), ('schalkauer', 1), ('siegmundsburg', 1), ('chinnakannan', 1), ('dishnetdsl', 1), ('hamilla', 1), ('millroy', 1), ('pindjarep', 1), ('rightstirling', 1)]...\n",
      "[2022-09-29 12:30:34,126] keeping 2000000 tokens which were in no less than 0 and no more than 880000 (=100.0%) documents\n",
      "[2022-09-29 12:30:39,269] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:30:39,350] adding document #880000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:31:04,562] discarding 37739 tokens: [('donerciler', 1), ('falez', 1), ('feslikan', 1), ('garajı', 1), ('hadrians_gate', 1), ('halkkart', 1), ('hibeş', 1), ('hıdırlık_tower_', 1), ('jahrein', 1), ('kaleici', 1)]...\n",
      "[2022-09-29 12:31:04,564] keeping 2000000 tokens which were in no less than 0 and no more than 890000 (=100.0%) documents\n",
      "[2022-09-29 12:31:07,977] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:31:08,035] adding document #890000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:31:34,537] discarding 40322 tokens: [('brimborium', 1), ('danceabilly', 1), ('fanphone', 1), ('broqueroye', 1), ('yselmond', 1), ('stäben', 1), ('ultraakustische', 1), ('wechselstrommaschinen', 1), ('wechselströme', 1), ('gaulcher', 1)]...\n",
      "[2022-09-29 12:31:34,539] keeping 2000000 tokens which were in no less than 0 and no more than 900000 (=100.0%) documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:31:39,390] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:31:39,471] adding document #900000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:32:03,689] discarding 35207 tokens: [('nonoca', 1), ('ventúra', 1), ('zaksauskas', 1), ('asbsbsw', 1), ('settmakers', 1), ('termofor', 1), ('thermophore', 1), ('vinovica', 1), ('breadservers', 1), ('coalmeters', 1)]...\n",
      "[2022-09-29 12:32:03,690] keeping 2000000 tokens which were in no less than 0 and no more than 910000 (=100.0%) documents\n",
      "[2022-09-29 12:32:07,149] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:32:07,204] adding document #910000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:32:34,459] discarding 36889 tokens: [('zolpinox', 1), ('zolpirest', 1), ('zolpistar', 1), ('zolpitop', 1), ('zolpitrac', 1), ('zolpium', 1), ('zolprem', 1), ('zolsana', 1), ('zolway', 1), ('zomnia', 1)]...\n",
      "[2022-09-29 12:32:34,460] keeping 2000000 tokens which were in no less than 0 and no more than 920000 (=100.0%) documents\n",
      "[2022-09-29 12:32:37,884] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:32:37,938] adding document #920000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:33:05,216] discarding 41307 tokens: [('siedlungsphase', 1), ('worldfuturefund', 1), ('iłowo', 1), ('korrigierte', 1), ('bakeham', 1), ('astagneau', 1), ('éveleyne', 1), ('eleftheromania', 1), ('gemetti', 1), ('hudlocke', 1)]...\n",
      "[2022-09-29 12:33:05,218] keeping 2000000 tokens which were in no less than 0 and no more than 930000 (=100.0%) documents\n",
      "[2022-09-29 12:33:09,990] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:33:10,072] adding document #930000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:33:33,189] discarding 40249 tokens: [('millaroo', 1), ('wunjunga', 1), ('existense', 1), ('エロス', 1), ('虐殺', 1), ('kuwabura', 1), ('南大隅郡', 1), ('大隅郡', 1), ('姶良郡', 1), ('桑原郡', 1)]...\n",
      "[2022-09-29 12:33:33,191] keeping 2000000 tokens which were in no less than 0 and no more than 940000 (=100.0%) documents\n",
      "[2022-09-29 12:33:36,582] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:33:36,639] adding document #940000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:34:02,597] discarding 55140 tokens: [('kukmér', 1), ('kulcsárfalu', 1), ('köröstyén', 1), ('középpulya', 1), ('kúpfalva', 1), ('küllő', 1), ('kőpatak', 1), ('lajtakáta', 1), ('lajtakörtvélyes', 1), ('lajtapordány', 1)]...\n",
      "[2022-09-29 12:34:02,599] keeping 2000000 tokens which were in no less than 0 and no more than 950000 (=100.0%) documents\n",
      "[2022-09-29 12:34:06,028] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:34:06,086] adding document #950000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:34:31,391] discarding 42972 tokens: [('phinias', 1), ('ballccourts', 1), ('gonazlez', 1), ('mapilca', 1), ('tihuatlan', 1), ('tlaxmalacatle', 1), ('tlaxmalactl', 1), ('wikerson', 1), ('xapaneca', 1), ('xicalcoluihqui', 1)]...\n",
      "[2022-09-29 12:34:31,393] keeping 2000000 tokens which were in no less than 0 and no more than 960000 (=100.0%) documents\n",
      "[2022-09-29 12:34:36,181] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:34:36,265] adding document #960000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:35:01,223] discarding 44421 tokens: [('gotreetop', 1), ('heightmin', 1), ('legendof', 1), ('mutinybay', 1), ('nemices', 1), ('nitrogenie', 1), ('rehydrator', 1), ('sectorenterprise', 1), ('skelvin', 1), ('smayhem', 1)]...\n",
      "[2022-09-29 12:35:01,225] keeping 2000000 tokens which were in no less than 0 and no more than 970000 (=100.0%) documents\n",
      "[2022-09-29 12:35:04,587] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:35:04,643] adding document #970000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:35:29,532] discarding 39091 tokens: [('ziegenort', 1), ('ćwierćmaraton', 1), ('łarpia', 1), ('świdwie', 1), ('munckel', 1), ('pyrzycw', 1), ('toeters', 1), ('gripiewò', 1), ('raciechowice', 1), ('jarszewko', 1)]...\n",
      "[2022-09-29 12:35:29,534] keeping 2000000 tokens which were in no less than 0 and no more than 980000 (=100.0%) documents\n",
      "[2022-09-29 12:35:34,290] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:35:34,376] adding document #980000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:35:58,886] discarding 44369 tokens: [('mathmas', 1), ('maundalis', 1), ('meliant', 1), ('meliot', 1), ('mellienderis', 1), ('melyans', 1), ('menaduke', 1), ('mescogneu', 1), ('mesconneuz', 1), ('mesconneü', 1)]...\n",
      "[2022-09-29 12:35:58,888] keeping 2000000 tokens which were in no less than 0 and no more than 990000 (=100.0%) documents\n",
      "[2022-09-29 12:36:03,678] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:36:03,761] adding document #990000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:36:27,020] discarding 48990 tokens: [('glühnix', 1), ('mcqst', 1), ('stammgelände', 1), ('tumcreate', 1), ('tumexchange', 1), ('conseravatives', 1), ('dogpole', 1), ('ownersrship', 1), ('abffe', 1), ('aclutx', 1)]...\n",
      "[2022-09-29 12:36:27,022] keeping 2000000 tokens which were in no less than 0 and no more than 1000000 (=100.0%) documents\n",
      "[2022-09-29 12:36:32,191] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:36:32,276] adding document #1000000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:36:56,715] discarding 45891 tokens: [('mesoamericus', 1), ('siderolamprinae', 1), ('siderolamprus', 1), ('antauges', 1), ('anzuetoi', 1), ('chiszari', 1), ('cuchumatanus', 1), ('cuetzpali', 1), ('fuscolabialis', 1), ('gadovii', 1)]...\n",
      "[2022-09-29 12:36:56,716] keeping 2000000 tokens which were in no less than 0 and no more than 1010000 (=100.0%) documents\n",
      "[2022-09-29 12:37:01,826] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:37:01,913] adding document #1010000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:37:26,645] discarding 39460 tokens: [('eurohorror', 1), ('wirraparinga', 1), ('expressby', 1), ('depthy', 1), ('dreamzzt', 1), ('ezanya', 1), ('hiwiller', 1), ('kevedit', 1), ('puzzlescript', 1), ('microhm', 1)]...\n",
      "[2022-09-29 12:37:26,647] keeping 2000000 tokens which were in no less than 0 and no more than 1020000 (=100.0%) documents\n",
      "[2022-09-29 12:37:30,284] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:37:30,347] adding document #1020000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:37:53,910] discarding 35163 tokens: [('bichweiler', 1), ('brienzerware', 1), ('furtwanger', 1), ('herrenhäusle', 1), ('inrebra', 1), ('jaegler', 1), ('jäck', 1), ('kuckucksuhr', 1), ('kuckucksuhren', 1), ('lackschilduhr', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:37:53,912] keeping 2000000 tokens which were in no less than 0 and no more than 1030000 (=100.0%) documents\n",
      "[2022-09-29 12:37:58,994] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:37:59,084] adding document #1030000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:38:22,350] discarding 35656 tokens: [('vostrukha', 1), ('xtoh', 1), ('zaltu', 1), ('castrovenes', 1), ('copral', 1), ('katicia', 1), ('katiucia', 1), ('woodheath', 1), ('microseeds', 1), ('pasteit', 1)]...\n",
      "[2022-09-29 12:38:22,351] keeping 2000000 tokens which were in no less than 0 and no more than 1040000 (=100.0%) documents\n",
      "[2022-09-29 12:38:27,244] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:38:27,328] adding document #1040000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:38:51,753] discarding 34959 tokens: [('bofof', 1), ('albeeville', 1), ('nearp', 1), ('yocumville', 1), ('antibari', 1), ('antibarum', 1), ('antivárion', 1), ('anžujska', 1), ('jerusalimac', 1), ('knjaževa', 1)]...\n",
      "[2022-09-29 12:38:51,755] keeping 2000000 tokens which were in no less than 0 and no more than 1050000 (=100.0%) documents\n",
      "[2022-09-29 12:38:56,934] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:38:57,023] adding document #1050000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:39:20,328] discarding 36558 tokens: [('thedish', 1), ('irimë', 1), ('cuivienyarna', 1), ('anasphere', 1), ('brph', 1), ('cosmoptera', 1), ('csiip', 1), ('ecoexploratorium', 1), ('girlstart', 1), ('innoviator', 1)]...\n",
      "[2022-09-29 12:39:20,329] keeping 2000000 tokens which were in no less than 0 and no more than 1060000 (=100.0%) documents\n",
      "[2022-09-29 12:39:23,732] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:39:23,789] adding document #1060000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:39:46,629] discarding 34155 tokens: [('alcleat', 1), ('alclit', 1), ('acrostolion', 1), ('chitôn', 1), ('hamiaux', 1), ('lartos', 1), ('microspectrography', 1), ('neorium', 1), ('pythocritos', 1), ('sipyla', 1)]...\n",
      "[2022-09-29 12:39:46,630] keeping 2000000 tokens which were in no less than 0 and no more than 1070000 (=100.0%) documents\n",
      "[2022-09-29 12:39:51,799] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:39:51,884] adding document #1070000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:40:13,771] discarding 37963 tokens: [('perusinum', 1), ('triumvirale', 1), ('triumviro', 1), ('jeongae', 1), ('matematice', 1), ('micropoems', 1), ('annestad', 1), ('fraiken', 1), ('chrislitherlandjonesboroark', 1), ('garrisonfsm', 1)]...\n",
      "[2022-09-29 12:40:13,773] keeping 2000000 tokens which were in no less than 0 and no more than 1080000 (=100.0%) documents\n",
      "[2022-09-29 12:40:17,185] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:40:17,243] adding document #1080000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:40:40,409] discarding 38897 tokens: [('keishōnan', 1), ('kōfuden', 1), ('kōkokumin', 1), ('seonggeun', 1), ('shiyoku', 1), ('subcontractees', 1), ('suigen', 1), ('yushik', 1), ('zenrahoku', 1), ('zenranan', 1)]...\n",
      "[2022-09-29 12:40:40,411] keeping 2000000 tokens which were in no less than 0 and no more than 1090000 (=100.0%) documents\n",
      "[2022-09-29 12:40:45,205] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:40:45,289] adding document #1090000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:41:07,595] discarding 35226 tokens: [('guariconensis', 1), ('guezennei', 1), ('guguanensis', 1), ('guryensis', 1), ('halosaccharolytica', 1), ('halosensibilis', 1), ('hamedanensis', 1), ('helmanticensis', 1), ('hespell', 1), ('hibiscicola', 1)]...\n",
      "[2022-09-29 12:41:07,597] keeping 2000000 tokens which were in no less than 0 and no more than 1100000 (=100.0%) documents\n",
      "[2022-09-29 12:41:12,399] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:41:12,483] adding document #1100000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:41:36,311] discarding 35953 tokens: [('noblezza', 1), ('perdendosi', 1), ('piangevole', 1), ('pianissimissimo', 1), ('pochiss', 1), ('pochissimo', 1), ('pressant', 1), ('rallentendo', 1), ('rasguedo', 1), ('rilassato', 1)]...\n",
      "[2022-09-29 12:41:36,313] keeping 2000000 tokens which were in no less than 0 and no more than 1110000 (=100.0%) documents\n",
      "[2022-09-29 12:41:41,109] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:41:41,193] adding document #1110000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:42:04,782] discarding 33919 tokens: [('landmands', 1), ('lapke', 1), ('deceas', 1), ('augustis', 1), ('collisons', 1), ('egyptial', 1), ('egyptianising', 1), ('gatehouse§', 1), ('rbyc', 1), ('wynvern', 1)]...\n",
      "[2022-09-29 12:42:04,784] keeping 2000000 tokens which were in no less than 0 and no more than 1120000 (=100.0%) documents\n",
      "[2022-09-29 12:42:10,053] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:42:10,137] adding document #1120000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:42:34,212] discarding 36391 tokens: [('adelberto', 1), ('colledonico', 1), ('gomano', 1), ('honoro', 1), ('daviaz', 1), ('massongex', 1), ('massunge', 1), ('tarnaiae', 1), ('driftingu', 1), ('polody', 1)]...\n",
      "[2022-09-29 12:42:34,214] keeping 2000000 tokens which were in no less than 0 and no more than 1130000 (=100.0%) documents\n",
      "[2022-09-29 12:42:38,989] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:42:39,073] adding document #1130000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:43:03,349] discarding 37985 tokens: [('hrfe', 1), ('rficns', 1), ('stuebing', 1), ('javarious', 1), ('chongpu', 1), ('georgea', 1), ('senanju', 1), ('somong', 1), ('songjim', 1), ('lozhkin', 1)]...\n",
      "[2022-09-29 12:43:03,350] keeping 2000000 tokens which were in no less than 0 and no more than 1140000 (=100.0%) documents\n",
      "[2022-09-29 12:43:08,537] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:43:08,623] adding document #1140000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:43:31,379] discarding 36514 tokens: [('troddin', 1), ('adhiratha', 1), ('akroor', 1), ('ashalata', 1), ('ashwathamas', 1), ('balraam', 1), ('belwalkar', 1), ('bidua', 1), ('brahmand', 1), ('dashraj', 1)]...\n",
      "[2022-09-29 12:43:31,381] keeping 2000000 tokens which were in no less than 0 and no more than 1150000 (=100.0%) documents\n",
      "[2022-09-29 12:43:35,072] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:43:35,157] adding document #1150000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:43:57,978] discarding 41416 tokens: [('ayagalria', 1), ('baffone', 1), ('lesil', 1), ('stelzenmuller', 1), ('toien', 1), ('arañibar', 1), ('confirmación', 1), ('erythrognatha', 1), ('femalenote', 1), ('mocagua', 1)]...\n",
      "[2022-09-29 12:43:57,980] keeping 2000000 tokens which were in no less than 0 and no more than 1160000 (=100.0%) documents\n",
      "[2022-09-29 12:44:01,384] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:44:01,445] adding document #1160000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:44:24,505] discarding 34329 tokens: [('xepe', 1), ('nettlebys', 1), ('rakassyi', 1), ('pattonwood', 1), ('acutiflorus', 1), ('alpiniformis', 1), ('alpinoarticulatus', 1), ('alpinopilosa', 1), ('anastrophyllum', 1), ('bantriensis', 1)]...\n",
      "[2022-09-29 12:44:24,507] keeping 2000000 tokens which were in no less than 0 and no more than 1170000 (=100.0%) documents\n",
      "[2022-09-29 12:44:28,080] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:44:28,143] adding document #1170000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:44:52,260] discarding 39466 tokens: [('māmmō', 1), ('אסתי', 1), ('ממו', 1), ('ማሞ', 1), ('እስቲ', 1), ('scriptshark', 1), ('bvrm', 1), ('dirusumarru', 1), ('vempa', 1), ('fingermonkey', 1)]...\n",
      "[2022-09-29 12:44:52,261] keeping 2000000 tokens which were in no less than 0 and no more than 1180000 (=100.0%) documents\n",
      "[2022-09-29 12:44:57,125] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:44:57,212] adding document #1180000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:45:21,911] discarding 42908 tokens: [('kangzhen', 1), ('tougen', 1), ('homanp', 1), ('kŭmho', 1), ('sokhu', 1), ('sŏhŭng', 1), ('anthonyen', 1), ('ascharina', 1), ('berawis', 1), ('gafia', 1)]...\n",
      "[2022-09-29 12:45:21,913] keeping 2000000 tokens which were in no less than 0 and no more than 1190000 (=100.0%) documents\n",
      "[2022-09-29 12:45:26,756] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:45:26,842] adding document #1190000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:45:52,291] discarding 34295 tokens: [('schokken', 1), ('waages', 1), ('kalameny', 1), ('breezerman', 1), ('networkwere', 1), ('pentrebaine', 1), ('trawscambria', 1), ('likavka', 1), ('adcomm', 1), ('boyll', 1)]...\n",
      "[2022-09-29 12:45:52,293] keeping 2000000 tokens which were in no less than 0 and no more than 1200000 (=100.0%) documents\n",
      "[2022-09-29 12:45:55,712] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:45:55,770] adding document #1200000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:46:19,354] discarding 36521 tokens: [('fernz', 1), ('rhinorhynchos', 1), ('whitleyi', 1), ('libidozone', 1), ('mthe', 1), ('kegola', 1), ('rakovor', 1), ('semgallia', 1), ('beknopte', 1), ('chandrabendi', 1)]...\n",
      "[2022-09-29 12:46:19,355] keeping 2000000 tokens which were in no less than 0 and no more than 1210000 (=100.0%) documents\n",
      "[2022-09-29 12:46:22,725] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:46:22,786] adding document #1210000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:46:46,929] discarding 36900 tokens: [('felkirk', 1), ('hodroyd', 1), ('fondeadero', 1), ('morochos', 1), ('orquilla', 1), ('azaële', 1), ('bosforo', 1), ('bottesiniurtext', 1), ('caratteristica', 1), ('contrabbassi', 1)]...\n",
      "[2022-09-29 12:46:46,931] keeping 2000000 tokens which were in no less than 0 and no more than 1220000 (=100.0%) documents\n",
      "[2022-09-29 12:46:51,717] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:46:51,803] adding document #1220000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:47:16,000] discarding 33246 tokens: [('frévent', 1), ('vasd', 1), ('dekins', 1), ('esprid', 1), ('fredrico', 1), ('shellhamer', 1), ('sixgunlover', 1), ('hlokozi', 1), ('zzzzzzzzzztt', 1), ('atromentic', 1)]...\n",
      "[2022-09-29 12:47:16,002] keeping 2000000 tokens which were in no less than 0 and no more than 1230000 (=100.0%) documents\n",
      "[2022-09-29 12:47:20,496] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:47:20,584] adding document #1230000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:47:44,856] discarding 33675 tokens: [('americanreligious', 1), ('flachmeier', 1), ('leiske', 1), ('ofseyer', 1), ('prestoncrest', 1), ('serns', 1), ('trovall', 1), ('zppr', 1), ('armanenschaft', 1), ('armanist', 1)]...\n",
      "[2022-09-29 12:47:44,858] keeping 2000000 tokens which were in no less than 0 and no more than 1240000 (=100.0%) documents\n",
      "[2022-09-29 12:47:50,009] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:47:50,094] adding document #1240000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:48:14,856] discarding 35763 tokens: [('zehring', 1), ('transfill', 1), ('baadebygger', 1), ('borresens', 1), ('falkum', 1), ('merenkävijät', 1), ('segelsällskap', 1), ('wassén', 1), ('monnalisa', 1), ('plasteramic', 1)]...\n",
      "[2022-09-29 12:48:14,858] keeping 2000000 tokens which were in no less than 0 and no more than 1250000 (=100.0%) documents\n",
      "[2022-09-29 12:48:18,301] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:48:18,359] adding document #1250000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:48:43,568] discarding 35498 tokens: [('agasthyarkoodam', 1), ('barnita', 1), ('chennama', 1), ('cwds', 1), ('govande', 1), ('hardwari', 1), ('harridan#0', 1), ('jasodhara', 1), ('krantijyoti', 1), ('maitrayee', 1)]...\n",
      "[2022-09-29 12:48:43,570] keeping 2000000 tokens which were in no less than 0 and no more than 1260000 (=100.0%) documents\n",
      "[2022-09-29 12:48:47,148] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:48:47,207] adding document #1260000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:49:11,657] discarding 40072 tokens: [('portand', 1), ('wastate', 1), ('berrondo', 1), ('biliardoweb', 1), ('birilli', 1), ('birillo', 1), ('cavazzana', 1), ('cifalà', 1), ('contentitem', 1), ('fibis', 1)]...\n",
      "[2022-09-29 12:49:11,659] keeping 2000000 tokens which were in no less than 0 and no more than 1270000 (=100.0%) documents\n",
      "[2022-09-29 12:49:16,502] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:49:16,587] adding document #1270000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:49:40,823] discarding 36463 tokens: [('aggadists', 1), ('תנחומא', 1), ('ḥuna', 1), ('avaland', 1), ('lawence', 1), ('trittipo', 1), ('claretsmad', 1), ('thallofide', 1), ('althawra', 1), ('letterpackets', 1)]...\n",
      "[2022-09-29 12:49:40,824] keeping 2000000 tokens which were in no less than 0 and no more than 1280000 (=100.0%) documents\n",
      "[2022-09-29 12:49:44,264] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:49:44,323] adding document #1280000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:50:06,588] discarding 42101 tokens: [('gynocritics', 1), ('gynocritiques', 1), ('intersexions', 1), ('aahd', 1), ('bakhaf', 1), ('betelmisny', 1), ('bithibbeni', 1), ('demoaa', 1), ('domoaa', 1), ('eial', 1)]...\n",
      "[2022-09-29 12:50:06,589] keeping 2000000 tokens which were in no less than 0 and no more than 1290000 (=100.0%) documents\n",
      "[2022-09-29 12:50:11,763] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:50:11,849] adding document #1290000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:50:34,367] discarding 31180 tokens: [('nubby', 1), ('pomalift', 1), ('realxs', 1), ('akioki', 1), ('chikataka', 1), ('karenori', 1), ('kiribaragawa', 1), ('kunikuzuri', 1), ('sekiso', 1), ('tagita', 1)]...\n",
      "[2022-09-29 12:50:34,368] keeping 2000000 tokens which were in no less than 0 and no more than 1300000 (=100.0%) documents\n",
      "[2022-09-29 12:50:37,823] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:50:37,881] adding document #1300000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:51:01,169] discarding 35275 tokens: [('aajer', 1), ('antoor', 1), ('anţūr', 1), ('daqwa', 1), ('dirat', 1), ('diret', 1), ('hweijer', 1), ('hweimel', 1), ('khneifes', 1), ('khnēfes', 1)]...\n",
      "[2022-09-29 12:51:01,171] keeping 2000000 tokens which were in no less than 0 and no more than 1310000 (=100.0%) documents\n",
      "[2022-09-29 12:51:04,605] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:51:04,663] adding document #1310000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:51:29,405] discarding 36596 tokens: [('mortty', 1), ('licomedes', 1), ('sammlexotschmett', 1), ('akwete', 1), ('arabade', 1), ('efosa', 1), ('ekassa', 1), ('joromi', 1), ('titibitis', 1), ('bayerslakepark', 1)]...\n",
      "[2022-09-29 12:51:29,406] keeping 2000000 tokens which were in no less than 0 and no more than 1320000 (=100.0%) documents\n",
      "[2022-09-29 12:51:34,260] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:51:34,347] adding document #1320000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:51:56,448] discarding 33652 tokens: [('chippiness', 1), ('sterzings', 1), ('alkenas', 1), ('broadlick', 1), ('depewa', 1), ('eslin', 1), ('flisinger', 1), ('gooddall', 1), ('lotterstein', 1), ('tcimpdis', 1)]...\n",
      "[2022-09-29 12:51:56,450] keeping 2000000 tokens which were in no less than 0 and no more than 1330000 (=100.0%) documents\n",
      "[2022-09-29 12:52:00,079] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:52:00,145] adding document #1330000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:52:24,213] discarding 37955 tokens: [('arawala', 1), ('bindisi', 1), ('kodoom', 1), ('mukjar', 1), ('murahileen', 1), ('guilcagh', 1), ('achwan', 1), ('assaliant', 1), ('galazi', 1), ('kogoya', 1)]...\n",
      "[2022-09-29 12:52:24,215] keeping 2000000 tokens which were in no less than 0 and no more than 1340000 (=100.0%) documents\n",
      "[2022-09-29 12:52:29,290] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:52:29,390] adding document #1340000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:52:53,970] discarding 37637 tokens: [('ashursat', 1), ('denkha', 1), ('haweil', 1), ('hurmiz', 1), ('ismiel', 1), ('malkeh', 1), ('shabow', 1), ('shereh', 1), ('shimoun', 1), ('wearen', 1)]...\n",
      "[2022-09-29 12:52:53,972] keeping 2000000 tokens which were in no less than 0 and no more than 1350000 (=100.0%) documents\n",
      "[2022-09-29 12:52:59,163] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:52:59,251] adding document #1350000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:53:22,331] discarding 36903 tokens: [('dinotopa', 1), ('highnest', 1), ('hoverhead', 1), ('poseidos', 1), ('quetzecoatlus', 1), ('sentiels', 1), ('skybaxes', 1), ('treetown', 1), ('radther', 1), ('zemnick', 1)]...\n",
      "[2022-09-29 12:53:22,333] keeping 2000000 tokens which were in no less than 0 and no more than 1360000 (=100.0%) documents\n",
      "[2022-09-29 12:53:25,778] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:53:25,838] adding document #1360000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:53:51,185] discarding 41052 tokens: [('argeri', 1), ('bastrikova', 1), ('dvornikova', 1), ('kosińska', 1), ('kosminskaya', 1), ('nossenko', 1), ('solonitskaya', 1), ('srael', 1), ('bejen', 1), ('candiroto', 1)]...\n",
      "[2022-09-29 12:53:51,187] keeping 2000000 tokens which were in no less than 0 and no more than 1370000 (=100.0%) documents\n",
      "[2022-09-29 12:53:56,009] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:53:56,096] adding document #1370000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:54:18,738] discarding 34954 tokens: [('akapelra', 1), ('bioneun', 1), ('boyak', 1), ('daemunap', 1), ('dangshineun', 1), ('gamgiyakdeonjigi', 1), ('gwaepgwaepsong', 1), ('gyeonhak', 1), ('haengjingok', 1), ('hoisang', 1)]...\n",
      "[2022-09-29 12:54:18,740] keeping 2000000 tokens which were in no less than 0 and no more than 1380000 (=100.0%) documents\n",
      "[2022-09-29 12:54:22,987] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:54:23,074] adding document #1380000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:54:46,414] discarding 37767 tokens: [('esblygeois', 1), ('chekla', 1), ('farashghan', 1), ('lochhill', 1), ('chagoyán', 1), ('mexplotiation', 1), ('esmanais', 1), ('esmans', 1), ('lalkhanabad', 1), ('قرغه', 1)]...\n",
      "[2022-09-29 12:54:46,416] keeping 2000000 tokens which were in no less than 0 and no more than 1390000 (=100.0%) documents\n",
      "[2022-09-29 12:54:49,792] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:54:49,850] adding document #1390000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:55:13,328] discarding 35236 tokens: [('bukkehåmmårbreen', 1), ('bukkehåmmårtjørna', 1), ('bukkehåmårtjønne', 1), ('høgdebrotet', 1), ('leirungsalpene', 1), ('bratosin', 1), ('popistașu', 1), ('aawf', 1), ('atcw', 1), ('hopwf', 1)]...\n",
      "[2022-09-29 12:55:13,330] keeping 2000000 tokens which were in no less than 0 and no more than 1400000 (=100.0%) documents\n",
      "[2022-09-29 12:55:16,754] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:55:16,813] adding document #1400000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:55:41,938] discarding 36905 tokens: [('ramosii', 1), ('āwikiwiki', 1), ('bluearrow', 1), ('eugander', 1), ('aeberhand', 1), ('aeberhard', 1), ('bermbach', 1), ('biesiadecki', 1), ('birvio', 1), ('bogana', 1)]...\n",
      "[2022-09-29 12:55:41,939] keeping 2000000 tokens which were in no less than 0 and no more than 1410000 (=100.0%) documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 12:55:45,357] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:55:45,419] adding document #1410000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:56:10,824] discarding 33134 tokens: [('laszkiewicz', 1), ('razingar', 1), ('lesert', 1), ('travellersintime', 1), ('baneklubberne', 1), ('fælledklubberne', 1), ('hanved', 1), ('altramerica', 1), ('capitaneada', 1), ('enormes', 1)]...\n",
      "[2022-09-29 12:56:10,826] keeping 2000000 tokens which were in no less than 0 and no more than 1420000 (=100.0%) documents\n",
      "[2022-09-29 12:56:15,673] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:56:15,760] adding document #1420000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:56:39,703] discarding 34058 tokens: [('ネーネーズ', 1), ('メモリアル', 1), ('綾乃', 1), ('imraan', 1), ('hytower', 1), ('avesha', 1), ('hosabettu', 1), ('kudroli', 1), ('kolaya', 1), ('maatri', 1)]...\n",
      "[2022-09-29 12:56:39,705] keeping 2000000 tokens which were in no less than 0 and no more than 1430000 (=100.0%) documents\n",
      "[2022-09-29 12:56:44,876] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:56:44,962] adding document #1430000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:57:09,456] discarding 37070 tokens: [('aarpi', 1), ('aenlle', 1), ('hercenberg', 1), ('mergerstat', 1), ('rechtsanwälte', 1), ('steuerberater', 1), ('endil', 1), ('endill', 1), ('endils', 1), ('eykur', 1)]...\n",
      "[2022-09-29 12:57:09,457] keeping 2000000 tokens which were in no less than 0 and no more than 1440000 (=100.0%) documents\n",
      "[2022-09-29 12:57:14,237] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:57:14,329] adding document #1440000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:57:37,673] discarding 32613 tokens: [('indignants', 1), ('доказательство', 1), ('научное', 1), ('существования', 1), ('abbaye_notre', 1), ('abbayedubec', 1), ('dame_du_bec_r', 1), ('hellouin_eglise_standré_r', 1), ('hellouin_r', 1), ('herlevini', 1)]...\n",
      "[2022-09-29 12:57:37,674] keeping 2000000 tokens which were in no less than 0 and no more than 1450000 (=100.0%) documents\n",
      "[2022-09-29 12:57:41,102] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:57:41,191] adding document #1450000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:58:01,204] discarding 29964 tokens: [('akutōtia', 1), ('erihāpeti', 1), ('fraidman', 1), ('hiahiatia', 1), ('ingoa', 1), ('tianara', 1), ('tīmatanga', 1), ('tūturu', 1), ('whakakōpekatia', 1), ('muckian', 1)]...\n",
      "[2022-09-29 12:58:01,205] keeping 2000000 tokens which were in no less than 0 and no more than 1460000 (=100.0%) documents\n",
      "[2022-09-29 12:58:06,054] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:58:06,142] adding document #1460000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:58:31,407] discarding 37256 tokens: [('trigonion', 1), ('actpl', 1), ('angelkoski', 1), ('savkovic', 1), ('magyarorszag', 1), ('mmcinemas', 1), ('blackstrobe', 1), ('thanstetten', 1), ('bombard#3§', 1), ('raise#16', 1)]...\n",
      "[2022-09-29 12:58:31,409] keeping 2000000 tokens which were in no less than 0 and no more than 1470000 (=100.0%) documents\n",
      "[2022-09-29 12:58:34,813] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:58:34,876] adding document #1470000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:59:00,565] discarding 33570 tokens: [('dreyssig', 1), ('mirotice', 1), ('ltifatı', 1), ('sihâm', 1), ('tahirdir', 1), ('مخلص', 1), ('نفعى', 1), ('shillinglee', 1), ('msacy', 1), ('coadapts', 1)]...\n",
      "[2022-09-29 12:59:00,567] keeping 2000000 tokens which were in no less than 0 and no more than 1480000 (=100.0%) documents\n",
      "[2022-09-29 12:59:05,408] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:59:05,498] adding document #1480000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:59:28,341] discarding 31108 tokens: [('thankoffering', 1), ('belezi', 1), ('dermenzhdieva', 1), ('harjunpää', 1), ('isänmaan', 1), ('kiusantekijät', 1), ('minkki', 1), ('toivot', 1), ('boyster', 1), ('oach', 1)]...\n",
      "[2022-09-29 12:59:28,342] keeping 2000000 tokens which were in no less than 0 and no more than 1490000 (=100.0%) documents\n",
      "[2022-09-29 12:59:31,719] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:59:31,777] adding document #1490000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 12:59:55,440] discarding 38151 tokens: [('stocanais', 1), ('borniana', 1), ('noszky', 1), ('ostenfeldi', 1), ('pertuberculiferum', 1), ('rarinodosa', 1), ('semilaevis', 1), ('sismonda', 1), ('albyfield', 1), ('alisary', 1)]...\n",
      "[2022-09-29 12:59:55,441] keeping 2000000 tokens which were in no less than 0 and no more than 1500000 (=100.0%) documents\n",
      "[2022-09-29 13:00:00,240] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:00:00,328] adding document #1500000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:00:22,962] discarding 33313 tokens: [('opaki', 1), ('pirinoa', 1), ('pukeatua', 1), ('rangikura', 1), ('tairangi', 1), ('tīnui', 1), ('waitohu', 1), ('whakamua', 1), ('whakatupuranga', 1), ('michalovici', 1)]...\n",
      "[2022-09-29 13:00:22,964] keeping 2000000 tokens which were in no less than 0 and no more than 1510000 (=100.0%) documents\n",
      "[2022-09-29 13:00:26,409] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:00:26,469] adding document #1510000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:00:49,433] discarding 31787 tokens: [('sqiggy', 1), ('tidgh', 1), ('bmmc', 1), ('dxrx', 1), ('dolisié', 1), ('othalie', 1), ('wjzi', 1), ('womr', 1), ('avide', 1), ('fastfuel', 1)]...\n",
      "[2022-09-29 13:00:49,435] keeping 2000000 tokens which were in no less than 0 and no more than 1520000 (=100.0%) documents\n",
      "[2022-09-29 13:00:53,090] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:00:53,151] adding document #1520000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:01:14,997] discarding 24133 tokens: [('uricotelism', 1), ('eiffinger', 1), ('idiootocus', 1), ('ootocos', 1), ('phytotelms', 1), ('tuberculed', 1), ('gunungensis', 1), ('mendolong', 1), ('aeate', 1), ('comnavnaw', 1)]...\n",
      "[2022-09-29 13:01:14,999] keeping 2000000 tokens which were in no less than 0 and no more than 1530000 (=100.0%) documents\n",
      "[2022-09-29 13:01:18,423] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:01:18,480] adding document #1530000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:01:43,057] discarding 32066 tokens: [('bezzerwizzer', 1), ('hemelaers', 1), ('kastaar', 1), ('zacharioudakis', 1), ('ceremoney', 1), ('edgeheads', 1), ('edgucational', 1), ('kjetill', 1), ('mamacitas', 1), ('bedersdorf', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:01:43,058] keeping 2000000 tokens which were in no less than 0 and no more than 1540000 (=100.0%) documents\n",
      "[2022-09-29 13:01:47,923] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:01:48,012] adding document #1540000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:02:11,162] discarding 37315 tokens: [('aywar', 1), ('bairoth', 1), ('hyozt', 1), ('kolovorot', 1), ('kubrakh', 1), ('lunarnoyi', 1), ('munruthel', 1), ('myrovozzrieniye', 1), ('naumchuk', 1), ('odalv', 1)]...\n",
      "[2022-09-29 13:02:11,164] keeping 2000000 tokens which were in no less than 0 and no more than 1550000 (=100.0%) documents\n",
      "[2022-09-29 13:02:14,656] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:02:14,717] adding document #1550000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:02:38,413] discarding 38559 tokens: [('shalám', 1), ('sholoim', 1), ('shulam', 1), ('sulmu', 1), ('djezir', 1), ('framqua', 1), ('gería', 1), ('picollos', 1), ('triatlón', 1), ('tytheroygaka', 1)]...\n",
      "[2022-09-29 13:02:38,415] keeping 2000000 tokens which were in no less than 0 and no more than 1560000 (=100.0%) documents\n",
      "[2022-09-29 13:02:43,225] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:02:43,318] adding document #1560000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:03:07,559] discarding 39351 tokens: [('pandetta', 1), ('cingit', 1), ('debuccalises', 1), ('oliviéri', 1), ('saˈpūtum', 1), ('schorta', 1), ('sānum', 1), ('ˈvītam', 1), ('helenchen', 1), ('sondenburg', 1)]...\n",
      "[2022-09-29 13:03:07,561] keeping 2000000 tokens which were in no less than 0 and no more than 1570000 (=100.0%) documents\n",
      "[2022-09-29 13:03:12,411] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:03:12,501] adding document #1570000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:03:36,870] discarding 33130 tokens: [('liwentaal', 1), ('bierstern', 1), ('brauerstern', 1), ('list_of_regular_polytopes_and_compounds', 1), ('prizrencollection', 1), ('sadkona', 1), ('sexagram', 1), ('sixagram', 1), ('two_dimensional_compounds', 1), ('stylistician', 1)]...\n",
      "[2022-09-29 13:03:36,872] keeping 2000000 tokens which were in no less than 0 and no more than 1580000 (=100.0%) documents\n",
      "[2022-09-29 13:03:41,666] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:03:41,754] adding document #1580000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:04:05,835] discarding 36163 tokens: [('nullordumun', 1), ('pomantog', 1), ('sampwshanau', 1), ('wnssikkitteahonat', 1), ('alcohujate', 1), ('arguisuelas', 1), ('arrancacepas', 1), ('barchín', 1), ('beamud', 1), ('belmontejo', 1)]...\n",
      "[2022-09-29 13:04:05,837] keeping 2000000 tokens which were in no less than 0 and no more than 1590000 (=100.0%) documents\n",
      "[2022-09-29 13:04:10,501] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:04:10,590] adding document #1590000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:04:33,990] discarding 30582 tokens: [('cheilophlebium', 1), ('cribrospora', 1), ('disporotrichum', 1), ('gondwanagaricites', 1), ('hemistropharia', 1), ('marasmioid', 1), ('mesophelliopsis', 1), ('palaeoagaracites', 1), ('plicatura', 1), ('plicaturopsidoid', 1)]...\n",
      "[2022-09-29 13:04:33,992] keeping 2000000 tokens which were in no less than 0 and no more than 1600000 (=100.0%) documents\n",
      "[2022-09-29 13:04:39,042] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:04:39,137] adding document #1600000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:05:04,057] discarding 33163 tokens: [('hamîdije', 1), ('hatzfeldhafen', 1), ('heldsbach', 1), ('hudaýbergenow', 1), ('iliatsminda', 1), ('janapolė', 1), ('jumanyýaz', 1), ('karelvi', 1), ('kerbabayeva', 1), ('khaishadar', 1)]...\n",
      "[2022-09-29 13:05:04,059] keeping 2000000 tokens which were in no less than 0 and no more than 1610000 (=100.0%) documents\n",
      "[2022-09-29 13:05:09,173] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:05:09,270] adding document #1610000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:05:33,882] discarding 32787 tokens: [('suasalito', 1), ('viñamarino', 1), ('aarkaadu', 1), ('arkaadu', 1), ('arugarkaadu', 1), ('arugars', 1), ('arungundram', 1), ('aruvur', 1), ('bamadevi', 1), ('darisanapuram', 1)]...\n",
      "[2022-09-29 13:05:33,885] keeping 2000000 tokens which were in no less than 0 and no more than 1620000 (=100.0%) documents\n",
      "[2022-09-29 13:05:39,124] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:05:39,217] adding document #1620000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:06:02,959] discarding 38994 tokens: [('五色雲車駕六龍', 1), ('亞東大帝國', 1), ('亞東開化中華早', 1), ('仙人掌上玉芙蓉', 1), ('億萬年', 1), ('共和五族開堯天', 1), ('努力國民革命', 1), ('卿雲歌', 1), ('卿雲爛兮', 1), ('可愛哉', 1)]...\n",
      "[2022-09-29 13:06:02,961] keeping 2000000 tokens which were in no less than 0 and no more than 1630000 (=100.0%) documents\n",
      "[2022-09-29 13:06:07,807] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:06:07,899] adding document #1630000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:06:30,069] discarding 45240 tokens: [('beihō', 1), ('bukkyōto', 1), ('eryō', 1), ('heikenōkyō', 1), ('ichinei', 1), ('jikyōja', 1), ('kaichos', 1), ('kōkōdō', 1), ('myōwakai', 1), ('nôkyô', 1)]...\n",
      "[2022-09-29 13:06:30,071] keeping 2000000 tokens which were in no less than 0 and no more than 1640000 (=100.0%) documents\n",
      "[2022-09-29 13:06:33,530] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:06:33,593] adding document #1640000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:06:56,743] discarding 27715 tokens: [('hinduistischen', 1), ('isaiat', 1), ('pfandt', 1), ('brokmeyer', 1), ('grubfest', 1), ('hallgeorgetown', 1), ('maskrafter', 1), ('maskrafters', 1), ('shmac', 1), ('amischickse', 1)]...\n",
      "[2022-09-29 13:06:56,745] keeping 2000000 tokens which were in no less than 0 and no more than 1650000 (=100.0%) documents\n",
      "[2022-09-29 13:07:01,734] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:07:01,821] adding document #1650000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:07:26,634] discarding 33457 tokens: [('ʦika', 1), ('ʦipi', 1), ('ʦiⁿd', 1), ('ʦiⁿdi', 1), ('ʦuh', 1), ('ʦuiⁿd', 1), ('ʦuʔ', 1), ('ʦuⁿdi', 1), ('ʦãĩh', 1), ('ˈaːrə', 1)]...\n",
      "[2022-09-29 13:07:26,636] keeping 2000000 tokens which were in no less than 0 and no more than 1660000 (=100.0%) documents\n",
      "[2022-09-29 13:07:31,493] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:07:31,582] adding document #1660000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:07:59,403] discarding 35615 tokens: [('drewscenery', 1), ('drewstudents', 1), ('drewstudentsinuc', 1), ('nascumc', 1), ('outsideclass', 1), ('studentswalking', 1), ('schrieberg', 1), ('canceau', 1), ('canseaux', 1), ('ocbd', 1)]...\n",
      "[2022-09-29 13:07:59,405] keeping 2000000 tokens which were in no less than 0 and no more than 1670000 (=100.0%) documents\n",
      "[2022-09-29 13:08:03,174] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:08:03,264] adding document #1670000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:08:27,048] discarding 37026 tokens: [('witenai', 1), ('acciaiouli', 1), ('murovalle', 1), ('borbadela', 1), ('bulideira', 1), ('catejan', 1), ('engaranho', 1), ('erdevedo', 1), ('expectações', 1), ('meirinho', 1)]...\n",
      "[2022-09-29 13:08:27,049] keeping 2000000 tokens which were in no less than 0 and no more than 1680000 (=100.0%) documents\n",
      "[2022-09-29 13:08:30,542] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:08:30,604] adding document #1680000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:08:53,256] discarding 30724 tokens: [('royaneh', 1), ('swegedaigea', 1), ('sélica', 1), ('thirded', 1), ('workparty', 1), ('addcit', 1), ('demonyo', 1), ('demonyong', 1), ('gumagana', 1), ('gumaru', 1)]...\n",
      "[2022-09-29 13:08:53,257] keeping 2000000 tokens which were in no less than 0 and no more than 1690000 (=100.0%) documents\n",
      "[2022-09-29 13:08:56,724] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:08:56,786] adding document #1690000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:09:21,137] discarding 36042 tokens: [('depsides', 1), ('galloylated', 1), ('hexahydrogallic', 1), ('iontrap', 1), ('trihydroxybenzoic', 1), ('ssnx', 1), ('survivra', 1), ('incrementandreturnx', 1), ('x_copy', 1), ('carsalesbase', 1)]...\n",
      "[2022-09-29 13:09:21,139] keeping 2000000 tokens which were in no less than 0 and no more than 1700000 (=100.0%) documents\n",
      "[2022-09-29 13:09:26,051] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:09:26,142] adding document #1700000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:09:51,595] discarding 48310 tokens: [('hyolbun', 1), ('mangukhoe', 1), ('ollima', 1), ('pulmyouui', 1), ('ssangch', 1), ('vacationa', 1), ('bucoveni', 1), ('hodoba', 1), ('hodopa', 1), ('hodopeni', 1)]...\n",
      "[2022-09-29 13:09:51,596] keeping 2000000 tokens which were in no less than 0 and no more than 1710000 (=100.0%) documents\n",
      "[2022-09-29 13:09:55,691] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:09:55,781] adding document #1710000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:10:19,781] discarding 42594 tokens: [('ˈehvər', 1), ('ˈfmli', 1), ('ˈfrˌfðərz', 1), ('ˈlbər', 1), ('ˈmti', 1), ('ˈnləʤ', 1), ('ˈntɪv', 1), ('ˈnvər', 1), ('ˈnʃənz', 1), ('ˈsŋɪŋ', 1)]...\n",
      "[2022-09-29 13:10:19,783] keeping 2000000 tokens which were in no less than 0 and no more than 1720000 (=100.0%) documents\n",
      "[2022-09-29 13:10:24,618] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:10:24,709] adding document #1720000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:10:48,944] discarding 33249 tokens: [('fatáwá', 1), ('faujdár', 1), ('faujdír', 1), ('fázil', 1), ('gaztteer', 1), ('haásir', 1), ('jágirdár', 1), ('kashitai', 1), ('keshavadeva', 1), ('krtyakalpataru', 1)]...\n",
      "[2022-09-29 13:10:48,946] keeping 2000000 tokens which were in no less than 0 and no more than 1730000 (=100.0%) documents\n",
      "[2022-09-29 13:10:53,858] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:10:53,949] adding document #1730000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:11:19,359] discarding 33967 tokens: [('scottine', 1), ('volbeck', 1), ('fstotal', 1), ('leplante', 1), ('wattard', 1), ('acholshausen', 1), ('arokalja', 1), ('bent#12§', 1), ('bronzerad', 1), ('clonbrinn', 1)]...\n",
      "[2022-09-29 13:11:19,361] keeping 2000000 tokens which were in no less than 0 and no more than 1740000 (=100.0%) documents\n",
      "[2022-09-29 13:11:24,198] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:11:24,289] adding document #1740000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:11:48,488] discarding 32868 tokens: [('oilbold', 1), ('autsa', 1), ('dharyin', 1), ('hrri', 1), ('ibtec', 1), ('niphmhr', 1), ('northmed', 1), ('nztri', 1), ('nzwalmi', 1), ('printsprint', 1)]...\n",
      "[2022-09-29 13:11:48,489] keeping 2000000 tokens which were in no less than 0 and no more than 1750000 (=100.0%) documents\n",
      "[2022-09-29 13:11:51,909] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:11:51,969] adding document #1750000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:12:16,922] discarding 30701 tokens: [('misqāl', 1), ('mithkal', 1), ('mithqaal', 1), ('mithqāl', 1), ('mitkal', 1), ('mitqal', 1), ('nakhud', 1), ('nakhuds', 1), ('nākhud', 1), ('thaqala', 1)]...\n",
      "[2022-09-29 13:12:16,925] keeping 2000000 tokens which were in no less than 0 and no more than 1760000 (=100.0%) documents\n",
      "[2022-09-29 13:12:21,771] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:12:21,860] adding document #1760000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:12:46,979] discarding 33508 tokens: [('apercentage', 1), ('chargapada', 1), ('descandant', 1), ('jambaimalai', 1), ('khorth', 1), ('oldkannada', 1), ('shipely', 1), ('cultropreneurs', 1), ('cotenability', 1), ('cotenable', 1)]...\n",
      "[2022-09-29 13:12:46,981] keeping 2000000 tokens which were in no less than 0 and no more than 1770000 (=100.0%) documents\n",
      "[2022-09-29 13:12:51,586] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:12:51,679] adding document #1770000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:13:18,458] discarding 38707 tokens: [('pasonaria', 1), ('abhicarah', 1), ('adaiyappalam', 1), ('amarnatha', 1), ('anupaya', 1), ('atimargi', 1), ('bhairavapadmavatikalpa', 1), ('bhasmajabala', 1), ('bhavaggana', 1), ('bhuvaneshwara', 1)]...\n",
      "[2022-09-29 13:13:18,459] keeping 2000000 tokens which were in no less than 0 and no more than 1780000 (=100.0%) documents\n",
      "[2022-09-29 13:13:23,391] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:13:23,484] adding document #1780000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:13:52,827] discarding 30415 tokens: [('tagliarino', 1), ('başkanlar', 1), ('galipleri', 1), ('kulüpler', 1), ('vakifgunes', 1), ('üncü', 1), ('şampiyon', 1), ('şampiyonu', 1), ('effervescents', 1), ('kirsebærvin', 1)]...\n",
      "[2022-09-29 13:13:52,829] keeping 2000000 tokens which were in no less than 0 and no more than 1790000 (=100.0%) documents\n",
      "[2022-09-29 13:13:57,670] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:13:57,759] adding document #1790000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:14:31,012] discarding 27503 tokens: [('centralumchurch', 1), ('mcmechan', 1), ('gavand', 1), ('prabhav', 1), ('pemadumcook', 1), ('pintol', 1), ('semjon', 1), ('wdep', 1), ('wleo', 1), ('wzbs', 1)]...\n",
      "[2022-09-29 13:14:31,014] keeping 2000000 tokens which were in no less than 0 and no more than 1800000 (=100.0%) documents\n",
      "[2022-09-29 13:14:35,841] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:14:35,930] adding document #1800000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:14:59,757] discarding 30405 tokens: [('katanyu', 1), ('longco', 1), ('pembunahan', 1), ('prakasit', 1), ('runfa', 1), ('sangstink', 1), ('前路', 1), ('北斗雙雄', 1), ('千王群英會', 1), ('大江南北', 1)]...\n",
      "[2022-09-29 13:14:59,759] keeping 2000000 tokens which were in no less than 0 and no more than 1810000 (=100.0%) documents\n",
      "[2022-09-29 13:15:04,669] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:15:04,759] adding document #1810000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:15:28,505] discarding 31917 tokens: [('acquista', 1), ('criticaldance', 1), ('elephantic', 1), ('fuiava', 1), ('joacob', 1), ('minoi', 1), ('smitch', 1), ('urbanyouthmovement', 1), ('versees', 1), ('artilleristische', 1)]...\n",
      "[2022-09-29 13:15:28,507] keeping 2000000 tokens which were in no less than 0 and no more than 1820000 (=100.0%) documents\n",
      "[2022-09-29 13:15:33,348] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:15:33,439] adding document #1820000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:15:56,641] discarding 34964 tokens: [('furnariides', 1), ('tyrannoidea', 1), ('cityrailway', 1), ('oecdmetropolitan', 1), ('aksela', 1), ('kaitera', 1), ('kanttila', 1), ('mannerkoski', 1), ('söyrinki', 1), ('besprochenen', 1)]...\n",
      "[2022-09-29 13:15:56,643] keeping 2000000 tokens which were in no less than 0 and no more than 1830000 (=100.0%) documents\n",
      "[2022-09-29 13:16:01,536] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:16:01,626] adding document #1830000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:16:26,780] discarding 30897 tokens: [('dschauzi', 1), ('statet', 1), ('fowlar', 1), ('nwmsa', 1), ('wvietnam', 1), ('acupunturist', 1), ('afmy', 1), ('azizy', 1), ('fpukm', 1), ('hafizzah', 1)]...\n",
      "[2022-09-29 13:16:26,782] keeping 2000000 tokens which were in no less than 0 and no more than 1840000 (=100.0%) documents\n",
      "[2022-09-29 13:16:31,653] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:16:31,744] adding document #1840000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:16:55,994] discarding 29493 tokens: [('abdulhamidov', 1), ('firetrautwig', 1), ('maestrini', 1), ('masback', 1), ('nbcfail', 1), ('tusup', 1), ('codeminion', 1), ('phantasmat', 1), ('pteroglider', 1), ('stoneloops', 1)]...\n",
      "[2022-09-29 13:16:55,996] keeping 2000000 tokens which were in no less than 0 and no more than 1850000 (=100.0%) documents\n",
      "[2022-09-29 13:17:01,166] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:17:01,255] adding document #1850000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:17:23,622] discarding 31291 tokens: [('eleventhhourfacts', 1), ('simanga', 1), ('lilmalayin', 1), ('meşahirî', 1), ('mülâzım', 1), ('silêmani', 1), ('subayı', 1), ('tarîxî', 1), ('zerekly', 1), ('movieola', 1)]...\n",
      "[2022-09-29 13:17:23,624] keeping 2000000 tokens which were in no less than 0 and no more than 1860000 (=100.0%) documents\n",
      "[2022-09-29 13:17:27,059] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:17:27,120] adding document #1860000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:17:50,530] discarding 31646 tokens: [('kevarim', 1), ('mezhibuz', 1), ('ohalei', 1), ('bobbarr', 1), ('restructered', 1), ('aaaaaaaaaabc', 1), ('aaaaaaaaaabcd', 1), ('aaaaaab', 1), ('aaaaaabc', 1), ('aaabc', 1)]...\n",
      "[2022-09-29 13:17:50,531] keeping 2000000 tokens which were in no less than 0 and no more than 1870000 (=100.0%) documents\n",
      "[2022-09-29 13:17:55,028] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:17:55,090] adding document #1870000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:18:20,853] discarding 32593 tokens: [('arogyam', 1), ('kadiyam', 1), ('parvathagiri', 1), ('deletang', 1), ('mizera', 1), ('chirumarthy', 1), ('madgulapally', 1), ('nammanna', 1), ('nshankar', 1), ('ramulayya', 1)]...\n",
      "[2022-09-29 13:18:20,855] keeping 2000000 tokens which were in no less than 0 and no more than 1880000 (=100.0%) documents\n",
      "[2022-09-29 13:18:25,745] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:18:25,837] adding document #1880000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:18:50,365] discarding 30692 tokens: [('acquilateralis', 1), ('anapella', 1), ('bellianum', 1), ('bernayi', 1), ('brombachensis', 1), ('camaronis', 1), ('catilliformis', 1), ('couttsi', 1), ('crassitesta', 1), ('cycladea', 1)]...\n",
      "[2022-09-29 13:18:50,367] keeping 2000000 tokens which were in no less than 0 and no more than 1890000 (=100.0%) documents\n",
      "[2022-09-29 13:18:53,850] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:18:53,912] adding document #1890000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:19:19,087] discarding 34362 tokens: [('fabyl', 1), ('gyngemyn', 1), ('meremayd', 1), ('pagaentries', 1), ('philosophicals', 1), ('powlysgate', 1), ('wythorne', 1), ('collatinos', 1), ('etnomatemática', 1), ('khipukuna', 1)]...\n",
      "[2022-09-29 13:19:19,089] keeping 2000000 tokens which were in no less than 0 and no more than 1900000 (=100.0%) documents\n",
      "[2022-09-29 13:19:23,989] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:19:24,081] adding document #1900000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:19:48,860] discarding 31552 tokens: [('badiana', 1), ('bhagowal', 1), ('khakanwali', 1), ('landakai', 1), ('nahaqqi', 1), ('phillaura', 1), ('burollet', 1), ('fonquernie', 1), ('néto', 1), ('reoven', 1)]...\n",
      "[2022-09-29 13:19:48,862] keeping 2000000 tokens which were in no less than 0 and no more than 1910000 (=100.0%) documents\n",
      "[2022-09-29 13:19:52,337] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:19:52,399] adding document #1910000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:20:14,300] discarding 31348 tokens: [('noywech', 1), ('asharkata', 1), ('asharkota', 1), ('palakhal', 1), ('prodhania', 1), ('singua', 1), ('taguria', 1), ('smeir', 1), ('tirchett', 1), ('almanzi', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:20:14,301] keeping 2000000 tokens which were in no less than 0 and no more than 1920000 (=100.0%) documents\n",
      "[2022-09-29 13:20:17,715] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:20:17,776] adding document #1920000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:20:43,581] discarding 34665 tokens: [('天狗倒し', 1), ('天狗囃子', 1), ('天狗太鼓', 1), ('天狗田', 1), ('天狗礫', 1), ('天狗笑い', 1), ('天狗谷', 1), ('山神楽', 1), ('狗賓の住処', 1), ('baschetto', 1)]...\n",
      "[2022-09-29 13:20:43,583] keeping 2000000 tokens which were in no less than 0 and no more than 1930000 (=100.0%) documents\n",
      "[2022-09-29 13:20:47,975] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:20:48,066] adding document #1930000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:21:11,227] discarding 27503 tokens: [('aquileoecheverria', 1), ('concherías', 1), ('lacarretica', 1), ('lectorias', 1), ('mcjdcr', 1), ('desplazada', 1), ('prodere', 1), ('refugiada', 1), ('repatriada', 1), ('afrodescendant', 1)]...\n",
      "[2022-09-29 13:21:11,230] keeping 2000000 tokens which were in no less than 0 and no more than 1940000 (=100.0%) documents\n",
      "[2022-09-29 13:21:16,474] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:21:16,565] adding document #1940000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:21:44,333] discarding 34879 tokens: [('hoidn', 1), ('akrm', 1), ('alkt', 1), ('bawt', 1), ('bsfx', 1), ('caterparrott', 1), ('ccyh', 1), ('cgbe', 1), ('clcy', 1), ('ctlc', 1)]...\n",
      "[2022-09-29 13:21:44,336] keeping 2000000 tokens which were in no less than 0 and no more than 1950000 (=100.0%) documents\n",
      "[2022-09-29 13:21:49,686] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:21:49,778] adding document #1950000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:22:18,154] discarding 32852 tokens: [('maigold', 1), ('spigold', 1), ('intereflection', 1), ('macistian', 1), ('macistius', 1), ('makistios', 1), ('μάκιστος', 1), ('μακίστιος', 1), ('anteposterior', 1), ('extramolar', 1)]...\n",
      "[2022-09-29 13:22:18,156] keeping 2000000 tokens which were in no less than 0 and no more than 1960000 (=100.0%) documents\n",
      "[2022-09-29 13:22:21,611] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:22:21,673] adding document #1960000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:22:47,692] discarding 33379 tokens: [('夹镜鸣琴', 1), ('如意桥', 1), ('杏花春馆', 1), ('杏花春馆遗址', 1), ('正觉寺', 1), ('福海', 1), ('西洋楼', 1), ('西洋樓', 1), ('黄花阵', 1), ('kosfost', 1)]...\n",
      "[2022-09-29 13:22:47,695] keeping 2000000 tokens which were in no less than 0 and no more than 1970000 (=100.0%) documents\n",
      "[2022-09-29 13:22:52,998] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:22:53,090] adding document #1970000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:23:19,605] discarding 41396 tokens: [('beć', 1), ('blinić', 1), ('događaje', 1), ('kesterčanek', 1), ('michelangelom', 1), ('srđo', 1), ('androuxii', 1), ('papastillii', 1), ('foreslopes', 1), ('loveykins', 1)]...\n",
      "[2022-09-29 13:23:19,606] keeping 2000000 tokens which were in no less than 0 and no more than 1980000 (=100.0%) documents\n",
      "[2022-09-29 13:23:24,477] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:23:24,570] adding document #1980000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:23:51,842] discarding 34881 tokens: [('márcadópuszta', 1), ('mónosokor', 1), ('nagyecsér', 1), ('peranera', 1), ('pernui', 1), ('picões', 1), ('schwirzenbeck', 1), ('somogyszentimre', 1), ('tacketorp', 1), ('tharmida', 1)]...\n",
      "[2022-09-29 13:23:51,844] keeping 2000000 tokens which were in no less than 0 and no more than 1990000 (=100.0%) documents\n",
      "[2022-09-29 13:23:57,037] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:23:57,129] adding document #1990000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:24:25,548] discarding 38318 tokens: [('eretmo', 1), ('dunavore', 1), ('haimheirgin', 1), ('maidín', 1), ('mbéara', 1), ('piorko', 1), ('prestwych', 1), ('altiplanities', 1), ('brendiae', 1), ('cytogeographic', 1)]...\n",
      "[2022-09-29 13:24:25,550] keeping 2000000 tokens which were in no less than 0 and no more than 2000000 (=100.0%) documents\n",
      "[2022-09-29 13:24:29,060] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:24:29,123] adding document #2000000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:24:55,343] discarding 32825 tokens: [('platyacanthum', 1), ('sapjegin', 1), ('ceratostratiotes', 1), ('donlesia', 1), ('counterstereotypes', 1), ('ahmoudi', 1), ('alrumaisa', 1), ('antibaby', 1), ('bannot', 1), ('celebrationin', 1)]...\n",
      "[2022-09-29 13:24:55,345] keeping 2000000 tokens which were in no less than 0 and no more than 2010000 (=100.0%) documents\n",
      "[2022-09-29 13:24:58,808] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:24:58,871] adding document #2010000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:25:22,795] discarding 31901 tokens: [('serchinger', 1), ('affairmackenzie', 1), ('lesslies', 1), ('ampolletta', 1), ('arumin', 1), ('baluardo', 1), ('canaviglia', 1), ('cantagaliina', 1), ('cogorano', 1), ('fossoreale', 1)]...\n",
      "[2022-09-29 13:25:22,796] keeping 2000000 tokens which were in no less than 0 and no more than 2020000 (=100.0%) documents\n",
      "[2022-09-29 13:25:26,323] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:25:26,386] adding document #2020000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:25:49,794] discarding 32624 tokens: [('patfleet', 1), ('boulevard_of_broken_rings', 1), ('circumtrinary', 1), ('debrisdisks', 1), ('hubblespacetelescope', 1), ('bstrozzicristof', 1), ('christóforos', 1), ('confías', 1), ('cynamolgi', 1), ('davenport#0§', 1)]...\n",
      "[2022-09-29 13:25:49,796] keeping 2000000 tokens which were in no less than 0 and no more than 2030000 (=100.0%) documents\n",
      "[2022-09-29 13:25:53,684] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:25:53,777] adding document #2030000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:26:16,644] discarding 33422 tokens: [('attilianus', 1), ('auctillus', 1), ('audaios', 1), ('aurunculeianus', 1), ('auxientius', 1), ('avitillus', 1), ('bamballio', 1), ('banquerius', 1), ('bellicianus', 1), ('bitucus', 1)]...\n",
      "[2022-09-29 13:26:16,645] keeping 2000000 tokens which were in no less than 0 and no more than 2040000 (=100.0%) documents\n",
      "[2022-09-29 13:26:20,118] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:26:20,180] adding document #2040000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:26:45,178] discarding 35927 tokens: [('lethi', 1), ('mamarce', 1), ('mamerca', 1), ('publilii', 1), ('puplie', 1), ('ranvthu', 1), ('ravnthu', 1), ('ravntzu', 1), ('thebris', 1), ('uchtave', 1)]...\n",
      "[2022-09-29 13:26:45,180] keeping 2000000 tokens which were in no less than 0 and no more than 2050000 (=100.0%) documents\n",
      "[2022-09-29 13:26:50,101] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:26:50,195] adding document #2050000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:27:13,977] discarding 34621 tokens: [('òwō', 1), ('òɖè', 1), ('òɖě', 1), ('óblún', 1), ('ólè', 1), ('óné', 1), ('óɡlò', 1), ('õdu', 1), ('õdʒo', 1), ('õglɔ', 1)]...\n",
      "[2022-09-29 13:27:13,979] keeping 2000000 tokens which were in no less than 0 and no more than 2060000 (=100.0%) documents\n",
      "[2022-09-29 13:27:18,901] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:27:18,994] adding document #2060000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:27:43,120] discarding 36043 tokens: [('feigenstein', 1), ('fergle', 1), ('arjolle', 1), ('indellicati', 1), ('liponti', 1), ('pribidrag', 1), ('primativus', 1), ('zeinfandall', 1), ('zenfendal', 1), ('zinfandal', 1)]...\n",
      "[2022-09-29 13:27:43,122] keeping 2000000 tokens which were in no less than 0 and no more than 2070000 (=100.0%) documents\n",
      "[2022-09-29 13:27:48,016] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:27:48,110] adding document #2070000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:28:13,836] discarding 31976 tokens: [('hannu_takkula_remembrance_forum', 1), ('johannesvirolainen', 1), ('mikkoalatalo', 1), ('olli_rehn_by_moritz_kosinsky_', 1), ('seppokaariainenoffice', 1), ('sti_kallio', 1), ('vehkapera', 1), ('slipstrike', 1), ('wehan', 1), ('fluoroethan', 1)]...\n",
      "[2022-09-29 13:28:13,838] keeping 2000000 tokens which were in no less than 0 and no more than 2080000 (=100.0%) documents\n",
      "[2022-09-29 13:28:18,756] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:28:18,849] adding document #2080000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:28:44,016] discarding 35332 tokens: [('hexanchids', 1), ('mcmurdodontidae', 1), ('orthacodontidae', 1), ('honselect', 1), ('khresmoi', 1), ('provisu', 1), ('santeromande', 1), ('statistiquement', 1), ('aegodontia', 1), ('aegodonts', 1)]...\n",
      "[2022-09-29 13:28:44,017] keeping 2000000 tokens which were in no less than 0 and no more than 2090000 (=100.0%) documents\n",
      "[2022-09-29 13:28:47,642] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:28:47,705] adding document #2090000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:29:13,645] discarding 40464 tokens: [('gikauxszu', 1), ('gmczsput', 1), ('gyfxhikhxrwtjk', 1), ('gzxybne', 1), ('haxwbmx', 1), ('hfuee', 1), ('hrlexp', 1), ('idxwb', 1), ('ieaofbskm', 1), ('ihue', 1)]...\n",
      "[2022-09-29 13:29:13,647] keeping 2000000 tokens which were in no less than 0 and no more than 2100000 (=100.0%) documents\n",
      "[2022-09-29 13:29:18,673] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:29:18,767] adding document #2100000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:29:44,541] discarding 34725 tokens: [('noriger', 1), ('aelerus', 1), ('egkyklios', 1), ('exuendus', 1), ('nunquamque', 1), ('azamatt', 1), ('baerenmarken', 1), ('bearbara', 1), ('bussemy', 1), ('chromabear', 1)]...\n",
      "[2022-09-29 13:29:44,543] keeping 2000000 tokens which were in no less than 0 and no more than 2110000 (=100.0%) documents\n",
      "[2022-09-29 13:29:49,485] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:29:49,577] adding document #2110000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:30:12,279] discarding 37953 tokens: [('arpaja', 1), ('massanello', 1), ('caterinas', 1), ('charakteristichen', 1), ('florentinischen', 1), ('personlichen', 1), ('sincrone', 1), ('tabarrini', 1), ('guerazzi', 1), ('rafius', 1)]...\n",
      "[2022-09-29 13:30:12,281] keeping 2000000 tokens which were in no less than 0 and no more than 2120000 (=100.0%) documents\n",
      "[2022-09-29 13:30:15,791] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:30:15,854] adding document #2120000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:30:38,085] discarding 27038 tokens: [('albinervus', 1), ('amblyosepalus', 1), ('anisotrichos', 1), ('chiapasanus', 1), ('cibellii', 1), ('galactoides', 1), ('gladiolatus', 1), ('pachyrrhizoides', 1), ('persistentus', 1), ('phasēlus', 1)]...\n",
      "[2022-09-29 13:30:38,086] keeping 2000000 tokens which were in no less than 0 and no more than 2130000 (=100.0%) documents\n",
      "[2022-09-29 13:30:43,028] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:30:43,099] adding document #2130000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:31:07,370] discarding 35032 tokens: [('norkroos', 1), ('põdramägi', 1), ('tammeoks', 1), ('viiralt', 1), ('kazuura', 1), ('arussaare', 1), ('aanandan', 1), ('abaraadham', 1), ('avutaaru', 1), ('ellaikkodu', 1)]...\n",
      "[2022-09-29 13:31:07,372] keeping 2000000 tokens which were in no less than 0 and no more than 2140000 (=100.0%) documents\n",
      "[2022-09-29 13:31:12,282] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:31:12,374] adding document #2140000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:31:35,459] discarding 45846 tokens: [('donnenfeld', 1), ('kmmy', 1), ('rocklaholics', 1), ('jhatkas', 1), ('latkas', 1), ('oorja', 1), ('patiyala', 1), ('rodies', 1), ('alceda', 1), ('blomar', 1)]...\n",
      "[2022-09-29 13:31:35,461] keeping 2000000 tokens which were in no less than 0 and no more than 2150000 (=100.0%) documents\n",
      "[2022-09-29 13:31:40,399] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:31:40,495] adding document #2150000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:32:05,862] discarding 40607 tokens: [('biaiñ', 1), ('chaiklin', 1), ('datanews', 1), ('huybregts', 1), ('ilusionistas', 1), ('irreverentes', 1), ('moodliar', 1), ('peshawa', 1), ('riny', 1), ('uriagereka', 1)]...\n",
      "[2022-09-29 13:32:05,864] keeping 2000000 tokens which were in no less than 0 and no more than 2160000 (=100.0%) documents\n",
      "[2022-09-29 13:32:10,758] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:32:10,852] adding document #2160000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:32:35,239] discarding 32509 tokens: [('estw', 1), ('gartenbahn', 1), ('niederholz', 1), ('pendelzug', 1), ('schwarzwaldstraße', 1), ('todtnauerli', 1), ('tüllinger', 1), ('wiesenthalbahn', 1), ('cnbr', 1), ('khomenei', 1)]...\n",
      "[2022-09-29 13:32:35,242] keeping 2000000 tokens which were in no less than 0 and no more than 2170000 (=100.0%) documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:32:40,149] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:32:40,242] adding document #2170000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:33:04,044] discarding 38636 tokens: [('jayalakshmy', 1), ('mareze', 1), ('nickitas', 1), ('boumakhrouta', 1), ('beddou', 1), ('bolodou', 1), ('faindou', 1), ('gbandou', 1), ('koleadou', 1), ('kongoma', 1)]...\n",
      "[2022-09-29 13:33:04,046] keeping 2000000 tokens which were in no less than 0 and no more than 2180000 (=100.0%) documents\n",
      "[2022-09-29 13:33:08,909] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:33:09,003] adding document #2180000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:33:32,600] discarding 32893 tokens: [('brandian', 1), ('amstelveense', 1), ('bachratík', 1), ('bebjak', 1), ('benkovský', 1), ('chladnokrvne', 1), ('dezorz', 1), ('gallovičových', 1), ('jedľovský', 1), ('krekovič', 1)]...\n",
      "[2022-09-29 13:33:32,601] keeping 2000000 tokens which were in no less than 0 and no more than 2190000 (=100.0%) documents\n",
      "[2022-09-29 13:33:37,522] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:33:37,616] adding document #2190000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:34:00,115] discarding 29321 tokens: [('tailhouse', 1), ('kutuh', 1), ('ungasan', 1), ('malmon', 1), ('packing#10', 1), ('packing#10§', 1), ('elementarbücher', 1), ('feldges', 1), ('manderlee', 1), ('metzlersche', 1)]...\n",
      "[2022-09-29 13:34:00,117] keeping 2000000 tokens which were in no less than 0 and no more than 2200000 (=100.0%) documents\n",
      "[2022-09-29 13:34:04,968] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:34:05,060] adding document #2200000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:34:29,062] discarding 31459 tokens: [('broliquier', 1), ('montrochet', 1), ('manswers', 1), ('pushtov', 1), ('dhrami', 1), ('sourcesbut', 1), ('droeven', 1), ('rigorose', 1), ('douel', 1), ('drumcairne', 1)]...\n",
      "[2022-09-29 13:34:29,064] keeping 2000000 tokens which were in no less than 0 and no more than 2210000 (=100.0%) documents\n",
      "[2022-09-29 13:34:33,936] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:34:34,029] adding document #2210000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:34:58,970] discarding 31199 tokens: [('alcort', 1), ('harborite', 1), ('heyniger', 1), ('hitch#6§', 1), ('ausbatt', 1), ('maubasa', 1), ('sftc', 1), ('hics', 1), ('privman', 1), ('covermymeds', 1)]...\n",
      "[2022-09-29 13:34:58,972] keeping 2000000 tokens which were in no less than 0 and no more than 2220000 (=100.0%) documents\n",
      "[2022-09-29 13:35:04,178] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:35:04,271] adding document #2220000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:35:37,475] discarding 38406 tokens: [('starspace', 1), ('realmusic', 1), ('борúсович', 1), ('кóршунов', 1), ('николáй', 1), ('fltplan', 1), ('bellacasa', 1), ('cirugeda', 1), ('rivadulla', 1), ('landsbergen', 1)]...\n",
      "[2022-09-29 13:35:37,477] keeping 2000000 tokens which were in no less than 0 and no more than 2230000 (=100.0%) documents\n",
      "[2022-09-29 13:35:42,365] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:35:42,459] adding document #2230000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:36:08,728] discarding 35218 tokens: [('siegfreid', 1), ('grosserode', 1), ('kriegshauser', 1), ('yonally', 1), ('fehlauer', 1), ('krankenhauses', 1), ('landesklinik', 1), ('pochampalli', 1), ('belltel', 1), ('trailridge', 1)]...\n",
      "[2022-09-29 13:36:08,730] keeping 2000000 tokens which were in no less than 0 and no more than 2240000 (=100.0%) documents\n",
      "[2022-09-29 13:36:14,064] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:36:14,159] adding document #2240000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:36:39,498] discarding 48170 tokens: [('thalothil', 1), ('uqms', 1), ('beizaks', 1), ('cimoška', 1), ('grīnvalds', 1), ('hermīne', 1), ('kidnappees', 1), ('krieviņš', 1), ('macītis', 1), ('maslovs', 1)]...\n",
      "[2022-09-29 13:36:39,501] keeping 2000000 tokens which were in no less than 0 and no more than 2250000 (=100.0%) documents\n",
      "[2022-09-29 13:36:44,452] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:36:44,549] adding document #2250000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:37:10,107] discarding 38687 tokens: [('assuer', 1), ('krontal', 1), ('morakeb', 1), ('northon', 1), ('fortuanato', 1), ('garibaldia', 1), ('timoniere', 1), ('gambardelli', 1), ('lorryload', 1), ('panaiota', 1)]...\n",
      "[2022-09-29 13:37:10,108] keeping 2000000 tokens which were in no less than 0 and no more than 2260000 (=100.0%) documents\n",
      "[2022-09-29 13:37:14,687] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:37:14,781] adding document #2260000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:37:39,692] discarding 36564 tokens: [('cincpacrepphil', 1), ('comnavphil', 1), ('heracleo', 1), ('alludin', 1), ('cyristal', 1), ('nawh', 1), ('shtting', 1), ('bipinchandra', 1), ('autofauteuil', 1), ('autoped', 1)]...\n",
      "[2022-09-29 13:37:39,694] keeping 2000000 tokens which were in no less than 0 and no more than 2270000 (=100.0%) documents\n",
      "[2022-09-29 13:37:43,316] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:37:43,381] adding document #2270000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:38:07,495] discarding 40706 tokens: [('బయ', 1), ('ಬಯ', 1), ('badade', 1), ('basavalingappa', 1), ('govindaswami', 1), ('hiwale', 1), ('hugar', 1), ('kunhikannan', 1), ('nayanthahalli', 1), ('somasekharan', 1)]...\n",
      "[2022-09-29 13:38:07,497] keeping 2000000 tokens which were in no less than 0 and no more than 2280000 (=100.0%) documents\n",
      "[2022-09-29 13:38:11,020] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:38:11,086] adding document #2280000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:38:36,177] discarding 36839 tokens: [('banków', 1), ('budnikowski', 1), ('dyrektorów', 1), ('finansowych', 1), ('finexa', 1), ('goliszewska', 1), ('groszek', 1), ('kornasiewicz', 1), ('rozłucki', 1), ('będziesz', 1)]...\n",
      "[2022-09-29 13:38:36,178] keeping 2000000 tokens which were in no less than 0 and no more than 2290000 (=100.0%) documents\n",
      "[2022-09-29 13:38:40,752] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:38:40,846] adding document #2290000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:39:06,315] discarding 34916 tokens: [('biuso', 1), ('trattore', 1), ('kariaotahi', 1), ('kariotahi', 1), ('maioro', 1), ('powercraft', 1), ('wiscontin', 1), ('bacatha', 1), ('celebratum', 1), ('esbas', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:39:06,317] keeping 2000000 tokens which were in no less than 0 and no more than 2300000 (=100.0%) documents\n",
      "[2022-09-29 13:39:11,234] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:39:11,329] adding document #2300000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:39:35,096] discarding 34425 tokens: [('squooky', 1), ('zogcasts', 1), ('ankeren', 1), ('donnenfeld', 1), ('doufikar', 1), ('heskamp', 1), ('takak', 1), ('zalai', 1), ('gallerher', 1), ('glenkirk', 1)]...\n",
      "[2022-09-29 13:39:35,097] keeping 2000000 tokens which were in no less than 0 and no more than 2310000 (=100.0%) documents\n",
      "[2022-09-29 13:39:38,553] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:39:38,617] adding document #2310000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:40:02,400] discarding 36656 tokens: [('balashow', 1), ('atombooks', 1), ('cvbc', 1), ('laungde', 1), ('launggyin', 1), ('linlu', 1), ('minking', 1), ('mondin', 1), ('myaukchun', 1), ('natbuzut', 1)]...\n",
      "[2022-09-29 13:40:02,402] keeping 2000000 tokens which were in no less than 0 and no more than 2320000 (=100.0%) documents\n",
      "[2022-09-29 13:40:05,975] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:40:06,040] adding document #2320000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:40:30,341] discarding 38770 tokens: [('actionline', 1), ('popehat', 1), ('vegasinc', 1), ('burquier', 1), ('cozbinov', 1), ('gengel', 1), ('kadhe', 1), ('kralert', 1), ('truyol', 1), ('zaitcev', 1)]...\n",
      "[2022-09-29 13:40:30,341] keeping 2000000 tokens which were in no less than 0 and no more than 2330000 (=100.0%) documents\n",
      "[2022-09-29 13:40:33,825] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:40:33,890] adding document #2330000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:40:57,921] discarding 37628 tokens: [('cartobibliographer', 1), ('czoering', 1), ('fatout', 1), ('luchsenstein', 1), ('mcgechaen', 1), ('weareyoungmoney', 1), ('antaramian', 1), ('adimchinobe', 1), ('antigirl', 1), ('biewald', 1)]...\n",
      "[2022-09-29 13:40:57,924] keeping 2000000 tokens which were in no less than 0 and no more than 2340000 (=100.0%) documents\n",
      "[2022-09-29 13:41:02,518] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:41:02,583] adding document #2340000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:41:28,777] discarding 36491 tokens: [('reitmaier', 1), ('vamouti', 1), ('meskhishivili', 1), ('interspilata', 1), ('tricinctaria', 1), ('sheikhpur', 1), ('heinleinian', 1), ('machiavelle', 1), ('stellatifolium', 1), ('副食大楼', 1)]...\n",
      "[2022-09-29 13:41:28,779] keeping 2000000 tokens which were in no less than 0 and no more than 2350000 (=100.0%) documents\n",
      "[2022-09-29 13:41:32,357] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:41:32,423] adding document #2350000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:41:58,165] discarding 32193 tokens: [('adlocative', 1), ('budad', 1), ('budugh', 1), ('cır', 1), ('digitorient', 1), ('introflexion', 1), ('introflexionbudugh', 1), ('lemér', 1), ('narrative_tense', 1), ('nonhumanplural', 1)]...\n",
      "[2022-09-29 13:41:58,166] keeping 2000000 tokens which were in no less than 0 and no more than 2360000 (=100.0%) documents\n",
      "[2022-09-29 13:42:01,644] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:42:01,708] adding document #2360000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:42:25,090] discarding 30343 tokens: [('palamattathu', 1), ('palomattathu', 1), ('reghukumar', 1), ('sathyanath', 1), ('vimmy', 1), ('prothallia', 1), ('craskie', 1), ('tuill', 1), ('gaboff', 1), ('dykaar', 1)]...\n",
      "[2022-09-29 13:42:25,092] keeping 2000000 tokens which were in no less than 0 and no more than 2370000 (=100.0%) documents\n",
      "[2022-09-29 13:42:28,621] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:42:28,686] adding document #2370000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:42:53,299] discarding 31976 tokens: [('bantigny', 1), ('bazuel', 1), ('bermerain', 1), ('bermeries', 1), ('beuvrages', 1), ('billety', 1), ('cauroir', 1), ('caëstre', 1), ('chéreng', 1), ('crènelée', 1)]...\n",
      "[2022-09-29 13:42:53,301] keeping 2000000 tokens which were in no less than 0 and no more than 2380000 (=100.0%) documents\n",
      "[2022-09-29 13:42:57,969] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:42:58,034] adding document #2380000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:43:24,591] discarding 33553 tokens: [('高燮诗学思想与诗歌创作初探', 1), ('高燮集', 1), ('bioctahedron', 1), ('bifurcationand', 1), ('amwmotors', 1), ('osima', 1), ('北監', 1), ('chaklakal', 1), ('chhitokulam', 1), ('ranitalab', 1)]...\n",
      "[2022-09-29 13:43:24,592] keeping 2000000 tokens which were in no less than 0 and no more than 2390000 (=100.0%) documents\n",
      "[2022-09-29 13:43:28,219] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:43:28,284] adding document #2390000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:43:54,239] discarding 36125 tokens: [('dcam', 1), ('dlrc', 1), ('hesselgesser', 1), ('ixlmath', 1), ('lithuaniancommonwealth', 1), ('peuribus', 1), ('prefed', 1), ('tropenell', 1), ('tagdulang', 1), ('clintycracken', 1)]...\n",
      "[2022-09-29 13:43:54,240] keeping 2000000 tokens which were in no less than 0 and no more than 2400000 (=100.0%) documents\n",
      "[2022-09-29 13:43:57,817] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:43:57,883] adding document #2400000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:44:22,023] discarding 34737 tokens: [('paquer', 1), ('prederi', 1), ('rivalue', 1), ('steerio', 1), ('youmeo', 1), ('fugiente', 1), ('spernit', 1), ('havebut', 1), ('hippograf', 1), ('isoskelés', 1)]...\n",
      "[2022-09-29 13:44:22,025] keeping 2000000 tokens which were in no less than 0 and no more than 2410000 (=100.0%) documents\n",
      "[2022-09-29 13:44:25,551] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:44:25,615] adding document #2410000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:44:48,794] discarding 35846 tokens: [('areatal', 1), ('haircost', 1), ('hfscs', 1), ('monolocularis', 1), ('seborrheica', 1), ('wigsthose', 1), ('shockmore', 1), ('rrcnca', 1), ('sidetrail', 1), ('clippingfilled', 1)]...\n",
      "[2022-09-29 13:44:48,796] keeping 2000000 tokens which were in no less than 0 and no more than 2420000 (=100.0%) documents\n",
      "[2022-09-29 13:44:52,290] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:44:52,355] adding document #2420000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:45:18,343] discarding 36988 tokens: [('cbmsweb', 1), ('epadel', 1), ('sigmaas', 1), ('alloed', 1), ('breikanz', 1), ('colonieros', 1), ('gabante', 1), ('jokili', 1), ('malverin', 1), ('tiátaro', 1)]...\n",
      "[2022-09-29 13:45:18,345] keeping 2000000 tokens which were in no less than 0 and no more than 2430000 (=100.0%) documents\n",
      "[2022-09-29 13:45:23,403] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:45:23,501] adding document #2430000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:45:46,682] discarding 37868 tokens: [('ruege', 1), ('snsbc', 1), ('turnamic', 1), ('kaseasbeh', 1), ('pourik', 1), ('qashoo', 1), ('בנסיעה', 1), ('בשלב', 1), ('החיילים', 1), ('החלטנו', 1)]...\n",
      "[2022-09-29 13:45:46,683] keeping 2000000 tokens which were in no less than 0 and no more than 2440000 (=100.0%) documents\n",
      "[2022-09-29 13:45:50,428] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:45:50,503] adding document #2440000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:46:14,322] discarding 31666 tokens: [('㥃', 1), ('万門', 1), ('偉大한', 1), ('歲年', 1), ('皇上萬歲', 1), ('皇帝萬歲', 1), ('自由万歳', 1), ('越南萬歲', 1), ('金日成將軍', 1), ('門南', 1)]...\n",
      "[2022-09-29 13:46:14,324] keeping 2000000 tokens which were in no less than 0 and no more than 2450000 (=100.0%) documents\n",
      "[2022-09-29 13:46:19,275] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:46:19,369] adding document #2450000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:46:41,709] discarding 29778 tokens: [('道円法親王', 1), ('邦仁王', 1), ('静仁法親王', 1), ('emryakuji', 1), ('gyōetsu', 1), ('himehōshi', 1), ('kamegiku', 1), ('nōen', 1), ('shomeimon', 1), ('shukushi', 1)]...\n",
      "[2022-09-29 13:46:41,711] keeping 2000000 tokens which were in no less than 0 and no more than 2460000 (=100.0%) documents\n",
      "[2022-09-29 13:46:45,504] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:46:45,568] adding document #2460000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:47:10,206] discarding 33274 tokens: [('kirkkomaalla', 1), ('kirkkomaan', 1), ('kirkkomaata', 1), ('koittaessa', 1), ('konserttifantasia', 1), ('koraali', 1), ('kummaa', 1), ('kuopustain', 1), ('kuuleppas', 1), ('kuutamossa', 1)]...\n",
      "[2022-09-29 13:47:10,207] keeping 2000000 tokens which were in no less than 0 and no more than 2470000 (=100.0%) documents\n",
      "[2022-09-29 13:47:15,155] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:47:15,252] adding document #2470000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:47:39,537] discarding 29636 tokens: [('submargined', 1), ('buccinorum', 1), ('threeline', 1), ('alabasteroides', 1), ('nassarid', 1), ('bisacchi', 1), ('gemmuliferus', 1), ('motrton', 1), ('niotha', 1), ('antillara', 1)]...\n",
      "[2022-09-29 13:47:39,539] keeping 2000000 tokens which were in no less than 0 and no more than 2480000 (=100.0%) documents\n",
      "[2022-09-29 13:47:43,049] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:47:43,114] adding document #2480000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:48:08,153] discarding 32338 tokens: [('beauteen', 1), ('compi', 1), ('hanasanaide', 1), ('misslim', 1), ('negachaincompi', 1), ('auhaduddin', 1), ('ayyuqi', 1), ('bafghi', 1), ('bassame', 1), ('beiza', 1)]...\n",
      "[2022-09-29 13:48:08,154] keeping 2000000 tokens which were in no less than 0 and no more than 2490000 (=100.0%) documents\n",
      "[2022-09-29 13:48:11,663] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:48:11,728] adding document #2490000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:48:37,206] discarding 43014 tokens: [('posvervnt', 1), ('procavg', 1), ('pverorva', 1), ('sagittariorvm', 1), ('tegvntvr', 1), ('tracvm', 1), ('tvmvlo', 1), ('vepogenus', 1), ('verecvnd', 1), ('vicesimae', 1)]...\n",
      "[2022-09-29 13:48:37,208] keeping 2000000 tokens which were in no less than 0 and no more than 2500000 (=100.0%) documents\n",
      "[2022-09-29 13:48:42,130] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:48:42,228] adding document #2500000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:49:12,067] discarding 40063 tokens: [('kexis', 1), ('kodefile', 1), ('krasbit', 1), ('lassoapp', 1), ('ledspec', 1), ('lsmaker', 1), ('madtracker', 1), ('manialinks', 1), ('mcaddon', 1), ('mcfunction', 1)]...\n",
      "[2022-09-29 13:49:12,069] keeping 2000000 tokens which were in no less than 0 and no more than 2510000 (=100.0%) documents\n",
      "[2022-09-29 13:49:17,324] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:49:17,421] adding document #2510000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:49:44,285] discarding 34199 tokens: [('odysseyantiphates', 1), ('enkyklon', 1), ('gentemque', 1), ('stolatae', 1), ('togatam', 1), ('toga§', 1), ('trabeati', 1), ('cartilige', 1), ('ruepell', 1), ('churretero', 1)]...\n",
      "[2022-09-29 13:49:44,287] keeping 2000000 tokens which were in no less than 0 and no more than 2520000 (=100.0%) documents\n",
      "[2022-09-29 13:49:47,839] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:49:47,906] adding document #2520000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:50:12,207] discarding 37616 tokens: [('生の哲学', 1), ('結論', 1), ('芸術と生活の融合', 1), ('西洋近世哲学史稿', 1), ('講演', 1), ('講義', 1), ('資料篇', 1), ('遠里丹婦麗天', 1), ('離接的偶然', 1), ('風流に関する一考察', 1)]...\n",
      "[2022-09-29 13:50:12,209] keeping 2000000 tokens which were in no less than 0 and no more than 2530000 (=100.0%) documents\n",
      "[2022-09-29 13:50:15,715] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:50:15,781] adding document #2530000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:50:39,222] discarding 30830 tokens: [('seldner', 1), ('rohidkhore', 1), ('setumadhavarao', 1), ('svarājya', 1), ('crescita', 1), ('chrisanthios', 1), ('enviroware', 1), ('fetokakis', 1), ('bierwith', 1), ('aldwinians', 1)]...\n",
      "[2022-09-29 13:50:39,224] keeping 2000000 tokens which were in no less than 0 and no more than 2540000 (=100.0%) documents\n",
      "[2022-09-29 13:50:42,741] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:50:42,806] adding document #2540000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:51:05,291] discarding 33619 tokens: [('marahani', 1), ('prescolair', 1), ('tratringa', 1), ('tratringua', 1), ('baranganic', 1), ('filipinoequivalent', 1), ('mamuel', 1), ('ourevitch', 1), ('iotsu', 1), ('iproc', 1)]...\n",
      "[2022-09-29 13:51:05,292] keeping 2000000 tokens which were in no less than 0 and no more than 2550000 (=100.0%) documents\n",
      "[2022-09-29 13:51:08,793] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:51:08,858] adding document #2550000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:51:33,636] discarding 37246 tokens: [('有朋', 1), ('東久邇宮', 1), ('松方', 1), ('榮作', 1), ('權兵衛', 1), ('正芳', 1), ('清浦', 1), ('湛山', 1), ('禮次郎', 1), ('稔彦', 1)]...\n",
      "[2022-09-29 13:51:33,637] keeping 2000000 tokens which were in no less than 0 and no more than 2560000 (=100.0%) documents\n",
      "[2022-09-29 13:51:37,177] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:51:37,244] adding document #2560000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:52:08,727] discarding 36190 tokens: [('yapónskoye', 1), ('八道總圖', 1), ('新製輿地全圖', 1), ('日本内海', 1), ('日本東海', 1), ('日本邊界略圖', 1), ('朝鮮東海', 1), ('朝鮮海', 1), ('서해', 1), ('androerotic', 1)]...\n",
      "[2022-09-29 13:52:08,728] keeping 2000000 tokens which were in no less than 0 and no more than 2570000 (=100.0%) documents\n",
      "[2022-09-29 13:52:12,288] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:52:12,355] adding document #2570000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:52:36,561] discarding 46342 tokens: [('berillus', 1), ('besicles', 1), ('bharatividyapeeth', 1), ('bvissc', 1), ('bvissci', 1), ('cboo', 1), ('cbóptica', 1), ('diyatarippu', 1), ('inquestionable', 1), ('mclinoptom', 1)]...\n",
      "[2022-09-29 13:52:36,563] keeping 2000000 tokens which were in no less than 0 and no more than 2580000 (=100.0%) documents\n",
      "[2022-09-29 13:52:40,085] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:52:40,152] adding document #2580000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:53:05,442] discarding 48066 tokens: [('melukau', 1), ('nadeethada', 1), ('njavakkat', 1), ('payappar', 1), ('rakkuly', 1), ('vazhanekkavu', 1), ('deproscribed', 1), ('statūs', 1), ('frolundaborg', 1), ('bettrath', 1)]...\n",
      "[2022-09-29 13:53:05,444] keeping 2000000 tokens which were in no less than 0 and no more than 2590000 (=100.0%) documents\n",
      "[2022-09-29 13:53:08,983] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:53:09,076] adding document #2590000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:53:34,481] discarding 31697 tokens: [('vojtus', 1), ('werthemann', 1), ('annsy', 1), ('arting', 1), ('brekkstein', 1), ('bærentsen', 1), ('búi', 1), ('dalsgarð', 1), ('elsubet', 1), ('eyðfinn', 1)]...\n",
      "[2022-09-29 13:53:34,483] keeping 2000000 tokens which were in no less than 0 and no more than 2600000 (=100.0%) documents\n",
      "[2022-09-29 13:53:39,421] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:53:39,516] adding document #2600000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:54:04,072] discarding 32589 tokens: [('macauleys', 1), ('macualey', 1), ('mehrstimmigen', 1), ('motettenkomposition', 1), ('stilgeschichte', 1), ('tenorgeige', 1), ('carlandstown', 1), ('cottlestown', 1), ('tisdalls', 1), ('anuerin', 1)]...\n",
      "[2022-09-29 13:54:04,074] keeping 2000000 tokens which were in no less than 0 and no more than 2610000 (=100.0%) documents\n",
      "[2022-09-29 13:54:07,744] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:54:07,840] adding document #2610000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:54:31,064] discarding 28405 tokens: [('agrarverhaltnisse', 1), ('altrömische', 1), ('milkwirtschaft', 1), ('molkereiwesens', 1), ('futan', 1), ('gregston', 1), ('handera', 1), ('trgpro', 1), ('adesham', 1), ('brodbridge', 1)]...\n",
      "[2022-09-29 13:54:31,065] keeping 2000000 tokens which were in no less than 0 and no more than 2620000 (=100.0%) documents\n",
      "[2022-09-29 13:54:34,574] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:54:34,639] adding document #2620000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:54:59,906] discarding 27765 tokens: [('hamartind', 1), ('hamrane', 1), ('sportparken', 1), ('petrelik', 1), ('cajica', 1), ('crepad', 1), ('desatres', 1), ('guajaro', 1), ('guamalito', 1), ('prevencion', 1)]...\n",
      "[2022-09-29 13:54:59,907] keeping 2000000 tokens which were in no less than 0 and no more than 2630000 (=100.0%) documents\n",
      "[2022-09-29 13:55:04,797] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:55:04,892] adding document #2630000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:55:39,190] discarding 33355 tokens: [('grehamarstølen', 1), ('hænsgardane', 1), ('leirhol', 1), ('maristua', 1), ('ryfoss', 1), ('ryfossen', 1), ('smeddalen', 1), ('sputrefossen', 1), ('stølsnøse', 1), ('tomaskyrkja', 1)]...\n",
      "[2022-09-29 13:55:39,192] keeping 2000000 tokens which were in no less than 0 and no more than 2640000 (=100.0%) documents\n",
      "[2022-09-29 13:55:44,096] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:55:44,192] adding document #2640000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:56:09,594] discarding 39231 tokens: [('mayerlucasfilm', 1), ('picturesbuena', 1), ('picturesdimension', 1), ('pictureslucasfilm', 1), ('picturesmarvel', 1), ('studiosdreamworks', 1), ('studioslucasfilm', 1), ('studiostristar', 1), ('eppulston', 1), ('iddouch', 1)]...\n",
      "[2022-09-29 13:56:09,596] keeping 2000000 tokens which were in no less than 0 and no more than 2650000 (=100.0%) documents\n",
      "[2022-09-29 13:56:13,197] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:56:13,277] adding document #2650000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:56:38,606] discarding 36714 tokens: [('begode', 1), ('cazzolato', 1), ('electricunicycle', 1), ('inventist', 1), ('kingsong', 1), ('micycle', 1), ('faquhar', 1), ('frithside', 1), ('mersuture', 1), ('istorefolder', 1)]...\n",
      "[2022-09-29 13:56:38,607] keeping 2000000 tokens which were in no less than 0 and no more than 2660000 (=100.0%) documents\n",
      "[2022-09-29 13:56:42,205] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:56:42,272] adding document #2660000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:57:09,485] discarding 34225 tokens: [('cannabisamericana', 1), ('dàmá', 1), ('genericmedication', 1), ('jlhopkins', 1), ('pebers', 1), ('brookesiinae', 1), ('chamaeleonid', 1), ('creamwareaudio', 1), ('fracrak', 1), ('minimodular', 1)]...\n",
      "[2022-09-29 13:57:09,488] keeping 2000000 tokens which were in no less than 0 and no more than 2670000 (=100.0%) documents\n",
      "[2022-09-29 13:57:14,078] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:57:14,150] adding document #2670000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:57:43,700] discarding 36932 tokens: [('compages', 1), ('ecliptically', 1), ('honsang', 1), ('honŭi', 1), ('iyeong', 1), ('krikōtē', 1), ('ongnu', 1), ('tischplanetarium', 1), ('崔攸之', 1), ('梁令瓚', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 13:57:43,702] keeping 2000000 tokens which were in no less than 0 and no more than 2680000 (=100.0%) documents\n",
      "[2022-09-29 13:57:49,095] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:57:49,194] adding document #2680000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:58:15,575] discarding 40826 tokens: [('wiandae', 1), ('特殊慰安隊', 1), ('특수위안대', 1), ('stilljill', 1), ('alfax', 1), ('ezox', 1), ('komaflex', 1), ('macophoto', 1), ('superslide', 1), ('caligarism', 1)]...\n",
      "[2022-09-29 13:58:15,577] keeping 2000000 tokens which were in no less than 0 and no more than 2690000 (=100.0%) documents\n",
      "[2022-09-29 13:58:19,088] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:58:19,154] adding document #2690000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:58:45,036] discarding 37966 tokens: [('quicksolder', 1), ('xenogc', 1), ('czulinski', 1), ('istranova', 1), ('saiyidi', 1), ('sawahii', 1), ('volksorkest', 1), ('atrpm', 1), ('vvtli', 1), ('apoifis', 1)]...\n",
      "[2022-09-29 13:58:45,038] keeping 2000000 tokens which were in no less than 0 and no more than 2700000 (=100.0%) documents\n",
      "[2022-09-29 13:58:49,968] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:58:50,065] adding document #2700000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:59:14,930] discarding 44473 tokens: [('kellemes', 1), ('kerstdagen', 1), ('laimingų', 1), ('laimīgu', 1), ('laouen', 1), ('mơi', 1), ('nadelik', 1), ('naththalak', 1), ('nowégò', 1), ('onnellista', 1)]...\n",
      "[2022-09-29 13:59:14,932] keeping 2000000 tokens which were in no less than 0 and no more than 2710000 (=100.0%) documents\n",
      "[2022-09-29 13:59:19,837] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:59:19,935] adding document #2710000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:59:44,923] discarding 44285 tokens: [('ご主人さま', 1), ('delachatre', 1), ('plainemaison', 1), ('kromyonia', 1), ('lomvardi', 1), ('psifaei', 1), ('psifta', 1), ('saronikós', 1), ('ravund', 1), ('bavariamarried', 1)]...\n",
      "[2022-09-29 13:59:44,925] keeping 2000000 tokens which were in no less than 0 and no more than 2720000 (=100.0%) documents\n",
      "[2022-09-29 13:59:49,640] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 13:59:49,739] adding document #2720000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:00:17,001] discarding 43494 tokens: [('exhibotion', 1), ('poorfisherman', 1), ('publikationsplattform', 1), ('staffelei', 1), ('borunov', 1), ('kossikovskaya', 1), ('kossikovsky', 1), ('misitsch', 1), ('otrovo', 1), ('staekelberg', 1)]...\n",
      "[2022-09-29 14:00:17,003] keeping 2000000 tokens which were in no less than 0 and no more than 2730000 (=100.0%) documents\n",
      "[2022-09-29 14:00:21,970] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:00:22,070] adding document #2730000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:00:46,307] discarding 37184 tokens: [('agrarne', 1), ('bakalskoe', 1), ('bilohorsk', 1), ('burulcha', 1), ('burunskaya', 1), ('cisdneper', 1), ('derekoika', 1), ('dzhankoj', 1), ('eclizee', 1), ('elattoma', 1)]...\n",
      "[2022-09-29 14:00:46,309] keeping 2000000 tokens which were in no less than 0 and no more than 2740000 (=100.0%) documents\n",
      "[2022-09-29 14:00:51,638] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:00:51,737] adding document #2740000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:01:17,865] discarding 38583 tokens: [('chalaghantepe', 1), ('fuija', 1), ('obelion', 1), ('schlurp', 1), ('trepanner', 1), ('worldfrom', 1), ('avouchers', 1), ('winemark', 1), ('khaox', 1), ('līam', 1)]...\n",
      "[2022-09-29 14:01:17,867] keeping 2000000 tokens which were in no less than 0 and no more than 2750000 (=100.0%) documents\n",
      "[2022-09-29 14:01:22,987] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:01:23,084] adding document #2750000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:01:48,535] discarding 36464 tokens: [('signjt', 1), ('gouwermentspoorwegen', 1), ('东丰镇', 1), ('东凤镇', 1), ('东风镇', 1), ('alexandravillard', 1), ('gringutes', 1), ('osterwalde', 1), ('osterwohle', 1), ('onevietnam', 1)]...\n",
      "[2022-09-29 14:01:48,537] keeping 2000000 tokens which were in no less than 0 and no more than 2760000 (=100.0%) documents\n",
      "[2022-09-29 14:01:53,534] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:01:53,631] adding document #2760000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:02:20,111] discarding 37432 tokens: [('govorkov', 1), ('noif', 1), ('organizzative', 1), ('reggnia', 1), ('verachi', 1), ('samotnjak', 1), ('vilovito', 1), ('pillbox#1', 1), ('ayangwa', 1), ('bangkero', 1)]...\n",
      "[2022-09-29 14:02:20,113] keeping 2000000 tokens which were in no less than 0 and no more than 2770000 (=100.0%) documents\n",
      "[2022-09-29 14:02:23,714] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:02:23,782] adding document #2770000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:02:49,911] discarding 37009 tokens: [('slip#21§', 1), ('fantamady', 1), ('heraf', 1), ('ndtoungou', 1), ('verzeri', 1), ('vizuete', 1), ('broniec', 1), ('ceapura', 1), ('demiddi', 1), ('eshinov', 1)]...\n",
      "[2022-09-29 14:02:49,912] keeping 2000000 tokens which were in no less than 0 and no more than 2780000 (=100.0%) documents\n",
      "[2022-09-29 14:02:54,840] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:02:54,937] adding document #2780000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:03:19,919] discarding 35289 tokens: [('aštuonių', 1), ('kursenieku', 1), ('kursisk', 1), ('kuršiškai', 1), ('sakutis', 1), ('sakučiai', 1), ('valuod', 1), ('vėjų', 1), ('marcimain', 1), ('ceose', 1)]...\n",
      "[2022-09-29 14:03:19,920] keeping 2000000 tokens which were in no less than 0 and no more than 2790000 (=100.0%) documents\n",
      "[2022-09-29 14:03:24,880] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:03:24,979] adding document #2790000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:03:51,048] discarding 37554 tokens: [('bygran', 1), ('chloripc', 1), ('elbanil', 1), ('furloe', 1), ('metoxon', 1), ('mirvale', 1), ('nexoval', 1), ('oorja', 1), ('postapplication', 1), ('preventol', 1)]...\n",
      "[2022-09-29 14:03:51,050] keeping 2000000 tokens which were in no less than 0 and no more than 2800000 (=100.0%) documents\n",
      "[2022-09-29 14:03:56,077] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:03:56,175] adding document #2800000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:04:22,475] discarding 45628 tokens: [('zompelri', 1), ('avonde', 1), ('palmentola', 1), ('dzongsa', 1), ('nichu', 1), ('sepearated', 1), ('sibsoo', 1), ('sibsu', 1), ('sipchoo', 1), ('tashichoeling', 1)]...\n",
      "[2022-09-29 14:04:22,478] keeping 2000000 tokens which were in no less than 0 and no more than 2810000 (=100.0%) documents\n",
      "[2022-09-29 14:04:27,476] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:04:27,577] adding document #2810000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:04:52,959] discarding 35494 tokens: [('dubronevski', 1), ('hynoceros', 1), ('alagyoz', 1), ('cattlebreeding', 1), ('daralagyózsky', 1), ('desyatins', 1), ('gokcha', 1), ('sharúro', 1), ('cltambour', 1), ('cspl', 1)]...\n",
      "[2022-09-29 14:04:52,961] keeping 2000000 tokens which were in no less than 0 and no more than 2820000 (=100.0%) documents\n",
      "[2022-09-29 14:04:57,894] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:04:57,991] adding document #2820000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:05:24,501] discarding 31780 tokens: [('aghdara', 1), ('regalvanised', 1), ('satellitenstadt', 1), ('basiocciptial', 1), ('bumbee', 1), ('saylori', 1), ('sagerfield', 1), ('apfelhaus', 1), ('berufsjugendlich', 1), ('kinderlied', 1)]...\n",
      "[2022-09-29 14:05:24,503] keeping 2000000 tokens which were in no less than 0 and no more than 2830000 (=100.0%) documents\n",
      "[2022-09-29 14:05:29,534] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:05:29,631] adding document #2830000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:05:55,042] discarding 41252 tokens: [('cebeli', 1), ('nuhuşağı', 1), ('salmanuşağı', 1), ('史朗', 1), ('arradon', 1), ('verthuy', 1), ('édouardine', 1), ('chalude', 1), ('puckridge', 1), ('bartfeld', 1)]...\n",
      "[2022-09-29 14:05:55,044] keeping 2000000 tokens which were in no less than 0 and no more than 2840000 (=100.0%) documents\n",
      "[2022-09-29 14:05:58,671] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:05:58,740] adding document #2840000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:06:25,450] discarding 33805 tokens: [('genealog', 1), ('severnyye', 1), ('scofton', 1), ('adoptee§', 1), ('kriegenburg', 1), ('laskmi', 1), ('nauval', 1), ('zailanty', 1), ('augsburg_protestantischer_friedhof_', 1), ('akhanouch', 1)]...\n",
      "[2022-09-29 14:06:25,452] keeping 2000000 tokens which were in no less than 0 and no more than 2850000 (=100.0%) documents\n",
      "[2022-09-29 14:06:28,984] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:06:29,050] adding document #2850000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:06:53,399] discarding 38520 tokens: [('gudz', 1), ('ignatyvich', 1), ('гудзь', 1), ('игнатьевич', 1), ('файл', 1), ('pomerant', 1), ('sniffer§', 1), ('torbiak', 1), ('acharacta', 1), ('affixella', 1)]...\n",
      "[2022-09-29 14:06:53,400] keeping 2000000 tokens which were in no less than 0 and no more than 2860000 (=100.0%) documents\n",
      "[2022-09-29 14:06:56,911] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:06:56,978] adding document #2860000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:07:24,010] discarding 39138 tokens: [('evaluna', 1), ('microestadio', 1), ('electrofuges', 1), ('enamide', 1), ('ectrodactyls', 1), ('ektroma', 1), ('hartsink', 1), ('syndactylized', 1), ('tarbellites', 1), ('dilkea', 1)]...\n",
      "[2022-09-29 14:07:24,012] keeping 2000000 tokens which were in no less than 0 and no more than 2870000 (=100.0%) documents\n",
      "[2022-09-29 14:07:28,931] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:07:29,029] adding document #2870000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:07:53,245] discarding 33688 tokens: [('valase', 1), ('screechie', 1), ('barsided', 1), ('prunieres', 1), ('schlechtgefesselte', 1), ('schrekers', 1), ('abschuss', 1), ('voudier', 1), ('ettler', 1), ('airies', 1)]...\n",
      "[2022-09-29 14:07:53,247] keeping 2000000 tokens which were in no less than 0 and no more than 2880000 (=100.0%) documents\n",
      "[2022-09-29 14:07:56,790] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:07:56,857] adding document #2880000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:08:23,170] discarding 37352 tokens: [('abaawa', 1), ('abasraba', 1), ('arkoful', 1), ('ayirebi', 1), ('begye', 1), ('bibianiha', 1), ('donkoyemu', 1), ('dresssing', 1), ('egyaa', 1), ('gyateh', 1)]...\n",
      "[2022-09-29 14:08:23,172] keeping 2000000 tokens which were in no less than 0 and no more than 2890000 (=100.0%) documents\n",
      "[2022-09-29 14:08:26,783] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:08:26,852] adding document #2890000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:08:51,714] discarding 33365 tokens: [('respiratoire', 1), ('jourdin', 1), ('studiebarometeret', 1), ('ekuiti', 1), ('ucti', 1), ('calenhead', 1), ('健司', 1), ('badison', 1), ('besanya', 1), ('chinede', 1)]...\n",
      "[2022-09-29 14:08:51,715] keeping 2000000 tokens which were in no less than 0 and no more than 2900000 (=100.0%) documents\n",
      "[2022-09-29 14:08:55,303] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:08:55,371] adding document #2900000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:09:18,204] discarding 34130 tokens: [('shicong', 1), ('ranbeer', 1), ('m_xfaaaaibaj', 1), ('veelya', 1), ('videoforma', 1), ('kerevat', 1), ('hiironmäki', 1), ('vapaana', 1), ('conspicuousness#1', 1), ('ghamara', 1)]...\n",
      "[2022-09-29 14:09:18,206] keeping 2000000 tokens which were in no less than 0 and no more than 2910000 (=100.0%) documents\n",
      "[2022-09-29 14:09:23,202] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:09:23,302] adding document #2910000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:09:48,770] discarding 37207 tokens: [('enisheim', 1), ('mauaranui', 1), ('kinoumbou', 1), ('ngouedi', 1), ('tiralosi', 1), ('mansŏng', 1), ('万城', 1), ('立石炭鉱', 1), ('탄광선', 1), ('coombedown', 1)]...\n",
      "[2022-09-29 14:09:48,771] keeping 2000000 tokens which were in no less than 0 and no more than 2920000 (=100.0%) documents\n",
      "[2022-09-29 14:09:53,717] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:09:53,816] adding document #2920000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:10:22,380] discarding 33497 tokens: [('сазнања', 1), ('филозофија', 1), ('чланци', 1), ('ficquet', 1), ('mcnoodle', 1), ('kulangavati', 1), ('sivashish', 1), ('mendicità', 1), ('provbo', 1), ('countertechnique', 1)]...\n",
      "[2022-09-29 14:10:22,382] keeping 2000000 tokens which were in no less than 0 and no more than 2930000 (=100.0%) documents\n",
      "[2022-09-29 14:10:26,178] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:10:26,276] adding document #2930000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:10:53,532] discarding 34547 tokens: [('thiruneetru', 1), ('trunaya', 1), ('vidvatha', 1), ('femedeer', 1), ('theirspace', 1), ('yourspace', 1), ('billeskov', 1), ('lvanon', 1), ('østerud', 1), ('beuretune', 1)]...\n",
      "[2022-09-29 14:10:53,534] keeping 2000000 tokens which were in no less than 0 and no more than 2940000 (=100.0%) documents\n",
      "[2022-09-29 14:10:58,569] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:10:58,666] adding document #2940000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:11:24,930] discarding 37366 tokens: [('삿포로에서', 1), ('여성이여', 1), ('일본은', 1), ('탐험하라', 1), ('테러리스트가', 1), ('푸른숲', 1), ('khandoli', 1), ('fambuena', 1), ('regiment_world', 1), ('bandanang', 1)]...\n",
      "[2022-09-29 14:11:24,932] keeping 2000000 tokens which were in no less than 0 and no more than 2950000 (=100.0%) documents\n",
      "[2022-09-29 14:11:28,572] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:11:28,639] adding document #2950000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:11:54,907] discarding 37758 tokens: [('nikwikwi', 1), ('skwim', 1), ('bathrub', 1), ('down_town', 1), ('looking_east', 1), ('looking_west', 1), ('bixpix', 1), ('fredasaurus', 1), ('hockerman', 1), ('sharapan', 1)]...\n",
      "[2022-09-29 14:11:54,909] keeping 2000000 tokens which were in no less than 0 and no more than 2960000 (=100.0%) documents\n",
      "[2022-09-29 14:11:59,848] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:11:59,946] adding document #2960000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:12:24,844] discarding 37521 tokens: [('gixxlies', 1), ('šála', 1), ('phežúta', 1), ('ȟaká', 1), ('oyúȟpe', 1), ('wazíbló', 1), ('wósoso', 1), ('sicanġu', 1), ('sápauŋ', 1), ('šuŋgská', 1)]...\n",
      "[2022-09-29 14:12:24,846] keeping 2000000 tokens which were in no less than 0 and no more than 2970000 (=100.0%) documents\n",
      "[2022-09-29 14:12:29,824] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:12:29,924] adding document #2970000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:12:56,730] discarding 37777 tokens: [('ugghhh', 1), ('awaywith', 1), ('aubornn', 1), ('revogação', 1), ('schatzgelder', 1), ('talveski', 1), ('fpnm', 1), ('furniturestyles', 1), ('kensingtonpalace', 1), ('presencechamber', 1)]...\n",
      "[2022-09-29 14:12:56,733] keeping 2000000 tokens which were in no less than 0 and no more than 2980000 (=100.0%) documents\n",
      "[2022-09-29 14:13:01,482] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:13:01,550] adding document #2980000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:13:26,773] discarding 35276 tokens: [('rensselaerian', 1), ('quarcini', 1), ('ntfd', 1), ('higner', 1), ('mehwaldt', 1), ('ukermark', 1), ('vandervoorte', 1), ('walmow', 1), ('benhamin', 1), ('teyanunsoke', 1)]...\n",
      "[2022-09-29 14:13:26,775] keeping 2000000 tokens which were in no less than 0 and no more than 2990000 (=100.0%) documents\n",
      "[2022-09-29 14:13:31,918] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:13:32,017] adding document #2990000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:13:59,175] discarding 34105 tokens: [('wendysu', 1), ('debraun', 1), ('deitl', 1), ('bareburger', 1), ('ratables#0§', 1), ('werimus', 1), ('italinate', 1), ('chachis', 1), ('koetas', 1), ('cinnnaminson', 1)]...\n",
      "[2022-09-29 14:13:59,177] keeping 2000000 tokens which were in no less than 0 and no more than 3000000 (=100.0%) documents\n",
      "[2022-09-29 14:14:04,138] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:14:04,237] adding document #3000000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:14:31,157] discarding 33779 tokens: [('naaldwijk_hofje', 1), ('pijletuinen', 1), ('woerdblok', 1), ('zandstrand', 1), ('explorenewyorkmills', 1), ('dorpslaan', 1), ('fopzoon', 1), ('leckerland', 1), ('leckerlant', 1), ('nieuw_lekkerland_kleine_molen_', 1)]...\n",
      "[2022-09-29 14:14:31,159] keeping 2000000 tokens which were in no less than 0 and no more than 3010000 (=100.0%) documents\n",
      "[2022-09-29 14:14:36,440] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:14:36,538] adding document #3010000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:15:01,592] discarding 30567 tokens: [('katjeskelder', 1), ('slotbossetoren', 1), ('slotjes', 1), ('divericates', 1), ('mispelbocht', 1), ('rucphense', 1), ('giesenplein', 1), ('oelbroec', 1), ('olliemeulen', 1), ('ontginningsboerderij', 1)]...\n",
      "[2022-09-29 14:15:01,593] keeping 2000000 tokens which were in no less than 0 and no more than 3020000 (=100.0%) documents\n",
      "[2022-09-29 14:15:05,140] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:15:05,207] adding document #3020000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:15:30,283] discarding 35876 tokens: [('potomatami', 1), ('glo_plats', 1), ('pdf_maps', 1), ('spatialdatalibrary', 1), ('garaudus', 1), ('directoriesusa', 1), ('salzburghers', 1), ('tromblé', 1), ('loehme', 1), ('kloha', 1)]...\n",
      "[2022-09-29 14:15:30,285] keeping 2000000 tokens which were in no less than 0 and no more than 3030000 (=100.0%) documents\n",
      "[2022-09-29 14:15:34,565] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:15:34,664] adding document #3030000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:16:06,085] discarding 32692 tokens: [('mcyt', 1), ('hopkyn', 1), ('institure', 1), ('chronophantasma', 1), ('grimore', 1), ('taokaka', 1), ('rard', 1), ('chaughara', 1), ('gajhya', 1), ('gājhyā', 1)]...\n",
      "[2022-09-29 14:16:06,088] keeping 2000000 tokens which were in no less than 0 and no more than 3040000 (=100.0%) documents\n",
      "[2022-09-29 14:16:10,443] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:16:10,542] adding document #3040000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:16:36,406] discarding 42056 tokens: [('planefield', 1), ('herrinfesta', 1), ('limebikes', 1), ('tuneberg', 1), ('statelineinfo', 1), ('balloit', 1), ('illinswek', 1), ('ghms', 1), ('edgecreek', 1), ('bernhaus', 1)]...\n",
      "[2022-09-29 14:16:36,407] keeping 2000000 tokens which were in no less than 0 and no more than 3050000 (=100.0%) documents\n",
      "[2022-09-29 14:16:40,035] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:16:40,105] adding document #3050000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:17:07,024] discarding 35501 tokens: [('loutzenhizer', 1), ('visitmontrose', 1), ('cherbeneau', 1), ('otonawanda', 1), ('delnorteriverwalk', 1), ('dmtnsunset', 1), ('dmtntrailhead', 1), ('lookoutmtn', 1), ('nɔɹt', 1), ('pinoscreek', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:17:07,026] keeping 2000000 tokens which were in no less than 0 and no more than 3060000 (=100.0%) documents\n",
      "[2022-09-29 14:17:10,578] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:17:10,645] adding document #3060000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:17:38,412] discarding 34980 tokens: [('msewg', 1), ('plipat', 1), ('rathchavy', 1), ('theasean', 1), ('bodstein', 1), ('enckendorf', 1), ('geschichtphilosophie', 1), ('halbmonatsschau', 1), ('kiepenheur', 1), ('moralwissenschaft', 1)]...\n",
      "[2022-09-29 14:17:38,415] keeping 2000000 tokens which were in no less than 0 and no more than 3070000 (=100.0%) documents\n",
      "[2022-09-29 14:17:43,500] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:17:43,601] adding document #3070000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:18:11,384] discarding 34242 tokens: [('oonalakleet', 1), ('thliq', 1), ('unalaklik', 1), ('eidamoo', 1), ('kingaghee', 1), ('kingigamute', 1), ('iġaluŋmiut', 1), ('nachirvik', 1), ('anaqtuġvik', 1), ('mekiana', 1)]...\n",
      "[2022-09-29 14:18:11,386] keeping 2000000 tokens which were in no less than 0 and no more than 3080000 (=100.0%) documents\n",
      "[2022-09-29 14:18:16,392] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:18:16,491] adding document #3080000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:18:43,946] discarding 34190 tokens: [('abcdxxxxxxxx', 1), ('alaw_expand', 1), ('codexor', 1), ('eeemmmm', 1), ('iexp', 1), ('linbuf', 1), ('logbuf', 1), ('seeemmmm', 1), ('kuarteti', 1), ('mbawawa', 1)]...\n",
      "[2022-09-29 14:18:43,950] keeping 2000000 tokens which were in no less than 0 and no more than 3090000 (=100.0%) documents\n",
      "[2022-09-29 14:18:49,347] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:18:49,416] adding document #3090000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:19:17,680] discarding 35668 tokens: [('austrianwings', 1), ('cardioide', 1), ('durchstoßenes', 1), ('aiguette', 1), ('ataze', 1), ('lladura', 1), ('lladure', 1), ('narbôn', 1), ('radelier', 1), ('flaiva', 1)]...\n",
      "[2022-09-29 14:19:17,682] keeping 2000000 tokens which were in no less than 0 and no more than 3100000 (=100.0%) documents\n",
      "[2022-09-29 14:19:22,654] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:19:22,752] adding document #3100000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:19:48,317] discarding 33786 tokens: [('teutimez', 1), ('tomyaars', 1), ('weshoyot', 1), ('youngmans', 1), ('dēmarchos', 1), ('kallikratian', 1), ('marylandhouse', 1), ('naggan', 1), ('apetitizershp', 1), ('chlebicky', 1)]...\n",
      "[2022-09-29 14:19:48,319] keeping 2000000 tokens which were in no less than 0 and no more than 3110000 (=100.0%) documents\n",
      "[2022-09-29 14:19:53,322] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:19:53,421] adding document #3110000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:20:25,870] discarding 41936 tokens: [('anjanisuta', 1), ('anjeneri', 1), ('anumant', 1), ('bukbis', 1), ('dashagreevakulantaka', 1), ('dinakrishnadasa', 1), ('hanumanthudu', 1), ('hanuruha', 1), ('kapeeshwara', 1), ('keiranshuyoshu', 1)]...\n",
      "[2022-09-29 14:20:25,872] keeping 2000000 tokens which were in no less than 0 and no more than 3120000 (=100.0%) documents\n",
      "[2022-09-29 14:20:30,857] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:20:30,958] adding document #3120000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:20:56,565] discarding 34652 tokens: [('jējūnus', 1), ('monosaccharidal', 1), ('appendixcancer', 1), ('extrathymically', 1), ('vermix', 1), ('algoretti', 1), ('montbail', 1), ('benadorassociates', 1), ('claudelien', 1), ('katalimov', 1)]...\n",
      "[2022-09-29 14:20:56,567] keeping 2000000 tokens which were in no less than 0 and no more than 3130000 (=100.0%) documents\n",
      "[2022-09-29 14:21:01,541] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:21:01,641] adding document #3130000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:21:27,904] discarding 33941 tokens: [('gaspár', 1), ('arnoldwatch', 1), ('ffoarchive', 1), ('fforst', 1), ('flutstein', 1), ('frankfurcie', 1), ('frankfurtoder', 1), ('frankfurtoderpost', 1), ('frankfurtoderrathaus', 1), ('frankfurtoderriverview', 1)]...\n",
      "[2022-09-29 14:21:27,907] keeping 2000000 tokens which were in no less than 0 and no more than 3140000 (=100.0%) documents\n",
      "[2022-09-29 14:21:33,082] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:21:33,181] adding document #3140000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:22:03,400] discarding 38075 tokens: [('spit#4§', 1), ('obinix', 1), ('heliopolises', 1), ('ichonuphys', 1), ('octaeterid', 1), ('thématisation', 1), ('wunaw', 1), ('ʻāʼat', 1), ('ʼatāma', 1), ('ʾōn', 1)]...\n",
      "[2022-09-29 14:22:03,402] keeping 2000000 tokens which were in no less than 0 and no more than 3150000 (=100.0%) documents\n",
      "[2022-09-29 14:22:08,783] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:22:08,886] adding document #3150000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:22:37,203] discarding 30867 tokens: [('acetylglucosaminyldiphosphodolichol', 1), ('diacetylchitobiosyl', 1), ('dolichylacetylglucosamine', 1), ('ariclê', 1), ('belizário', 1), ('cicillo', 1), ('danuza', 1), ('egrei', 1), ('feldens', 1), ('guiomarita', 1)]...\n",
      "[2022-09-29 14:22:37,205] keeping 2000000 tokens which were in no less than 0 and no more than 3160000 (=100.0%) documents\n",
      "[2022-09-29 14:22:42,235] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:22:42,334] adding document #3160000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:23:10,158] discarding 33661 tokens: [('namarrkondjadjan', 1), ('numbuwah', 1), ('markumundana', 1), ('windilumba', 1), ('wallanganda', 1), ('boaliri', 1), ('djaun', 1), ('djungguan', 1), ('djungguwan', 1), ('djuwany', 1)]...\n",
      "[2022-09-29 14:23:10,159] keeping 2000000 tokens which were in no less than 0 and no more than 3170000 (=100.0%) documents\n",
      "[2022-09-29 14:23:15,146] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:23:15,245] adding document #3170000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:23:42,669] discarding 31983 tokens: [('toymate', 1), ('africakin', 1), ('bondian', 1), ('dahum', 1), ('dahumni', 1), ('unstirring', 1), ('zanzarim', 1), ('zanzarimi', 1), ('awarn', 1), ('futurecast', 1)]...\n",
      "[2022-09-29 14:23:42,671] keeping 2000000 tokens which were in no less than 0 and no more than 3180000 (=100.0%) documents\n",
      "[2022-09-29 14:23:48,060] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:23:48,160] adding document #3180000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:24:14,548] discarding 34907 tokens: [('havensport', 1), ('levacy', 1), ('farschman', 1), ('luvada', 1), ('mcgookey', 1), ('shenigo', 1), ('leonardsburg', 1), ('braffetsville', 1), ('ahkeak', 1), ('akóóh', 1)]...\n",
      "[2022-09-29 14:24:14,549] keeping 2000000 tokens which were in no less than 0 and no more than 3190000 (=100.0%) documents\n",
      "[2022-09-29 14:24:18,180] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:24:18,249] adding document #3190000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:24:45,457] discarding 31852 tokens: [('hargand', 1), ('instransigeance', 1), ('proleterian', 1), ('umapur', 1), ('redhu', 1), ('amarts', 1), ('artefactum', 1), ('dáňová', 1), ('hlobila', 1), ('mezihoráková', 1)]...\n",
      "[2022-09-29 14:24:45,459] keeping 2000000 tokens which were in no less than 0 and no more than 3200000 (=100.0%) documents\n",
      "[2022-09-29 14:24:49,110] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:24:49,178] adding document #3200000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:25:17,528] discarding 32798 tokens: [('disincludes', 1), ('lanikuala', 1), ('röstens', 1), ('sjöabol', 1), ('snugge', 1), ('tegnérkyrkogården', 1), ('uitgeversmaatschappy', 1), ('werelde', 1), ('huraqan', 1), ('cruitt', 1)]...\n",
      "[2022-09-29 14:25:17,530] keeping 2000000 tokens which were in no less than 0 and no more than 3210000 (=100.0%) documents\n",
      "[2022-09-29 14:25:21,337] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:25:21,410] adding document #3210000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:25:52,963] discarding 36073 tokens: [('phytoglycogen', 1), ('shiveling', 1), ('agamai', 1), ('agamos', 1), ('gracilimembris', 1), ('koggelmander', 1), ('luati', 1), ('mucoso', 1), ('tassiliensis', 1), ('turuensis', 1)]...\n",
      "[2022-09-29 14:25:52,964] keeping 2000000 tokens which were in no less than 0 and no more than 3220000 (=100.0%) documents\n",
      "[2022-09-29 14:25:56,771] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:25:56,847] adding document #3220000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:26:23,952] discarding 31410 tokens: [('raddory', 1), ('rewdgo', 1), ('saignante', 1), ('stoique', 1), ('swanber', 1), ('teacosy', 1), ('theatricule', 1), ('wardore', 1), ('waredo', 1), ('yorger', 1)]...\n",
      "[2022-09-29 14:26:23,954] keeping 2000000 tokens which were in no less than 0 and no more than 3230000 (=100.0%) documents\n",
      "[2022-09-29 14:26:29,326] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:26:29,425] adding document #3230000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:26:55,806] discarding 37334 tokens: [('dichellion', 1), ('digrifwr', 1), ('dregaron', 1), ('gampiau', 1), ('moetheu', 1), ('uφer', 1), ('werbā', 1), ('segos', 1), ('vitunis', 1), ('vosacius', 1)]...\n",
      "[2022-09-29 14:26:55,808] keeping 2000000 tokens which were in no less than 0 and no more than 3240000 (=100.0%) documents\n",
      "[2022-09-29 14:27:00,833] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:27:00,935] adding document #3240000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:27:27,852] discarding 39200 tokens: [('aparchomai', 1), ('aparxamenos', 1), ('aphrattias', 1), ('apotrachô', 1), ('apotrechô', 1), ('arbylis', 1), ('argetos', 1), ('aristeros', 1), ('arkeuthos', 1), ('aspalia', 1)]...\n",
      "[2022-09-29 14:27:27,854] keeping 2000000 tokens which were in no less than 0 and no more than 3250000 (=100.0%) documents\n",
      "[2022-09-29 14:27:32,947] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:27:33,050] adding document #3250000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:27:59,671] discarding 38650 tokens: [('vārus', 1), ('οὐᾶρος', 1), ('eristenea', 1), ('perianders', 1), ('keyportroute', 1), ('ekhemos', 1), ('káranos', 1), ('tḗmenos', 1), ('cresephontes', 1), ('kabegami', 1)]...\n",
      "[2022-09-29 14:27:59,672] keeping 2000000 tokens which were in no less than 0 and no more than 3260000 (=100.0%) documents\n",
      "[2022-09-29 14:28:04,686] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:28:04,787] adding document #3260000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:28:29,922] discarding 33404 tokens: [('nodesafferent', 1), ('femtofarads', 1), ('andecava', 1), ('andecavum', 1), ('andegavum', 1), ('angeriens', 1), ('anjoubus', 1), ('assiuis', 1), ('baumette', 1), ('brionneau', 1)]...\n",
      "[2022-09-29 14:28:29,924] keeping 2000000 tokens which were in no less than 0 and no more than 3270000 (=100.0%) documents\n",
      "[2022-09-29 14:28:34,909] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:28:35,009] adding document #3270000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:29:00,691] discarding 37407 tokens: [('butiful', 1), ('golfhous', 1), ('hadok', 1), ('noodls', 1), ('parsli', 1), ('rerums', 1), ('genobebo', 1), ('angeloniaeae', 1), ('antirrhinoideae', 1), ('aptosimeae', 1)]...\n",
      "[2022-09-29 14:29:00,693] keeping 2000000 tokens which were in no less than 0 and no more than 3280000 (=100.0%) documents\n",
      "[2022-09-29 14:29:05,789] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:29:05,890] adding document #3280000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:29:32,901] discarding 34683 tokens: [('achembaum', 1), ('amerimonte', 1), ('beachin', 1), ('calicountry', 1), ('dreambound', 1), ('featuringjustin', 1), ('janiels', 1), ('jawga', 1), ('reesmack', 1), ('superlatone', 1)]...\n",
      "[2022-09-29 14:29:32,903] keeping 2000000 tokens which were in no less than 0 and no more than 3290000 (=100.0%) documents\n",
      "[2022-09-29 14:29:36,558] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:29:36,627] adding document #3290000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:30:02,940] discarding 33875 tokens: [('africainement', 1), ('bahwak', 1), ('bussas', 1), ('eddyani', 1), ('insaha', 1), ('jawbni', 1), ('jbeldersa', 1), ('librejano', 1), ('lmima', 1), ('makaynach', 1)]...\n",
      "[2022-09-29 14:30:02,942] keeping 2000000 tokens which were in no less than 0 and no more than 3300000 (=100.0%) documents\n",
      "[2022-09-29 14:30:07,980] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:30:08,080] adding document #3300000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:30:34,936] discarding 38604 tokens: [('alrn', 1), ('gallawa', 1), ('féminas', 1), ('nwslpa', 1), ('nwslplayoffs', 1), ('airbudz', 1), ('amkette', 1), ('boomerfx', 1), ('chargepro', 1), ('evofox', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:30:34,938] keeping 2000000 tokens which were in no less than 0 and no more than 3310000 (=100.0%) documents\n",
      "[2022-09-29 14:30:40,014] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:30:40,116] adding document #3310000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:31:06,549] discarding 35892 tokens: [('helitender', 1), ('santabarbaracountyfirebc', 1), ('santabarbaracountyfireengine', 1), ('santabarbaracountyfiretruck', 1), ('sbcfd', 1), ('phoukea', 1), ('saburisak', 1), ('vongkut', 1), ('云良', 1), ('cheptenye', 1)]...\n",
      "[2022-09-29 14:31:06,551] keeping 2000000 tokens which were in no less than 0 and no more than 3320000 (=100.0%) documents\n",
      "[2022-09-29 14:31:11,544] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:31:11,644] adding document #3320000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:31:37,406] discarding 31940 tokens: [('docedge', 1), ('docplay', 1), ('realscreen', 1), ('maanada', 1), ('mayilada', 1), ('ramakatha', 1), ('blahovist', 1), ('donchyk', 1), ('savoofa', 1), ('siedoi', 1)]...\n",
      "[2022-09-29 14:31:37,407] keeping 2000000 tokens which were in no less than 0 and no more than 3330000 (=100.0%) documents\n",
      "[2022-09-29 14:31:41,051] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:31:41,120] adding document #3330000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:32:07,205] discarding 32475 tokens: [('leibnitzia', 1), ('citysense', 1), ('smartlighting', 1), ('strenzfeld', 1), ('tvilight', 1), ('moaa', 1), ('dogiyai', 1), ('dioesce', 1), ('geraac', 1), ('geralf', 1)]...\n",
      "[2022-09-29 14:32:07,207] keeping 2000000 tokens which were in no less than 0 and no more than 3340000 (=100.0%) documents\n",
      "[2022-09-29 14:32:12,261] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:32:12,362] adding document #3340000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:32:38,840] discarding 39755 tokens: [('haek', 1), ('shyrell', 1), ('cruzaba', 1), ('uijeonbu', 1), ('préciser', 1), ('wdgo', 1), ('heistern', 1), ('fernsby', 1), ('musidorus', 1), ('timescertified', 1)]...\n",
      "[2022-09-29 14:32:38,841] keeping 2000000 tokens which were in no less than 0 and no more than 3350000 (=100.0%) documents\n",
      "[2022-09-29 14:32:42,515] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:32:42,586] adding document #3350000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:33:06,513] discarding 31860 tokens: [('tungkod', 1), ('scaleup', 1), ('cyrtobotryum', 1), ('spillenger', 1), ('spillinger', 1), ('aarland', 1), ('aubitt', 1), ('chromology', 1), ('cultuurpodium', 1), ('daysprog', 1)]...\n",
      "[2022-09-29 14:33:06,515] keeping 2000000 tokens which were in no less than 0 and no more than 3360000 (=100.0%) documents\n",
      "[2022-09-29 14:33:10,181] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:33:10,249] adding document #3360000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:33:37,706] discarding 38178 tokens: [('cstore_fdw', 1), ('støff', 1), ('østlandets', 1), ('axungia', 1), ('mantequeros', 1), ('saín', 1), ('hitokaisha', 1), ('ikkasen', 1), ('桃介', 1), ('福澤', 1)]...\n",
      "[2022-09-29 14:33:37,708] keeping 2000000 tokens which were in no less than 0 and no more than 3370000 (=100.0%) documents\n",
      "[2022-09-29 14:33:42,012] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:33:42,081] adding document #3370000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:34:07,047] discarding 31310 tokens: [('burrite', 1), ('sbogarro', 1), ('egboh', 1), ('enakhe', 1), ('iwinosa', 1), ('kuvana', 1), ('preye', 1), ('bierkan', 1), ('kendeja', 1), ('rljau', 1)]...\n",
      "[2022-09-29 14:34:07,049] keeping 2000000 tokens which were in no less than 0 and no more than 3380000 (=100.0%) documents\n",
      "[2022-09-29 14:34:10,663] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:34:10,731] adding document #3380000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:34:37,097] discarding 37237 tokens: [('voncelle', 1), ('maksumov', 1), ('rizayev', 1), ('lvyone', 1), ('illawara', 1), ('biessipoff', 1), ('jmas', 1), ('eleey', 1), ('barchelius', 1), ('barchæus', 1)]...\n",
      "[2022-09-29 14:34:37,099] keeping 2000000 tokens which were in no less than 0 and no more than 3390000 (=100.0%) documents\n",
      "[2022-09-29 14:34:42,194] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:34:42,296] adding document #3390000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:35:09,701] discarding 38193 tokens: [('airhistory', 1), ('pepiniere', 1), ('ascontemporary', 1), ('infliger', 1), ('akikoae', 1), ('imbißstand', 1), ('aguaytiella', 1), ('zimplistic', 1), ('id_rubrique', 1), ('choumu', 1)]...\n",
      "[2022-09-29 14:35:09,703] keeping 2000000 tokens which were in no less than 0 and no more than 3400000 (=100.0%) documents\n",
      "[2022-09-29 14:35:14,777] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:35:14,880] adding document #3400000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:35:40,123] discarding 36030 tokens: [('muchundipalli', 1), ('padappat', 1), ('rumeysa', 1), ('papradiski', 1), ('jojoya', 1), ('crouès', 1), ('seuès', 1), ('afiyat', 1), ('hongjiàn', 1), ('keqiong', 1)]...\n",
      "[2022-09-29 14:35:40,125] keeping 2000000 tokens which were in no less than 0 and no more than 3410000 (=100.0%) documents\n",
      "[2022-09-29 14:35:43,776] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:35:43,845] adding document #3410000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:36:09,758] discarding 39033 tokens: [('reenfranchised', 1), ('vendrás', 1), ('callà', 1), ('outrushing', 1), ('preradovic', 1), ('skrtel', 1), ('torreño', 1), ('vaclik', 1), ('wrongfooted', 1), ('arenalle', 1)]...\n",
      "[2022-09-29 14:36:09,760] keeping 2000000 tokens which were in no less than 0 and no more than 3420000 (=100.0%) documents\n",
      "[2022-09-29 14:36:15,075] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:36:15,177] adding document #3420000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:36:41,775] discarding 34240 tokens: [('gruppteatern', 1), ('voraz', 1), ('sprkl', 1), ('hybsch', 1), ('roddolo', 1), ('arrecifeño', 1), ('gerbaldo', 1), ('abbedagge', 1), ('enatron', 1), ('jojopyun', 1)]...\n",
      "[2022-09-29 14:36:41,776] keeping 2000000 tokens which were in no less than 0 and no more than 3430000 (=100.0%) documents\n",
      "[2022-09-29 14:36:46,499] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:36:46,599] adding document #3430000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:37:12,166] discarding 31590 tokens: [('hohenackerana', 1), ('inglīsī', 1), ('kachetica', 1), ('krytzka', 1), ('lahidjanicus', 1), ('longeaculeata', 1), ('luristanica', 1), ('lātīnī', 1), ('majorovii', 1), ('megataphros', 1)]...\n",
      "[2022-09-29 14:37:12,168] keeping 2000000 tokens which were in no less than 0 and no more than 3440000 (=100.0%) documents\n",
      "[2022-09-29 14:37:16,027] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:37:16,096] adding document #3440000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:37:48,250] discarding 39808 tokens: [('gudī', 1), ('gulzár', 1), ('gurrag', 1), ('guřř', 1), ('guřřag', 1), ('guśtin', 1), ('gužn', 1), ('gužnag', 1), ('gwask', 1), ('gwaśtin', 1)]...\n",
      "[2022-09-29 14:37:48,252] keeping 2000000 tokens which were in no less than 0 and no more than 3450000 (=100.0%) documents\n",
      "[2022-09-29 14:37:53,318] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:37:53,421] adding document #3450000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:38:21,847] discarding 31214 tokens: [('argfx', 1), ('barhl', 1), ('dmbx', 1), ('dprx', 1), ('duxa', 1), ('homeodb', 1), ('metahox', 1), ('nonspecifically#0', 1), ('pintox', 1), ('pknox', 1)]...\n",
      "[2022-09-29 14:38:21,849] keeping 2000000 tokens which were in no less than 0 and no more than 3460000 (=100.0%) documents\n",
      "[2022-09-29 14:38:25,511] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:38:25,579] adding document #3460000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:38:49,773] discarding 33396 tokens: [('ܬܟܬܒ', 1), ('ܬܟܬܒܘܢ', 1), ('ܬܟܬܒܝܢ', 1), ('ܬܟܬܘܒ', 1), ('nikiforoff', 1), ('dobbingstone', 1), ('gloreda', 1), ('rklscp', 1), ('blausteins', 1), ('hydrafrac', 1)]...\n",
      "[2022-09-29 14:38:49,774] keeping 2000000 tokens which were in no less than 0 and no more than 3470000 (=100.0%) documents\n",
      "[2022-09-29 14:38:53,392] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:38:53,460] adding document #3470000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:39:17,872] discarding 36011 tokens: [('dṣelan', 1), ('dṣuku', 1), ('dṣumu', 1), ('dṣāwāra', 1), ('dṣēkiri', 1), ('egbēle', 1), ('egbīra', 1), ('ekamtulūfu', 1), ('ekī', 1), ('erēgba', 1)]...\n",
      "[2022-09-29 14:39:17,874] keeping 2000000 tokens which were in no less than 0 and no more than 3480000 (=100.0%) documents\n",
      "[2022-09-29 14:39:23,222] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:39:23,323] adding document #3480000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:39:49,470] discarding 39042 tokens: [('пантелеимонов_мужской_монастырь', 1), ('сивучей', 1), ('спортивная_площадка_в_петропавловске', 1), ('флайборд', 1), ('opdagelsesrejser', 1), ('pedderdatter', 1), ('pülse', 1), ('utkolotsk', 1), ('coullodin', 1), ('culraick', 1)]...\n",
      "[2022-09-29 14:39:49,472] keeping 2000000 tokens which were in no less than 0 and no more than 3490000 (=100.0%) documents\n",
      "[2022-09-29 14:39:54,557] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:39:54,660] adding document #3490000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:40:21,882] discarding 46101 tokens: [('omníčiye', 1), ('otʃʰeːtʰi', 1), ('ssiw', 1), ('ssiwak', 1), ('unkpatina', 1), ('wakíčhuŋza', 1), ('wakȟaŋ', 1), ('witkówiŋ', 1), ('wočhékiye', 1), ('wíŋtke', 1)]...\n",
      "[2022-09-29 14:40:21,884] keeping 2000000 tokens which were in no less than 0 and no more than 3500000 (=100.0%) documents\n",
      "[2022-09-29 14:40:25,568] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:40:25,639] adding document #3500000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:40:51,924] discarding 34712 tokens: [('南京大屠杀史料集', 1), ('南京大屠杀纪念馆家破人亡雕塑', 1), ('hippophobe', 1), ('华龙皇家陵园', 1), ('張園', 1), ('攝政王', 1), ('曜之', 1), ('流轉的王妃', 1), ('清帝退位詔書', 1), ('靜園', 1)]...\n",
      "[2022-09-29 14:40:51,926] keeping 2000000 tokens which were in no less than 0 and no more than 3510000 (=100.0%) documents\n",
      "[2022-09-29 14:40:55,541] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:40:55,610] adding document #3510000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:41:22,352] discarding 32938 tokens: [('cɾɪ', 1), ('cṵ', 1), ('dbú', 1), ('dbā', 1), ('dbū', 1), ('djréè', 1), ('djūlɛ', 1), ('djɛ', 1), ('dowlu', 1), ('do³', 1)]...\n",
      "[2022-09-29 14:41:22,354] keeping 2000000 tokens which were in no less than 0 and no more than 3520000 (=100.0%) documents\n",
      "[2022-09-29 14:41:27,871] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:41:27,974] adding document #3520000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:41:54,131] discarding 35180 tokens: [('ànúú', 1), ('ànɛ', 1), ('ànɪ', 1), ('ànʊ', 1), ('ànṍ', 1), ('àtâ', 1), ('àtâʔ', 1), ('àtù', 1), ('àwáíʔ', 1), ('àwã', 1)]...\n",
      "[2022-09-29 14:41:54,132] keeping 2000000 tokens which were in no less than 0 and no more than 3530000 (=100.0%) documents\n",
      "[2022-09-29 14:41:59,558] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:41:59,661] adding document #3530000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:42:25,349] discarding 32900 tokens: [('picols', 1), ('pulishe', 1), ('qinggangpu', 1), ('ryukuans', 1), ('shabali', 1), ('shuangqikou', 1), ('shushalian', 1), ('sotokufu', 1), ('tanemomi', 1), ('tanketok', 1)]...\n",
      "[2022-09-29 14:42:25,351] keeping 2000000 tokens which were in no less than 0 and no more than 3540000 (=100.0%) documents\n",
      "[2022-09-29 14:42:30,457] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:42:30,558] adding document #3540000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:42:56,239] discarding 32113 tokens: [('dsbu', 1), ('cinematographica', 1), ('simanje', 1), ('devenham', 1), ('karyakram', 1), ('kasakaru', 1), ('sarfaesi', 1), ('coentro', 1), ('cyria', 1), ('egrei', 1)]...\n",
      "[2022-09-29 14:42:56,240] keeping 2000000 tokens which were in no less than 0 and no more than 3550000 (=100.0%) documents\n",
      "[2022-09-29 14:43:01,304] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:43:01,373] adding document #3550000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:43:26,905] discarding 33241 tokens: [('serviceexchange', 1), ('krajinai', 1), ('paleseed', 1), ('plantago_lanceolata_plant', 1), ('abbaabbacdccdc', 1), ('flajan', 1), ('nonpossessively', 1), ('creechborough', 1), ('cructan', 1), ('crychbeorh', 1)]...\n",
      "[2022-09-29 14:43:26,907] keeping 2000000 tokens which were in no less than 0 and no more than 3560000 (=100.0%) documents\n",
      "[2022-09-29 14:43:30,586] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:43:30,655] adding document #3560000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:43:56,369] discarding 34012 tokens: [('f_otq', 1), ('f_passrq', 1), ('f_read', 1), ('f_t', 1), ('f_termin', 1), ('f_uread', 1), ('f_uwrite', 1), ('f_wait', 1), ('f_write', 1), ('ir_bc', 1)]...\n",
      "[2022-09-29 14:43:56,371] keeping 2000000 tokens which were in no less than 0 and no more than 3570000 (=100.0%) documents\n",
      "[2022-09-29 14:44:01,429] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:44:01,532] adding document #3570000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:44:27,810] discarding 31583 tokens: [('barbareña', 1), ('campagnoni', 1), ('fineco', 1), ('gonve', 1), ('ituriz', 1), ('carramer', 1), ('cornich', 1), ('dorotes', 1), ('octaire', 1), ('permereur', 1)]...\n",
      "[2022-09-29 14:44:27,813] keeping 2000000 tokens which were in no less than 0 and no more than 3580000 (=100.0%) documents\n",
      "[2022-09-29 14:44:31,747] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:44:31,816] adding document #3580000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:44:58,933] discarding 30659 tokens: [('eskrigge', 1), ('korsts', 1), ('mediaburn', 1), ('nixonette', 1), ('brevannes', 1), ('dépendante', 1), ('ourousseff', 1), ('ouvreur', 1), ('perade', 1), ('piérade', 1)]...\n",
      "[2022-09-29 14:44:58,934] keeping 2000000 tokens which were in no less than 0 and no more than 3590000 (=100.0%) documents\n",
      "[2022-09-29 14:45:04,026] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:45:04,126] adding document #3590000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:45:30,483] discarding 32278 tokens: [('castelferretti', 1), ('sverresdotter', 1), ('batkid', 1), ('fióktelepe', 1), ('bessonart', 1), ('ekmel', 1), ('analogspeicher', 1), ('mediatheks', 1), ('medienarchiv', 1), ('phonothek', 1)]...\n",
      "[2022-09-29 14:45:30,485] keeping 2000000 tokens which were in no less than 0 and no more than 3600000 (=100.0%) documents\n",
      "[2022-09-29 14:45:35,625] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:45:35,727] adding document #3600000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:46:02,250] discarding 34339 tokens: [('nahrāʾ', 1), ('nəhar', 1), ('sharieat', 1), ('tabaraya', 1), ('yurdnan', 1), ('ʾurdunn', 1), ('الحاصباني', 1), ('اللدان', 1), ('براغيث', 1), ('دردره', 1)]...\n",
      "[2022-09-29 14:46:02,252] keeping 2000000 tokens which were in no less than 0 and no more than 3610000 (=100.0%) documents\n",
      "[2022-09-29 14:46:07,617] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:46:07,718] adding document #3610000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:46:33,503] discarding 31748 tokens: [('farbod', 1), ('khampasath', 1), ('polifonte', 1), ('sionin', 1), ('poellinger', 1), ('radsi', 1), ('takefive', 1), ('wengari', 1), ('cluggie', 1), ('oppostition', 1)]...\n",
      "[2022-09-29 14:46:33,505] keeping 2000000 tokens which were in no less than 0 and no more than 3620000 (=100.0%) documents\n",
      "[2022-09-29 14:46:38,897] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:46:38,965] adding document #3620000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:47:03,482] discarding 29389 tokens: [('μιμεῖσθαι', 1), ('envaccounting', 1), ('envisionation', 1), ('naturalcapitalcoalition', 1), ('naturalcapitalforum', 1), ('teebweb', 1), ('white_cover', 1), ('macrosceloides', 1), ('borhorst', 1), ('iiguni', 1)]...\n",
      "[2022-09-29 14:47:03,483] keeping 2000000 tokens which were in no less than 0 and no more than 3630000 (=100.0%) documents\n",
      "[2022-09-29 14:47:07,205] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:47:07,273] adding document #3630000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:47:31,391] discarding 29130 tokens: [('le_port_de_la_daurade', 1), ('nef_de_la_cathédrale_saint', 1), ('nupces', 1), ('olmieres', 1), ('olmières', 1), ('orbessan_', 1), ('pierre_des_chartreux_', 1), ('plantes_', 1), ('raisin_', 1), ('resseguier_', 1)]...\n",
      "[2022-09-29 14:47:31,393] keeping 2000000 tokens which were in no less than 0 and no more than 3640000 (=100.0%) documents\n",
      "[2022-09-29 14:47:36,740] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:47:36,849] adding document #3640000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:48:01,211] discarding 32206 tokens: [('äspe', 1), ('appromaximately', 1), ('gallträsk', 1), ('gränkull', 1), ('kauniais', 1), ('afterassimilation', 1), ('autoritäärinen', 1), ('beforeassimilation', 1), ('chattailla', 1), ('chättäillä', 1)]...\n",
      "[2022-09-29 14:48:01,213] keeping 2000000 tokens which were in no less than 0 and no more than 3650000 (=100.0%) documents\n",
      "[2022-09-29 14:48:05,162] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:48:05,237] adding document #3650000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:48:28,147] discarding 29931 tokens: [('viscusus', 1), ('antiremodeling', 1), ('sandbells', 1), ('chunchuse', 1), ('chunguse', 1), ('chunguses', 1), ('greintz', 1), ('khunhuzy', 1), ('kreigschiffe', 1), ('manchzhurii', 1)]...\n",
      "[2022-09-29 14:48:28,148] keeping 2000000 tokens which were in no less than 0 and no more than 3660000 (=100.0%) documents\n",
      "[2022-09-29 14:48:31,825] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:48:31,899] adding document #3660000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:48:57,096] discarding 39984 tokens: [('canarsees', 1), ('minnewit', 1), ('mistuit', 1), ('spoonerizes', 1), ('flintstone§', 1), ('sennonian', 1), ('denoye', 1), ('moduk', 1), ('diplomathesis', 1), ('hexagonalhp', 1)]...\n",
      "[2022-09-29 14:48:57,098] keeping 2000000 tokens which were in no less than 0 and no more than 3670000 (=100.0%) documents\n",
      "[2022-09-29 14:49:00,753] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:49:00,823] adding document #3670000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:49:26,737] discarding 29061 tokens: [('conodontophora', 1), ('cornudininae', 1), ('cornuodontidae', 1), ('cryptotaxidae', 1), ('cyrtoniodontinae', 1), ('dapsilodontidae', 1), ('dischidognathidae', 1), ('distacodontida', 1), ('drepanodontinae', 1), ('drepanoistodontidae', 1)]...\n",
      "[2022-09-29 14:49:26,738] keeping 2000000 tokens which were in no less than 0 and no more than 3680000 (=100.0%) documents\n",
      "[2022-09-29 14:49:30,365] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:49:30,433] adding document #3680000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:49:56,169] discarding 32724 tokens: [('ctenodont', 1), ('decembranchiata', 1), ('ectocochliate', 1), ('interjocerids', 1), ('prorocadherin', 1), ('etdr', 1), ('misreportings', 1), ('mueseum', 1), ('caliatour', 1), ('directiekamervoc', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:49:56,171] keeping 2000000 tokens which were in no less than 0 and no more than 3690000 (=100.0%) documents\n",
      "[2022-09-29 14:49:59,761] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:49:59,830] adding document #3690000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:50:22,570] discarding 30476 tokens: [('reenstiernas', 1), ('enegada', 1), ('semrera', 1), ('bahkei', 1), ('adrianapole', 1), ('chelebowski', 1), ('gothicinvasions', 1), ('haemismontus', 1), ('kurdjalii', 1), ('kurdjaliistvo', 1)]...\n",
      "[2022-09-29 14:50:22,572] keeping 2000000 tokens which were in no less than 0 and no more than 3700000 (=100.0%) documents\n",
      "[2022-09-29 14:50:27,658] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:50:27,761] adding document #3700000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:50:51,781] discarding 30515 tokens: [('elitei', 1), ('holocaustfrom', 1), ('aibim', 1), ('rusni', 1), ('shankarapura', 1), ('decacorn', 1), ('trendyol', 1), ('diwaan', 1), ('ek_khilari_baawan_pattey', 1), ('hindigeetmala', 1)]...\n",
      "[2022-09-29 14:50:51,783] keeping 2000000 tokens which were in no less than 0 and no more than 3710000 (=100.0%) documents\n",
      "[2022-09-29 14:50:55,446] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:50:55,514] adding document #3710000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:51:21,725] discarding 34658 tokens: [('anaonn', 1), ('aréopage', 1), ('assolant', 1), ('bepred', 1), ('bezal', 1), ('breizad', 1), ('brézal', 1), ('dueuing', 1), ('dénicheurs', 1), ('extutique', 1)]...\n",
      "[2022-09-29 14:51:21,727] keeping 2000000 tokens which were in no less than 0 and no more than 3720000 (=100.0%) documents\n",
      "[2022-09-29 14:51:25,382] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:51:25,451] adding document #3720000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:51:55,405] discarding 34881 tokens: [('aridhu', 1), ('kalaiarasan', 1), ('kuruthiattam', 1), ('oliperukki', 1), ('hadla', 1), ('aajeedh', 1), ('adainthen', 1), ('avaloru', 1), ('bikshai', 1), ('chellakuralukkana', 1)]...\n",
      "[2022-09-29 14:51:55,406] keeping 2000000 tokens which were in no less than 0 and no more than 3730000 (=100.0%) documents\n",
      "[2022-09-29 14:51:59,153] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:51:59,223] adding document #3730000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:52:25,255] discarding 35816 tokens: [('tabrys', 1), ('chhapa', 1), ('deepsthamb', 1), ('dudhade', 1), ('braizes', 1), ('gauffres', 1), ('gurnets', 1), ('hatelet', 1), ('lovefood', 1), ('panadas', 1)]...\n",
      "[2022-09-29 14:52:25,257] keeping 2000000 tokens which were in no less than 0 and no more than 3740000 (=100.0%) documents\n",
      "[2022-09-29 14:52:28,967] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:52:29,037] adding document #3740000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:52:55,466] discarding 35070 tokens: [('abrigramma', 1), ('affinigramma', 1), ('angarogramma', 1), ('apochrysogramma', 1), ('burmogramma', 1), ('burmopsychops', 1), ('calophleba', 1), ('cretanallachiinae', 1), ('cretanallachius', 1), ('cretogramma', 1)]...\n",
      "[2022-09-29 14:52:55,469] keeping 2000000 tokens which were in no less than 0 and no more than 3750000 (=100.0%) documents\n",
      "[2022-09-29 14:53:00,587] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:53:00,689] adding document #3750000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:53:27,021] discarding 36443 tokens: [('cirrhophragma', 1), ('vallorani', 1), ('synaula', 1), ('melanula', 1), ('maeandria', 1), ('tignaria', 1), ('parabolella', 1), ('sølvguttene', 1), ('buić', 1), ('dajht', 1)]...\n",
      "[2022-09-29 14:53:27,023] keeping 2000000 tokens which were in no less than 0 and no more than 3760000 (=100.0%) documents\n",
      "[2022-09-29 14:53:30,699] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:53:30,769] adding document #3760000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:54:02,533] discarding 32214 tokens: [('measul', 1), ('aseeda', 1), ('fidushaus', 1), ('trübungen', 1), ('laureaux', 1), ('ldcy', 1), ('fneeq', 1), ('fppe', 1), ('ftpq', 1), ('gmmq', 1)]...\n",
      "[2022-09-29 14:54:02,535] keeping 2000000 tokens which were in no less than 0 and no more than 3770000 (=100.0%) documents\n",
      "[2022-09-29 14:54:07,586] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:54:07,687] adding document #3770000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:54:31,674] discarding 30853 tokens: [('filipinia', 1), ('philippiniana', 1), ('dagulf', 1), ('aaajoken', 1), ('waldprechtsweier', 1), ('erigonian', 1), ('anjanatchi', 1), ('anjanatchiamman', 1), ('antanatchi', 1), ('chandikesa', 1)]...\n",
      "[2022-09-29 14:54:31,675] keeping 2000000 tokens which were in no less than 0 and no more than 3780000 (=100.0%) documents\n",
      "[2022-09-29 14:54:36,694] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:54:36,794] adding document #3780000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:55:02,440] discarding 34003 tokens: [('opportunismus', 1), ('wwsasonefamily', 1), ('wwsfightingspirit', 1), ('wwsignitethelove', 1), ('wwsinthecity', 1), ('wwskeepthefaith', 1), ('wwsonebigfight', 1), ('wwsroadtoforever', 1), ('wwssourceofjoy', 1), ('wwsthebiggestfear', 1)]...\n",
      "[2022-09-29 14:55:02,441] keeping 2000000 tokens which were in no less than 0 and no more than 3790000 (=100.0%) documents\n",
      "[2022-09-29 14:55:06,099] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:55:06,169] adding document #3790000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:55:28,430] discarding 29130 tokens: [('mecelhatton', 1), ('totić', 1), ('gadjali', 1), ('jatib', 1), ('shade#1', 1), ('xepop', 1), ('xhwj', 1), ('xecsal', 1), ('sárkányország', 1), ('xhrasa', 1)]...\n",
      "[2022-09-29 14:55:28,431] keeping 2000000 tokens which were in no less than 0 and no more than 3800000 (=100.0%) documents\n",
      "[2022-09-29 14:55:32,149] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:55:32,218] adding document #3800000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:55:57,019] discarding 36018 tokens: [('damnandae', 1), ('diuinum', 1), ('jóhansson', 1), ('melussina', 1), ('hydrazyl', 1), ('mathem', 1), ('mediaforum', 1), ('pabsec', 1), ('движущихся', 1), ('aububakar', 1)]...\n",
      "[2022-09-29 14:55:57,021] keeping 2000000 tokens which were in no less than 0 and no more than 3810000 (=100.0%) documents\n",
      "[2022-09-29 14:56:02,140] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 14:56:02,243] adding document #3810000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:56:32,381] discarding 36591 tokens: [('neckpipe', 1), ('pbone', 1), ('riedlocker', 1), ('schlangenverzierungen', 1), ('tenorbassposaune', 1), ('boggingly', 1), ('brandyyy', 1), ('eeeeyack', 1), ('goonshowradio', 1), ('singez', 1)]...\n",
      "[2022-09-29 14:56:32,383] keeping 2000000 tokens which were in no less than 0 and no more than 3820000 (=100.0%) documents\n",
      "[2022-09-29 14:56:37,540] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:56:37,644] adding document #3820000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:57:02,403] discarding 33932 tokens: [('samegamemaniak', 1), ('scrush', 1), ('tapotron', 1), ('aninteger', 1), ('endotheliumsuch', 1), ('enteamoebas', 1), ('enteramin', 1), ('entoamoebas', 1), ('finidings', 1), ('hydroxytriptamine', 1)]...\n",
      "[2022-09-29 14:57:02,405] keeping 2000000 tokens which were in no less than 0 and no more than 3830000 (=100.0%) documents\n",
      "[2022-09-29 14:57:07,489] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:57:07,592] adding document #3830000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:57:32,253] discarding 36847 tokens: [('besedna', 1), ('besẹ', 1), ('celovito', 1), ('citatna', 1), ('deklaracije', 1), ('deklaracijo', 1), ('dostojanstva', 1), ('dostojanstvo', 1), ('držav', 1), ('državnimi', 1)]...\n",
      "[2022-09-29 14:57:32,255] keeping 2000000 tokens which were in no less than 0 and no more than 3840000 (=100.0%) documents\n",
      "[2022-09-29 14:57:37,342] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:57:37,445] adding document #3840000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:58:00,748] discarding 29179 tokens: [('ilimu', 1), ('leftinternet', 1), ('nakosteen', 1), ('bloodbringer', 1), ('brahtilis', 1), ('cordolane', 1), ('coronic', 1), ('demimon', 1), ('ritskaw', 1), ('skrant', 1)]...\n",
      "[2022-09-29 14:58:00,750] keeping 2000000 tokens which were in no less than 0 and no more than 3850000 (=100.0%) documents\n",
      "[2022-09-29 14:58:04,446] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:58:04,516] adding document #3850000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:58:30,610] discarding 40364 tokens: [('logudori', 1), ('luchía', 1), ('lìngua', 1), ('lìnia', 1), ('lòmpios', 1), ('macumadas', 1), ('magumadas', 1), ('mandicatu', 1), ('margiane', 1), ('margianes', 1)]...\n",
      "[2022-09-29 14:58:30,613] keeping 2000000 tokens which were in no less than 0 and no more than 3860000 (=100.0%) documents\n",
      "[2022-09-29 14:58:36,004] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:58:36,117] adding document #3860000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:59:02,749] discarding 32644 tokens: [('mekaj', 1), ('monelia', 1), ('paliettino', 1), ('kamenchenko', 1), ('radchuk', 1), ('блог', 1), ('еженедельника', 1), ('elakatothrix', 1), ('oocystis', 1), ('pseudokephrion', 1)]...\n",
      "[2022-09-29 14:59:02,751] keeping 2000000 tokens which were in no less than 0 and no more than 3870000 (=100.0%) documents\n",
      "[2022-09-29 14:59:07,952] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:59:08,054] adding document #3870000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:59:34,720] discarding 32170 tokens: [('massihiya', 1), ('beaujing', 1), ('javillonar', 1), ('جمکران', 1), ('cimfr', 1), ('cmpdil', 1), ('heymakers', 1), ('allostericity', 1), ('biomodulatory', 1), ('honaris', 1)]...\n",
      "[2022-09-29 14:59:34,722] keeping 2000000 tokens which were in no less than 0 and no more than 3880000 (=100.0%) documents\n",
      "[2022-09-29 14:59:38,437] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 14:59:38,507] adding document #3880000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:00:06,370] discarding 34577 tokens: [('conservativecentral', 1), ('coricare', 1), ('cuatòrdexe', 1), ('cumineca', 1), ('cuosa', 1), ('càdhu', 1), ('càne', 1), ('cànten', 1), ('cēl', 1), ('cōda', 1)]...\n",
      "[2022-09-29 15:00:06,372] keeping 2000000 tokens which were in no less than 0 and no more than 3890000 (=100.0%) documents\n",
      "[2022-09-29 15:00:11,504] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:00:11,606] adding document #3890000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:00:45,043] discarding 35574 tokens: [('alfmorgans', 1), ('brianburke', 1), ('carmenlawrence', 1), ('charlescourt', 1), ('colinbarnett', 1), ('davidbrand', 1), ('frankwilson', 1), ('frankwise', 1), ('geoffgallop', 1), ('georgeleake', 1)]...\n",
      "[2022-09-29 15:00:45,044] keeping 2000000 tokens which were in no less than 0 and no more than 3900000 (=100.0%) documents\n",
      "[2022-09-29 15:00:50,111] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:00:50,214] adding document #3900000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:01:15,885] discarding 33096 tokens: [('iǰuŋ', 1), ('kɔnu', 1), ('meṇḍa', 1), ('muql', 1), ('ntoʔ', 1), ('pjut', 1), ('počču', 1), ('punče', 1), ('putʼ', 1), ('putʼi', 1)]...\n",
      "[2022-09-29 15:01:15,886] keeping 2000000 tokens which were in no less than 0 and no more than 3910000 (=100.0%) documents\n",
      "[2022-09-29 15:01:20,927] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:01:21,029] adding document #3910000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:01:45,083] discarding 33401 tokens: [('halipleumon', 1), ('isēmerinai', 1), ('kantion', 1), ('katepsugmenē', 1), ('kukloi', 1), ('meiōsis', 1), ('mentonomon', 1), ('metuonidis', 1), ('nerigon', 1), ('penēs', 1)]...\n",
      "[2022-09-29 15:01:45,085] keeping 2000000 tokens which were in no less than 0 and no more than 3920000 (=100.0%) documents\n",
      "[2022-09-29 15:01:48,939] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:01:49,041] adding document #3920000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:02:14,818] discarding 33636 tokens: [('paramagmatic', 1), ('kruisoprichting', 1), ('sandable', 1), ('flagstaffand', 1), ('cleiss', 1), ('jershua', 1), ('nearunder', 1), ('aristonimos', 1), ('kallixenes', 1), ('meneclides', 1)]...\n",
      "[2022-09-29 15:02:14,819] keeping 2000000 tokens which were in no less than 0 and no more than 3930000 (=100.0%) documents\n",
      "[2022-09-29 15:02:18,517] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:02:18,587] adding document #3930000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:02:47,490] discarding 33981 tokens: [('kayatrayastotra', 1), ('lokapariksā', 1), ('lokātīta', 1), ('madhyamakasastrastuti', 1), ('mahāyānavimsika', 1), ('manjusriparamarthastuti', 1), ('mulamadhyamakavrtti', 1), ('mulasarvāstivadisrāmanerakārikā', 1), ('māhayānist', 1), ('mūlamadhyamakakārikās', 1)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:02:47,492] keeping 2000000 tokens which were in no less than 0 and no more than 3940000 (=100.0%) documents\n",
      "[2022-09-29 15:02:52,602] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:02:52,704] adding document #3940000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:03:19,061] discarding 34397 tokens: [('pendea', 1), ('pendeza', 1), ('vbstem', 1), ('wataenda', 1), ('drainge', 1), ('hibam', 1), ('hidrologico', 1), ('hydrodinamic', 1), ('navegabilidad', 1), ('pluviométrica', 1)]...\n",
      "[2022-09-29 15:03:19,062] keeping 2000000 tokens which were in no less than 0 and no more than 3950000 (=100.0%) documents\n",
      "[2022-09-29 15:03:22,705] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:03:22,774] adding document #3950000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:03:47,568] discarding 31445 tokens: [('zachie', 1), ('amanadon', 1), ('cumati', 1), ('curagua', 1), ('arshpreet', 1), ('etimarpu', 1), ('hussamuddin', 1), ('jeevanantham', 1), ('somveer', 1), ('kochipan', 1)]...\n",
      "[2022-09-29 15:03:47,570] keeping 2000000 tokens which were in no less than 0 and no more than 3960000 (=100.0%) documents\n",
      "[2022-09-29 15:03:51,205] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:03:51,274] adding document #3960000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:04:18,952] discarding 36094 tokens: [('laedatur', 1), ('perversorum', 1), ('puniatur', 1), ('vardhmana', 1), ('bumpkinish', 1), ('macronations', 1), ('micronationalists', 1), ('micropatrology', 1), ('ourania_gold_coins_', 1), ('paloman', 1)]...\n",
      "[2022-09-29 15:04:18,953] keeping 2000000 tokens which were in no less than 0 and no more than 3970000 (=100.0%) documents\n",
      "[2022-09-29 15:04:22,739] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:04:22,810] adding document #3970000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:04:47,904] discarding 30303 tokens: [('peindjalang', 1), ('wotojobaluk', 1), ('apogeemi', 1), ('astronaut_john_glenn_being_honored_', 1), ('astronautassignmentschart', 1), ('biopack', 1), ('erectionwb', 1), ('mcdonnellmercurycapsule', 1), ('missmi', 1), ('perigeemi', 1)]...\n",
      "[2022-09-29 15:04:47,906] keeping 2000000 tokens which were in no less than 0 and no more than 3980000 (=100.0%) documents\n",
      "[2022-09-29 15:04:53,135] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:04:53,238] adding document #3980000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:05:19,139] discarding 33324 tokens: [('dahurinaia', 1), ('keregsur', 1), ('lamiin', 1), ('mungunhurhree', 1), ('rinchinlhumbe', 1), ('shagaa', 1), ('tamgatai', 1), ('administrativeunit', 1), ('populationprospects', 1), ('socialcommission', 1)]...\n",
      "[2022-09-29 15:05:19,142] keeping 2000000 tokens which were in no less than 0 and no more than 3990000 (=100.0%) documents\n",
      "[2022-09-29 15:05:24,309] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:05:24,413] adding document #3990000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:05:51,498] discarding 33189 tokens: [('superglycerinated', 1), ('autosolvolysis', 1), ('alfès', 1), ('ausetanes', 1), ('butsenit', 1), ('caparrella', 1), ('ilerdam', 1), ('llatinoamericà', 1), ('sanuí', 1), ('socioeconòmic', 1)]...\n",
      "[2022-09-29 15:05:51,500] keeping 2000000 tokens which were in no less than 0 and no more than 4000000 (=100.0%) documents\n",
      "[2022-09-29 15:05:56,632] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:05:56,733] adding document #4000000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:06:25,297] discarding 34053 tokens: [('brahestadium', 1), ('brestia', 1), ('brestum', 1), ('brisgoviae', 1), ('brivates', 1), ('brugae', 1), ('brunntrudum', 1), ('bruntraut', 1), ('budapestum', 1), ('budovisium', 1)]...\n",
      "[2022-09-29 15:06:25,298] keeping 2000000 tokens which were in no less than 0 and no more than 4010000 (=100.0%) documents\n",
      "[2022-09-29 15:06:30,423] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:06:30,526] adding document #4010000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:06:56,051] discarding 34285 tokens: [('bojaro', 1), ('buhigas', 1), ('cincúnegui', 1), ('comfloan', 1), ('comgeim', 1), ('comsubmar', 1), ('dgcsem', 1), ('escrigas', 1), ('estrán', 1), ('hidalga', 1)]...\n",
      "[2022-09-29 15:06:56,053] keeping 2000000 tokens which were in no less than 0 and no more than 4020000 (=100.0%) documents\n",
      "[2022-09-29 15:07:01,550] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:07:01,653] adding document #4020000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:07:26,875] discarding 34809 tokens: [('kerius', 1), ('mebusan', 1), ('ballybot', 1), ('rannafast', 1), ('simeuluensis', 1), ('tsukadai', 1), ('yusukei', 1), ('tatyama', 1), ('saidock', 1), ('basindale', 1)]...\n",
      "[2022-09-29 15:07:26,876] keeping 2000000 tokens which were in no less than 0 and no more than 4030000 (=100.0%) documents\n",
      "[2022-09-29 15:07:31,767] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:07:31,872] adding document #4030000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:08:00,023] discarding 36847 tokens: [('genearal', 1), ('koilakuntla', 1), ('loporto', 1), ('siehndel', 1), ('sstastny', 1), ('jeffett', 1), ('gravitywall', 1), ('ninelie', 1), ('tielle', 1), ('valhaitrising', 1)]...\n",
      "[2022-09-29 15:08:00,025] keeping 2000000 tokens which were in no less than 0 and no more than 4040000 (=100.0%) documents\n",
      "[2022-09-29 15:08:04,203] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:08:04,273] adding document #4040000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:08:32,498] discarding 35288 tokens: [('slicky', 1), ('aufrichtung', 1), ('bachereau', 1), ('darstellungsweisen', 1), ('frankurt', 1), ('fügung', 1), ('geselschap', 1), ('historienbild', 1), ('kaiserproklamation', 1), ('kokalj', 1)]...\n",
      "[2022-09-29 15:08:32,499] keeping 2000000 tokens which were in no less than 0 and no more than 4050000 (=100.0%) documents\n",
      "[2022-09-29 15:08:37,677] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:08:37,782] adding document #4050000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:09:10,375] discarding 57397 tokens: [('greenstreaked', 1), ('hingemouth', 1), ('nefeles', 1), ('kimpumpa', 1), ('liosomadoras', 1), ('lumphead', 1), ('ηρώδειο', 1), ('ηχογραφήσεις', 1), ('multifsciatus', 1), ('orthogoniata', 1)]...\n",
      "[2022-09-29 15:09:10,377] keeping 2000000 tokens which were in no less than 0 and no more than 4060000 (=100.0%) documents\n",
      "[2022-09-29 15:09:15,546] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:09:15,654] adding document #4060000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:09:44,521] discarding 34276 tokens: [('bluas', 1), ('bonaj', 1), ('bonajn', 1), ('botelon', 1), ('brilan', 1), ('brilanta', 1), ('brosado', 1), ('cikatroj', 1), ('deprenis', 1), ('domaĉon', 1)]...\n",
      "[2022-09-29 15:09:44,522] keeping 2000000 tokens which were in no less than 0 and no more than 4070000 (=100.0%) documents\n",
      "[2022-09-29 15:09:48,246] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:09:48,316] adding document #4070000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:10:13,956] discarding 31651 tokens: [('axsiz', 1), ('hirafumi', 1), ('rionos', 1), ('shinba', 1), ('changhee', 1), ('엠스트리트', 1), ('iscaroo', 1), ('loucheaux', 1), ('belvito', 1), ('gollinglith', 1)]...\n",
      "[2022-09-29 15:10:13,958] keeping 2000000 tokens which were in no less than 0 and no more than 4080000 (=100.0%) documents\n",
      "[2022-09-29 15:10:19,094] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:10:19,196] adding document #4080000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:10:45,458] discarding 33457 tokens: [('elsinorian', 1), ('gandalfson', 1), ('mordrup', 1), ('nøjsomheden', 1), ('vapnagård', 1), ('årgangsøl', 1), ('alebosjön', 1), ('alhamn', 1), ('ansmark', 1), ('anumark', 1)]...\n",
      "[2022-09-29 15:10:45,459] keeping 2000000 tokens which were in no less than 0 and no more than 4090000 (=100.0%) documents\n",
      "[2022-09-29 15:10:50,657] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:10:50,761] adding document #4090000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:11:18,748] discarding 36680 tokens: [('movzl', 1), ('retrn', 1), ('simulogic', 1), ('skpbn', 1), ('skpbz', 1), ('skpdn', 1), ('skpdz', 1), ('frisleven', 1), ('ruijsbroek', 1), ('fasfax', 1)]...\n",
      "[2022-09-29 15:11:18,750] keeping 2000000 tokens which were in no less than 0 and no more than 4100000 (=100.0%) documents\n",
      "[2022-09-29 15:11:22,457] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:11:22,527] adding document #4100000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:11:48,111] discarding 40221 tokens: [('muḳaddimetü', 1), ('nĕr', 1), ('taharóg', 1), ('brinklehof', 1), ('hofbrincl', 1), ('hofbrinkle', 1), ('honclbrif', 1), ('honkelbrif', 1), ('berufungsgericht', 1), ('doublejeopardyreform', 1)]...\n",
      "[2022-09-29 15:11:48,112] keeping 2000000 tokens which were in no less than 0 and no more than 4110000 (=100.0%) documents\n",
      "[2022-09-29 15:11:51,769] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:11:51,840] adding document #4110000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:12:17,047] discarding 39402 tokens: [('正日', 1), ('水瀨日', 1), ('百種', 1), ('禮會冬至', 1), ('禮盂蘭', 1), ('節上元', 1), ('節下元', 1), ('節清明', 1), ('節竈君', 1), ('節重九', 1)]...\n",
      "[2022-09-29 15:12:17,048] keeping 2000000 tokens which were in no less than 0 and no more than 4120000 (=100.0%) documents\n",
      "[2022-09-29 15:12:20,778] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:12:20,849] adding document #4120000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:12:47,779] discarding 33467 tokens: [('mischehenstreit', 1), ('newmediaartprojectnetwork', 1), ('nussholz', 1), ('reichskontingent', 1), ('rheintower', 1), ('riverrhine', 1), ('severeinskirche', 1), ('topogeographer', 1), ('brahamajala', 1), ('xiàshui', 1)]...\n",
      "[2022-09-29 15:12:47,780] keeping 2000000 tokens which were in no less than 0 and no more than 4130000 (=100.0%) documents\n",
      "[2022-09-29 15:12:51,590] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:12:51,661] adding document #4130000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:13:17,817] discarding 43447 tokens: [('smeltbrook', 1), ('akubu', 1), ('differyes', 1), ('leþing', 1), ('munabechisen', 1), ('takumai', 1), ('exocervix', 1), ('outward§', 1), ('cantoretti', 1), ('castrados', 1)]...\n",
      "[2022-09-29 15:13:17,818] keeping 2000000 tokens which were in no less than 0 and no more than 4140000 (=100.0%) documents\n",
      "[2022-09-29 15:13:23,232] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:13:23,338] adding document #4140000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:13:49,938] discarding 36568 tokens: [('magrao', 1), ('gursimrat', 1), ('lalthuammawia', 1), ('soram', 1), ('stojanovič', 1), ('vadachalam', 1), ('zohmingliana', 1), ('hattanda', 1), ('notsuda', 1), ('elsinho', 1)]...\n",
      "[2022-09-29 15:13:49,940] keeping 2000000 tokens which were in no less than 0 and no more than 4150000 (=100.0%) documents\n",
      "[2022-09-29 15:13:53,708] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:13:53,779] adding document #4150000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:14:22,331] discarding 50812 tokens: [('flagellatum', 1), ('genpeiense', 1), ('kryla', 1), ('udka', 1), ('forgler', 1), ('unguiculatum', 1), ('glabripenne', 1), ('goethghebuer', 1), ('obscuritory', 1), ('senguni', 1)]...\n",
      "[2022-09-29 15:14:22,334] keeping 2000000 tokens which were in no less than 0 and no more than 4160000 (=100.0%) documents\n",
      "[2022-09-29 15:14:26,829] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:14:26,935] adding document #4160000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:14:53,957] discarding 45783 tokens: [('cisey', 1), ('derussify', 1), ('ikayop', 1), ('iyoykir', 1), ('jōmons', 1), ('koichii', 1), ('matanpushi', 1), ('matsumomushi', 1), ('mekuragumo', 1), ('ninkari', 1)]...\n",
      "[2022-09-29 15:14:53,958] keeping 2000000 tokens which were in no less than 0 and no more than 4170000 (=100.0%) documents\n",
      "[2022-09-29 15:14:57,737] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:14:57,809] adding document #4170000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:15:27,518] discarding 33077 tokens: [('zeylonibus', 1), ('gruntov', 1), ('kinpi', 1), ('mutʌ', 1), ('offpmo', 1), ('patʌ', 1), ('pesü', 1), ('phylolinguistic', 1), ('pissü', 1), ('saɣa', 1)]...\n",
      "[2022-09-29 15:15:27,520] keeping 2000000 tokens which were in no less than 0 and no more than 4180000 (=100.0%) documents\n",
      "[2022-09-29 15:15:32,770] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:15:32,874] adding document #4180000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:16:00,863] discarding 35008 tokens: [('educationruth', 1), ('typicalalbedo', 1), ('aanother', 1), ('alabahmu', 1), ('alabamo', 1), ('alabamu', 1), ('alebamon', 1), ('alibamou', 1), ('allibamou', 1), ('buddharaksa', 1)]...\n",
      "[2022-09-29 15:16:00,865] keeping 2000000 tokens which were in no less than 0 and no more than 4190000 (=100.0%) documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:16:04,620] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:16:04,690] adding document #4190000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:16:31,746] discarding 34441 tokens: [('paranganj', 2), ('sirta', 2), ('moewhare', 2), ('mākino', 2), ('opopoti', 2), ('peterehema', 2), ('pākira', 2), ('tamarawaho', 2), ('tapukino', 2), ('tawhitinui', 2)]...\n",
      "[2022-09-29 15:16:31,748] keeping 2000000 tokens which were in no less than 0 and no more than 4200000 (=100.0%) documents\n",
      "[2022-09-29 15:16:36,933] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:16:37,037] adding document #4200000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:17:02,374] discarding 32120 tokens: [('čаvić', 2), ('orbitbeyond', 2), ('lwale', 2), ('bodumatau', 2), ('dikgakana', 2), ('kaepe', 2), ('lediba', 2), ('makalamabedi', 2), ('mapororo', 2), ('mokgalo', 2)]...\n",
      "[2022-09-29 15:17:02,376] keeping 2000000 tokens which were in no less than 0 and no more than 4210000 (=100.0%) documents\n",
      "[2022-09-29 15:17:06,089] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:17:06,159] adding document #4210000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:17:32,925] discarding 33989 tokens: [('takatoro', 2), ('soach', 2), ('hlavního', 2), ('dokomademo', 2), ('attyé', 2), ('aughnacreevy', 2), ('miksalište', 2), ('jevrosimovic', 2), ('jaggln', 2), ('bazoyenza', 2)]...\n",
      "[2022-09-29 15:17:32,927] keeping 2000000 tokens which were in no less than 0 and no more than 4220000 (=100.0%) documents\n",
      "[2022-09-29 15:17:38,165] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:17:38,269] adding document #4220000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:18:04,806] discarding 37943 tokens: [('bmye', 2), ('bomayé', 2), ('jahyanai', 2), ('jaymax', 2), ('kayz', 2), ('matéta', 2), ('équilibré', 2), ('iraee', 2), ('clemot', 2), ('abudi', 2)]...\n",
      "[2022-09-29 15:18:04,808] keeping 2000000 tokens which were in no less than 0 and no more than 4230000 (=100.0%) documents\n",
      "[2022-09-29 15:18:09,994] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:18:10,098] adding document #4230000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:18:41,740] discarding 29100 tokens: [('cenanges', 2), ('contigucephalus', 2), ('cyclometopum', 2), ('dawnaria', 2), ('dawnarioides', 2), ('dysimia', 2), ('goneokara', 2), ('herpis', 2), ('lamenia', 2), ('malenia', 2)]...\n",
      "[2022-09-29 15:18:41,742] keeping 2000000 tokens which were in no less than 0 and no more than 4240000 (=100.0%) documents\n",
      "[2022-09-29 15:18:45,569] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:18:45,639] adding document #4240000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:19:13,601] discarding 32627 tokens: [('achilty', 2), ('jezeki', 2), ('przedr', 2), ('afrosmicronyx', 2), ('hedychrous', 2), ('miarus', 2), ('promecotarsus', 2), ('sharpia', 2), ('smicrorhynchus', 2), ('topelatus', 2)]...\n",
      "[2022-09-29 15:19:13,602] keeping 2000000 tokens which were in no less than 0 and no more than 4250000 (=100.0%) documents\n",
      "[2022-09-29 15:19:17,383] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:19:17,453] adding document #4250000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:19:52,318] discarding 32770 tokens: [('iriartei', 2), ('jinhongensis', 2), ('mattinglyi', 2), ('nigricephala', 2), ('pallidoventer', 2), ('rachoui', 2), ('trapidoi', 2), ('wepster', 2), ('atomyria', 2), ('callisina', 2)]...\n",
      "[2022-09-29 15:19:52,319] keeping 2000000 tokens which were in no less than 0 and no more than 4260000 (=100.0%) documents\n",
      "[2022-09-29 15:19:57,795] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:19:57,897] adding document #4260000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:20:31,005] discarding 36959 tokens: [('octotoma', 2), ('pentispa', 2), ('xenochalepus', 2), ('atramontensis', 2), ('betpakdalensis', 2), ('fumosipennis', 2), ('gineri', 2), ('impercepta', 2), ('jakowleffi', 2), ('kilimandjaroensis', 2)]...\n",
      "[2022-09-29 15:20:31,007] keeping 2000000 tokens which were in no less than 0 and no more than 4270000 (=100.0%) documents\n",
      "[2022-09-29 15:20:36,219] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:20:36,323] adding document #4270000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:21:04,183] discarding 34265 tokens: [('coeruleocephalus', 2), ('cupulifer', 2), ('ilonae', 2), ('kechevi', 2), ('mironovi', 2), ('sublamellatus', 2), ('taeniomerus', 2), ('bouttemy', 2), ('goetgeluck', 2), ('herbinet', 2)]...\n",
      "[2022-09-29 15:21:04,185] keeping 2000000 tokens which were in no less than 0 and no more than 4280000 (=100.0%) documents\n",
      "[2022-09-29 15:21:09,368] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:21:09,471] adding document #4280000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:21:35,804] discarding 29725 tokens: [('scanloni', 2), ('depressiuscula', 2), ('traili', 2), ('subcalvus', 2), ('okok', 2), ('displicata', 2), ('haplopus', 2), ('appenhageni', 2), ('hustachei', 2), ('punctatulus', 2)]...\n",
      "[2022-09-29 15:21:35,806] keeping 2000000 tokens which were in no less than 0 and no more than 4290000 (=100.0%) documents\n",
      "[2022-09-29 15:21:41,245] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:21:41,354] adding document #4290000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:22:06,683] discarding 33515 tokens: [('mantilleri', 2), ('stereodermus', 2), ('sreg', 2), ('chajian', 2), ('laodonglu', 2), ('qushi', 2), ('shenglilu', 2), ('探親家', 2), ('ḥezyonot', 2), ('brolaski', 2)]...\n",
      "[2022-09-29 15:22:06,685] keeping 2000000 tokens which were in no less than 0 and no more than 4300000 (=100.0%) documents\n",
      "[2022-09-29 15:22:11,920] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:22:12,025] adding document #4300000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:22:39,161] discarding 29709 tokens: [('barraudi', 2), ('cribata', 2), ('amplicella', 2), ('auripilosa', 2), ('subsulcata', 2), ('nybom', 2), ('transformata', 2), ('hakusanus', 2), ('quinquedentatus', 2), ('shibuyai', 2)]...\n",
      "[2022-09-29 15:22:39,163] keeping 2000000 tokens which were in no less than 0 and no more than 4310000 (=100.0%) documents\n",
      "[2022-09-29 15:22:44,354] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:22:44,457] adding document #4310000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:23:10,800] discarding 30386 tokens: [('zilvar', 2), ('hychkin', 2), ('kheison', 2), ('khyznikov', 2), ('korotkykh', 2), ('malkhasov', 2), ('oryekhov', 2), ('pravoverov', 2), ('shylovskyi', 2), ('sosicki', 2)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:23:10,802] keeping 2000000 tokens which were in no less than 0 and no more than 4320000 (=100.0%) documents\n",
      "[2022-09-29 15:23:15,945] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:23:16,048] adding document #4320000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:23:42,864] discarding 35689 tokens: [('latecompressus', 2), ('mahafali', 2), ('mamibillae', 2), ('maniensis', 2), ('nepocranus', 2), ('ominosus', 2), ('palatus', 2), ('pardous', 2), ('perlongus', 2), ('permarginatus', 2)]...\n",
      "[2022-09-29 15:23:42,866] keeping 2000000 tokens which were in no less than 0 and no more than 4330000 (=100.0%) documents\n",
      "[2022-09-29 15:23:48,162] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:23:48,265] adding document #4330000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:24:15,822] discarding 32171 tokens: [('turyna', 2), ('cebines', 2), ('atelid', 2), ('anrp', 2), ('chaparralensis', 2), ('lophiodolodus', 2), ('olini', 2), ('protheosodon', 2), ('nicklesia', 2), ('pulchellia', 2)]...\n",
      "[2022-09-29 15:24:15,824] keeping 2000000 tokens which were in no less than 0 and no more than 4340000 (=100.0%) documents\n",
      "[2022-09-29 15:24:20,930] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:24:21,032] adding document #4340000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:24:50,525] discarding 33572 tokens: [('kichiji', 2), ('graffitiger', 2), ('kyjev', 2), ('reraju', 2), ('scaevilius', 2), ('scaevinius', 2), ('scaevius', 2), ('akumulátor', 2), ('hůř', 2), ('railoa', 2)]...\n",
      "[2022-09-29 15:24:50,527] keeping 2000000 tokens which were in no less than 0 and no more than 4350000 (=100.0%) documents\n",
      "[2022-09-29 15:24:55,705] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:24:55,809] adding document #4350000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:25:32,838] discarding 33325 tokens: [('baridah', 2), ('baritus', 2), ('barlus', 2), ('besarun', 2), ('bostamin', 2), ('bugung', 2), ('bulangan', 2), ('chinly', 2), ('chrisnadia', 2), ('chyang', 2)]...\n",
      "[2022-09-29 15:25:32,839] keeping 2000000 tokens which were in no less than 0 and no more than 4360000 (=100.0%) documents\n",
      "[2022-09-29 15:25:36,631] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:25:36,703] adding document #4360000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:26:03,736] discarding 30213 tokens: [('meridionator', 2), ('fulvator', 2), ('woldstedt', 2), ('metopoplax', 2), ('microtechnites', 2), ('micrutalis', 2), ('atymna', 2), ('cyrtolobus', 2), ('grandolobus', 2), ('smilia', 2)]...\n",
      "[2022-09-29 15:26:03,738] keeping 2000000 tokens which were in no less than 0 and no more than 4370000 (=100.0%) documents\n",
      "[2022-09-29 15:26:08,873] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:26:08,976] adding document #4370000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:26:35,048] discarding 34503 tokens: [('明敬皇后', 2), ('郭氏', 2), ('pontifs', 2), ('salvart', 2), ('flamboyante', 2), ('filmograf', 2), ('张值豪', 2), ('黄李白云', 2), ('assombração', 2), ('caranguejo', 2)]...\n",
      "[2022-09-29 15:26:35,049] keeping 2000000 tokens which were in no less than 0 and no more than 4380000 (=100.0%) documents\n",
      "[2022-09-29 15:26:40,214] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:26:40,320] adding document #4380000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:27:09,757] discarding 33435 tokens: [('tsuikyū', 2), ('lopusznick', 2), ('toramus', 2), ('melsheimeri', 2), ('marseile', 2), ('contrell', 2), ('milijić', 2), ('летучие', 2), ('kholeif', 2), ('brány', 2)]...\n",
      "[2022-09-29 15:27:09,759] keeping 2000000 tokens which were in no less than 0 and no more than 4390000 (=100.0%) documents\n",
      "[2022-09-29 15:27:14,943] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:27:15,047] adding document #4390000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:27:44,458] discarding 33171 tokens: [('garoli', 2), ('weaverindependent', 2), ('futbolteca', 2), ('corrosus', 2), ('dandalu', 2), ('furcicollis', 2), ('keralicus', 2), ('montreuili', 2), ('petrovitzi', 2), ('rufobasalis', 2)]...\n",
      "[2022-09-29 15:27:44,460] keeping 2000000 tokens which were in no less than 0 and no more than 4400000 (=100.0%) documents\n",
      "[2022-09-29 15:27:48,179] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:27:48,250] adding document #4400000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:28:17,041] discarding 32667 tokens: [('城东村', 2), ('富强村', 2), ('滨湖村', 2), ('delemarle', 2), ('cigal', 2), ('nudisiri', 2), ('brönnum', 2), ('caricum', 2), ('hurmic', 2), ('gaaij', 2)]...\n",
      "[2022-09-29 15:28:17,043] keeping 2000000 tokens which were in no less than 0 and no more than 4410000 (=100.0%) documents\n",
      "[2022-09-29 15:28:22,169] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:28:22,272] adding document #4410000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:28:49,523] discarding 32683 tokens: [('kratzig', 2), ('syuzeva', 2), ('gaspic', 2), ('melleby', 2), ('sibabau', 2), ('percossi', 2), ('velunachi', 2), ('khoroshyovsky', 2), ('канонерская', 2), ('мореходная', 2)]...\n",
      "[2022-09-29 15:28:49,530] keeping 2000000 tokens which were in no less than 0 and no more than 4420000 (=100.0%) documents\n",
      "[2022-09-29 15:28:54,759] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:28:54,862] adding document #4420000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:29:28,808] discarding 92616 tokens: [('vanthaanadi', 2), ('veesuvom', 2), ('kragra', 2), ('canaga', 2), ('jinghi', 2), ('bahuwa', 2), ('samanpur', 2), ('dadaonan', 2), ('feishajiao', 2), ('autocity', 2)]...\n",
      "[2022-09-29 15:29:28,810] keeping 2000000 tokens which were in no less than 0 and no more than 4430000 (=100.0%) documents\n",
      "[2022-09-29 15:29:33,989] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:29:34,101] adding document #4430000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:30:03,430] discarding 35979 tokens: [('skubík', 2), ('모르잖아요', 2), ('caetratus', 2), ('weathrall', 2), ('triazolite', 2), ('skyminhyuk', 2), ('도박', 2), ('신사', 2), ('polodig', 2), ('thioalkalibacter', 2)]...\n",
      "[2022-09-29 15:30:03,432] keeping 2000000 tokens which were in no less than 0 and no more than 4440000 (=100.0%) documents\n",
      "[2022-09-29 15:30:07,228] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:30:07,299] adding document #4440000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:30:36,496] discarding 34162 tokens: [('kennealey', 2), ('akhiya', 2), ('palsin', 2), ('tuikong', 2), ('aerilata', 2), ('burgenrunde', 2), ('lils', 2), ('woiski', 2), ('boosenburg', 2), ('arcticisoli', 2)]...\n",
      "[2022-09-29 15:30:36,498] keeping 2000000 tokens which were in no less than 0 and no more than 4450000 (=100.0%) documents\n",
      "[2022-09-29 15:30:42,021] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:30:42,125] adding document #4450000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:31:15,954] discarding 31050 tokens: [('penright', 2), ('ulatoski', 2), ('åblad', 2), ('kornharber', 2), ('leckström', 2), ('särneman', 2), ('ibéyise', 2), ('chteniia', 2), ('shisong', 2), ('belaia', 2)]...\n",
      "[2022-09-29 15:31:15,955] keeping 2000000 tokens which were in no less than 0 and no more than 4460000 (=100.0%) documents\n",
      "[2022-09-29 15:31:21,090] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:31:21,194] adding document #4460000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:31:51,441] discarding 36971 tokens: [('tennichi', 2), ('maareform', 2), ('abstinenter', 2), ('shiloi', 2), ('okutan', 2), ('mürmann', 2), ('borketey', 2), ('supanai', 2), ('yellowkies', 2), ('viramdeva', 2)]...\n",
      "[2022-09-29 15:31:51,443] keeping 2000000 tokens which were in no less than 0 and no more than 4470000 (=100.0%) documents\n",
      "[2022-09-29 15:31:56,329] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:31:56,401] adding document #4470000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:32:23,534] discarding 30017 tokens: [('cahle', 2), ('cătun', 2), ('descoperite', 2), ('glorioasa', 2), ('grăjdana', 2), ('leurdeni', 2), ('nișcov', 2), ('pribegie', 2), ('romanoslavica', 2), ('toponimică', 2)]...\n",
      "[2022-09-29 15:32:23,535] keeping 2000000 tokens which were in no less than 0 and no more than 4480000 (=100.0%) documents\n",
      "[2022-09-29 15:32:27,275] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:32:27,345] adding document #4480000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:32:55,493] discarding 35395 tokens: [('asllinea', 2), ('yuzbashyan', 2), ('guheshvarapataka', 2), ('shubhakara', 2), ('harcevic', 2), ('salkicevic', 2), ('unkic', 2), ('naratreekul', 2), ('sitchomthong', 2), ('chainoi', 2)]...\n",
      "[2022-09-29 15:32:55,495] keeping 2000000 tokens which were in no less than 0 and no more than 4490000 (=100.0%) documents\n",
      "[2022-09-29 15:33:00,734] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:33:00,839] adding document #4490000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:33:28,027] discarding 33408 tokens: [('epeiromys', 2), ('fedti', 2), ('fossorcastor', 2), ('geringia', 2), ('gladiofex', 2), ('haplomys', 2), ('hartshornianus', 2), ('hippodus', 2), ('hitonkala', 2), ('ironcloudi', 2)]...\n",
      "[2022-09-29 15:33:28,029] keeping 2000000 tokens which were in no less than 0 and no more than 4500000 (=100.0%) documents\n",
      "[2022-09-29 15:33:31,774] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:33:31,845] adding document #4500000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:34:01,397] discarding 35061 tokens: [('pariogonus', 2), ('patefacta', 2), ('pecorae', 2), ('pelicatus', 2), ('peracuminata', 2), ('persites', 2), ('philhydrus', 2), ('popoagicum', 2), ('praepropera', 2), ('praetutus', 2)]...\n",
      "[2022-09-29 15:34:01,399] keeping 2000000 tokens which were in no less than 0 and no more than 4510000 (=100.0%) documents\n",
      "[2022-09-29 15:34:06,547] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:34:06,651] adding document #4510000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:34:34,748] discarding 35254 tokens: [('echanthus', 2), ('echinocythereis', 2), ('elongatoidea', 2), ('elongatoides', 2), ('enterogramma', 2), ('entosolenia', 2), ('eocenense', 2), ('eocenensis', 2), ('eocensis', 2), ('eoclathurella', 2)]...\n",
      "[2022-09-29 15:34:34,751] keeping 2000000 tokens which were in no less than 0 and no more than 4520000 (=100.0%) documents\n",
      "[2022-09-29 15:34:40,006] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:34:40,111] adding document #4520000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:35:07,574] discarding 34769 tokens: [('spiroxybeloceras', 2), ('tenuiplicatus', 2), ('ascarinites', 2), ('barwini', 2), ('bellsanum', 2), ('belviderensis', 2), ('bighornensis', 2), ('bullopsis', 2), ('colpodontosaurus', 2), ('cryptometoicoceras', 2)]...\n",
      "[2022-09-29 15:35:07,576] keeping 2000000 tokens which were in no less than 0 and no more than 4530000 (=100.0%) documents\n",
      "[2022-09-29 15:35:11,367] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:35:11,439] adding document #4530000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:35:38,687] discarding 31152 tokens: [('washakiensis', 2), ('libouton', 2), ('bágh', 2), ('kánkaria', 2), ('tápti', 2), ('ágra', 2), ('pixelberry', 2), ('filargo', 2), ('kaveny', 2), ('thumbmap', 2)]...\n",
      "[2022-09-29 15:35:38,689] keeping 2000000 tokens which were in no less than 0 and no more than 4540000 (=100.0%) documents\n",
      "[2022-09-29 15:35:44,020] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:35:44,124] adding document #4540000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:36:10,516] discarding 32238 tokens: [('modiella', 2), ('newportopora', 2), ('nieszkowskia', 2), ('numismoides', 2), ('oepikodus', 2), ('ozarkina', 2), ('pachydicta', 2), ('pagodia', 2), ('palaeocystites', 2), ('paleschara', 2)]...\n",
      "[2022-09-29 15:36:10,518] keeping 2000000 tokens which were in no less than 0 and no more than 4550000 (=100.0%) documents\n",
      "[2022-09-29 15:36:15,726] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:36:15,830] adding document #4550000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:36:44,149] discarding 42623 tokens: [('permopanorpa', 2), ('permopsylla', 2), ('phasmatocycas', 2), ('phenopterum', 2), ('polaricyclus', 2), ('pompilioides', 2), ('probnis', 2), ('properrinites', 2), ('protereisma', 2), ('sandrewia', 2)]...\n",
      "[2022-09-29 15:36:44,151] keeping 2000000 tokens which were in no less than 0 and no more than 4560000 (=100.0%) documents\n",
      "[2022-09-29 15:36:49,351] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:36:49,457] adding document #4560000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:37:16,062] discarding 32588 tokens: [('subjugata', 2), ('subquatra', 2), ('sullivanti', 2), ('synaptophylloides', 2), ('troosticrinus', 2), ('twenhofelella', 2), ('verneuliana', 2), ('versaillesensis', 2), ('vestusta', 2), ('waldronensis', 2)]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:37:16,064] keeping 2000000 tokens which were in no less than 0 and no more than 4570000 (=100.0%) documents\n",
      "[2022-09-29 15:37:21,260] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:37:21,365] adding document #4570000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:37:49,669] discarding 37358 tokens: [('macropyge', 2), ('maladensis', 2), ('marginauctum', 2), ('menoparia', 2), ('metabowmania', 2), ('mohawkensis', 2), ('morozoviella', 2), ('neoeridotrypella', 2), ('oryctocare', 2), ('pachycranium', 2)]...\n",
      "[2022-09-29 15:37:49,671] keeping 2000000 tokens which were in no less than 0 and no more than 4580000 (=100.0%) documents\n",
      "[2022-09-29 15:37:53,562] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:37:53,634] adding document #4580000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:38:20,676] discarding 36715 tokens: [('paradisensis', 2), ('parallella', 2), ('parapenascoceras', 2), ('parvicristus', 2), ('paurorhyncha', 2), ('perchaensis', 2), ('permiensis', 2), ('planotectus', 2), ('popanoceras', 2), ('porostictia', 2)]...\n",
      "[2022-09-29 15:38:20,678] keeping 2000000 tokens which were in no less than 0 and no more than 4590000 (=100.0%) documents\n",
      "[2022-09-29 15:38:25,899] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:38:26,006] adding document #4590000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:38:53,930] discarding 38709 tokens: [('breestede', 2), ('caajte', 2), ('rutse', 2), ('schoenderwoert', 2), ('poncedelon', 2), ('gunash', 2), ('thavanesvaran', 2), ('ntyam', 2), ('bjertnes', 2), ('kehalacha', 2)]...\n",
      "[2022-09-29 15:38:53,932] keeping 2000000 tokens which were in no less than 0 and no more than 4600000 (=100.0%) documents\n",
      "[2022-09-29 15:38:59,118] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:38:59,224] adding document #4600000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:39:31,822] discarding 41542 tokens: [('pihurik', 2), ('szolgálatok', 2), ('tevékenysége', 2), ('állambiztonsági', 2), ('helye', 2), ('identitás', 2), ('konferenciák', 2), ('koordinátái', 2), ('világtörténet', 2), ('útjai', 2)]...\n",
      "[2022-09-29 15:39:31,824] keeping 2000000 tokens which were in no less than 0 and no more than 4610000 (=100.0%) documents\n",
      "[2022-09-29 15:39:36,629] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:39:36,736] adding document #4610000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:40:05,943] discarding 37705 tokens: [('doukhane', 2), ('madarsuma', 2), ('guennara', 2), ('marazanae', 2), ('trecarrel', 2), ('epentroma', 2), ('otakauica', 2), ('titirangiensis', 2), ('nizhnedonsky', 2), ('novogrushevsky', 2)]...\n",
      "[2022-09-29 15:40:05,944] keeping 2000000 tokens which were in no less than 0 and no more than 4620000 (=100.0%) documents\n",
      "[2022-09-29 15:40:09,869] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:40:09,940] adding document #4620000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:40:38,010] discarding 42221 tokens: [('dalleres', 2), ('orzeliscinae', 2), ('bassignies', 2), ('rheina', 2), ('picheleira', 2), ('senovalov', 2), ('abmisibil', 2), ('kummeri', 2), ('kicknosway', 2), ('olivadisi', 2)]...\n",
      "[2022-09-29 15:40:38,012] keeping 2000000 tokens which were in no less than 0 and no more than 4630000 (=100.0%) documents\n",
      "[2022-09-29 15:40:43,199] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:40:43,306] adding document #4630000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:41:12,723] discarding 38262 tokens: [('akutoku', 2), ('heishirōkatsujinken', 2), ('kariudo', 2), ('koroshite', 2), ('watatte', 2), ('bodhivamsa', 2), ('dworatschek', 2), ('wareek', 2), ('gagaâ', 2), ('amalli', 2)]...\n",
      "[2022-09-29 15:41:12,725] keeping 2000000 tokens which were in no less than 0 and no more than 4640000 (=100.0%) documents\n",
      "[2022-09-29 15:41:18,279] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:41:18,384] adding document #4640000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:41:46,072] discarding 37086 tokens: [('mozhaeva', 2), ('mixnitz', 2), ('schüsserlbrunn', 2), ('jeruchim', 2), ('jorika', 2), ('bogildo', 2), ('gogeumdo', 2), ('chalermporn', 2), ('hattagowit', 2), ('pumpanwong', 2)]...\n",
      "[2022-09-29 15:41:46,073] keeping 2000000 tokens which were in no less than 0 and no more than 4650000 (=100.0%) documents\n",
      "[2022-09-29 15:41:51,265] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:41:51,370] adding document #4650000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:42:20,138] discarding 39990 tokens: [('denglai', 2), ('choad', 2), ('tolchico', 2), ('graefenburg', 2), ('西流村', 2), ('phorbaceus', 2), ('φόρβαντος', 2), ('φόρβας', 2), ('skrizzy', 2), ('chawallakorn', 2)]...\n",
      "[2022-09-29 15:42:20,140] keeping 2000000 tokens which were in no less than 0 and no more than 4660000 (=100.0%) documents\n",
      "[2022-09-29 15:42:25,300] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:42:25,407] adding document #4660000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:42:51,295] discarding 35128 tokens: [('boardships', 2), ('teigeki', 2), ('glyptelasma', 2), ('lespéret', 2), ('trkalian', 2), ('lilopristone', 2), ('toripristone', 2), ('lonaprisan', 2), ('experess', 2), ('hyperracer', 2)]...\n",
      "[2022-09-29 15:42:51,297] keeping 2000000 tokens which were in no less than 0 and no more than 4670000 (=100.0%) documents\n",
      "[2022-09-29 15:42:55,122] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:42:55,194] adding document #4670000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:43:21,911] discarding 34567 tokens: [('adegbehingbe', 2), ('lapule', 2), ('tamean', 2), ('senjittale', 2), ('idrissid', 2), ('zequinhas', 2), ('brillieu', 2), ('lanfra', 2), ('lanfren', 2), ('callaecans', 2)]...\n",
      "[2022-09-29 15:43:21,913] keeping 2000000 tokens which were in no less than 0 and no more than 4680000 (=100.0%) documents\n",
      "[2022-09-29 15:43:25,966] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:43:26,038] adding document #4680000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:43:53,959] discarding 32627 tokens: [('homasote', 1), ('gsrp', 1), ('nexss', 1), ('alexious', 1), ('chabuka', 1), ('deprose', 1), ('enelesi', 1), ('esmey', 1), ('folosani', 1), ('fontino', 1)]...\n",
      "[2022-09-29 15:43:53,961] keeping 2000000 tokens which were in no less than 0 and no more than 4690000 (=100.0%) documents\n",
      "[2022-09-29 15:43:59,462] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:43:59,566] adding document #4690000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:44:30,849] discarding 34436 tokens: [('azhaikkudhe', 2), ('kuzhandhaiyadi', 2), ('thennai', 2), ('halfhour', 2), ('soberscove', 2), ('contempuls', 2), ('vakilpour', 2), ('kokangol', 2), ('haitatsunin', 2), ('cavungi', 2)]...\n",
      "[2022-09-29 15:44:30,851] keeping 2000000 tokens which were in no less than 0 and no more than 4700000 (=100.0%) documents\n",
      "[2022-09-29 15:44:36,023] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:44:36,128] adding document #4700000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:45:01,635] discarding 36887 tokens: [('aankda', 2), ('dhulghat', 2), ('skålbrekka', 2), ('veanova', 2), ('lanchowfu', 2), ('蘭州府', 2), ('gravenwiesbach', 2), ('bayankhutag', 2), ('aichfeldes', 2), ('bayabani', 2)]...\n",
      "[2022-09-29 15:45:01,637] keeping 2000000 tokens which were in no less than 0 and no more than 4710000 (=100.0%) documents\n",
      "[2022-09-29 15:45:06,795] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:45:06,900] adding document #4710000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:45:31,916] discarding 34127 tokens: [('isergina', 2), ('jaroslawa', 2), ('jokaste', 2), ('jonhodge', 2), ('jubilatrix', 2), ('justinehénin', 2), ('jürgenstock', 2), ('kagayayutaka', 2), ('kartvelia', 2), ('kibirev', 2)]...\n",
      "[2022-09-29 15:45:31,919] keeping 2000000 tokens which were in no less than 0 and no more than 4720000 (=100.0%) documents\n",
      "[2022-09-29 15:45:37,118] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:45:37,222] adding document #4720000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:46:03,594] discarding 41766 tokens: [('monkhoo', 2), ('oÿuun', 2), ('oÿuunbileg', 2), ('shumiyaa', 2), ('tumbish', 2), ('tuvshinjargal', 2), ('tümenjargal', 2), ('üjin', 2), ('ÿundenbat', 2), ('pilbrodalen', 2)]...\n",
      "[2022-09-29 15:46:03,596] keeping 2000000 tokens which were in no less than 0 and no more than 4730000 (=100.0%) documents\n",
      "[2022-09-29 15:46:08,731] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:46:08,837] adding document #4730000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:46:38,167] discarding 34255 tokens: [('gouic', 2), ('methylpiperidinopyrazole', 2), ('propylpyrazoletriol', 2), ('prabhari', 2), ('zhaoquan', 2), ('внеорбитные', 2), ('monoszlós', 2), ('álmosd', 2), ('killmurray', 2), ('бросай', 2)]...\n",
      "[2022-09-29 15:46:38,169] keeping 2000000 tokens which were in no less than 0 and no more than 4740000 (=100.0%) documents\n",
      "[2022-09-29 15:46:43,338] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:46:43,443] adding document #4740000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:47:09,528] discarding 33354 tokens: [('duulat', 2), ('ismaiilov', 2), ('kachkynbekov', 2), ('nichipurenko', 2), ('paizov', 2), ('salmorbek', 2), ('semiletko', 2), ('shushenkov', 2), ('suiunbaev', 2), ('zhookaev', 2)]...\n",
      "[2022-09-29 15:47:09,530] keeping 2000000 tokens which were in no less than 0 and no more than 4750000 (=100.0%) documents\n",
      "[2022-09-29 15:47:13,329] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:47:13,401] adding document #4750000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:47:42,304] discarding 36093 tokens: [('vergerius', 2), ('cliodhan', 2), ('fedarussanti', 2), ('lekone', 2), ('marvwon', 2), ('дикое', 2), ('sohoman', 2), ('soundmill', 2), ('tinraheen', 2), ('gimping', 2)]...\n",
      "[2022-09-29 15:47:42,306] keeping 2000000 tokens which were in no less than 0 and no more than 4760000 (=100.0%) documents\n",
      "[2022-09-29 15:47:46,191] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:47:46,264] adding document #4760000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:48:18,798] discarding 37448 tokens: [('uitați', 2), ('apiwe', 2), ('masterbrewer', 2), ('nxusani', 2), ('sekanka', 2), ('bamunkumbit', 2), ('byiae', 2), ('chengfong', 2), ('mangeh', 2), ('mekheng', 2)]...\n",
      "[2022-09-29 15:48:18,800] keeping 2000000 tokens which were in no less than 0 and no more than 4770000 (=100.0%) documents\n",
      "[2022-09-29 15:48:23,134] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:48:23,209] adding document #4770000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:48:53,563] discarding 34747 tokens: [('satylghan', 2), ('sungule', 2), ('tangáxuan', 2), ('zuangua', 2), ('艾劳', 2), ('knee_dist', 2), ('qopbaseball', 2), ('longplayings', 2), ('inporn', 2), ('phuvichit', 2)]...\n",
      "[2022-09-29 15:48:53,565] keeping 2000000 tokens which were in no less than 0 and no more than 4780000 (=100.0%) documents\n",
      "[2022-09-29 15:48:58,368] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:48:58,441] adding document #4780000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:49:25,550] discarding 32333 tokens: [('balandrau', 1), ('ballús', 1), ('bazaco', 1), ('berenàveu', 1), ('boqueras', 1), ('esparbé', 1), ('fosques', 1), ('glaçat', 1), ('marcús', 1), ('mellali', 1)]...\n",
      "[2022-09-29 15:49:25,552] keeping 2000000 tokens which were in no less than 0 and no more than 4790000 (=100.0%) documents\n",
      "[2022-09-29 15:49:30,706] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:49:30,811] adding document #4790000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:49:59,827] discarding 34077 tokens: [('bizzorero', 2), ('elortuondo', 2), ('galanena', 2), ('arcaus', 2), ('dibarrat', 2), ('garbizu', 2), ('diribarne', 2), ('dellecassagrande', 2), ('yenrick', 2), ('occie', 2)]...\n",
      "[2022-09-29 15:49:59,829] keeping 2000000 tokens which were in no less than 0 and no more than 4800000 (=100.0%) documents\n",
      "[2022-09-29 15:50:05,032] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:50:05,139] adding document #4800000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:50:31,020] discarding 34710 tokens: [('mordsen', 2), ('moruisi', 2), ('nkello', 2), ('ruveve', 2), ('agbaegbu', 2), ('microfinancebank', 2), ('narongdat', 2), ('takantong', 2), ('acledabank', 2), ('canadiabank', 2)]...\n",
      "[2022-09-29 15:50:31,022] keeping 2000000 tokens which were in no less than 0 and no more than 4810000 (=100.0%) documents\n",
      "[2022-09-29 15:50:36,216] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:50:36,320] adding document #4810000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:51:06,012] discarding 35796 tokens: [('koottappana', 2), ('kulathamal', 2), ('moonnukallinmoodu', 2), ('mullaravila', 2), ('muttakkadu', 2), ('olathanni', 2), ('perumpazhuthoor', 2), ('pirayummoodu', 2), ('thavaravila', 2), ('thozhukkal', 2)]...\n",
      "[2022-09-29 15:51:06,014] keeping 2000000 tokens which were in no less than 0 and no more than 4820000 (=100.0%) documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-09-29 15:51:09,758] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:51:09,830] adding document #4820000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:51:38,715] discarding 34328 tokens: [('mudickal', 2), ('thandekkad', 2), ('parkkari', 2), ('ezhippuram', 2), ('maramkulangara', 2), ('morakkala', 2), ('nadamel', 2), ('itzamná', 2), ('kafati', 2), ('afrocyclops', 2)]...\n",
      "[2022-09-29 15:51:38,717] keeping 2000000 tokens which were in no less than 0 and no more than 4830000 (=100.0%) documents\n",
      "[2022-09-29 15:51:44,208] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:51:44,313] adding document #4830000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:52:12,348] discarding 34767 tokens: [('越前焼', 2), ('anjineeyulu', 2), ('madhapeddi', 2), ('hsppr', 2), ('pawtoberfest', 2), ('theoddone', 2), ('mommyla', 2), ('miangang', 2), ('kumbadjena', 2), ('felixin', 2)]...\n",
      "[2022-09-29 15:52:12,350] keeping 2000000 tokens which were in no less than 0 and no more than 4840000 (=100.0%) documents\n",
      "[2022-09-29 15:52:17,489] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:52:17,594] adding document #4840000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:52:44,822] discarding 32229 tokens: [('gimbère', 1), ('khirin', 2), ('artasiamerica', 1), ('bahc', 1), ('crapas', 1), ('dadaiksun', 1), ('dalhangari', 1), ('factoid#1', 1), ('hoyoon', 1), ('intraracial', 1)]...\n",
      "[2022-09-29 15:52:44,824] keeping 2000000 tokens which were in no less than 0 and no more than 4850000 (=100.0%) documents\n",
      "[2022-09-29 15:52:50,092] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:52:50,198] adding document #4850000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:53:15,705] discarding 31311 tokens: [('cochleovestibular', 1), ('coxhlear', 1), ('nitrogrn', 1), ('oedeama', 1), ('tinnitis', 1), ('copycat§', 1), ('박정환', 1), ('박호산', 1), ('skjelmose', 1), ('lacharn', 1)]...\n",
      "[2022-09-29 15:53:15,707] keeping 2000000 tokens which were in no less than 0 and no more than 4860000 (=100.0%) documents\n",
      "[2022-09-29 15:53:20,854] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:53:20,959] adding document #4860000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:53:54,988] discarding 34224 tokens: [('rangedor', 2), ('chenderawasih', 2), ('kristinaitis', 2), ('ivanah', 2), ('menideh', 2), ('missourincaa', 2), ('adaloja', 2), ('foliguet', 2), ('mehas', 2), ('અશ', 2)]...\n",
      "[2022-09-29 15:53:54,990] keeping 2000000 tokens which were in no less than 0 and no more than 4870000 (=100.0%) documents\n",
      "[2022-09-29 15:53:58,744] resulting dictionary: Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:53:58,815] adding document #4870000 to Dictionary(2000000 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...)\n",
      "[2022-09-29 15:54:01,144] finished iterating over Wikipedia corpus of 4870548 documents with 2069056400 positions (total 22348968 articles, 2152239174 positions before pruning articles shorter than 50 words)\n",
      "[2022-09-29 15:54:01,526] built Dictionary(2001509 unique tokens: ['ability', 'ability#1§', 'able#0', 'abolish', 'abolition§']...) from 4870548 documents (total 2069056400 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "# loc = 'num'|'lr'|'ent'\n",
    "# pos = True|False\n",
    "# download latest wiki dump\n",
    "#w.download_wiki_dump('en', WIKIXML)\n",
    "\n",
    "# parse wiki dump\n",
    "wiki_sentences = w.WikiSentences(WIKIXML, 'en',lower=True) # Orignal\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='EM',lower=True,pos=False,loc=False)\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='DEP',lower=True,pos=False,loc=False)\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='UNS',lower=True,pos=False,loc=False)\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='UNSEM',lower=True,pos=False,loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T14:54:03.247052Z",
     "start_time": "2022-09-29T14:54:01.532436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the data\n"
     ]
    }
   ],
   "source": [
    "#sv.save(wiki_sentences,\"wiki_sentences_pos_sample\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_pos\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_dep\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp_loc\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp_ent\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp_ent_sample\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences\") # orignal\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_dep2\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_uns\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_unsem\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_em\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_wnet\")\n",
    "sv.save(wiki_sentences,\"wiki_sentences_wnet_noun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Phrase mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T18:50:46.815932Z",
     "start_time": "2021-05-29T18:50:46.810808Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:24:31.858045Z",
     "start_time": "2021-05-29T18:51:21.445049Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phrases = Phrases(sentences, min_count=100, threshold=1)\n",
    "frozen_phrases = phrases.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T11:41:54.697897Z",
     "start_time": "2021-05-30T11:41:38.608475Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sv.save(phrases,\"gensim_phrases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:06:13.397797Z",
     "start_time": "2020-03-16T22:06:13.394080Z"
    }
   },
   "source": [
    "# Train procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T17:03:31.086301Z",
     "start_time": "2022-09-26T17:03:29.127200Z"
    }
   },
   "outputs": [],
   "source": [
    "#sentences = sv.load(\"wiki_sentences_no\")\n",
    "#temp_sens are cased!!\n",
    "#sentences = sv.load(\"temp_sens\")\n",
    " \n",
    "#sentences = sv.load(\"wiki_sentences\") #Normal sentences using wiki_old.py\n",
    "\n",
    "#Wiki_Sentences_SP are cased\n",
    "#sentences = sv.load(\"Wiki_Sentences_SP\")\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_sp_loc\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_sp\") #New\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_pos\") # not to be used\n",
    "#sentences = sv.load(\"Wiki_sentences_pos_sample\")\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_sp_ent\") # New\n",
    "#sentences = sv.load(\"wiki_sentences_sp_ent_sample\") # New\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_dep\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_dep2\") #New\n",
    "\n",
    "#wiki english sample Cased \n",
    "#sentences = sv.load(\"Wiki_sentences_sp_sample\")\n",
    "#sentences = sv.load(\"wiki_sentences_uns\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_unsem\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_em\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_wnet\") #New\n",
    "sentences = sv.load(\"wiki_sentences_wnet_noun\") #New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T17:03:42.932622Z",
     "start_time": "2022-09-26T17:03:31.089314Z"
    }
   },
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "    print(sent[:100])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T17:03:42.938601Z",
     "start_time": "2022-09-26T17:03:42.934712Z"
    }
   },
   "outputs": [],
   "source": [
    "#sentences = wiki_sentences\n",
    "print(\"Minimum length of token:\",sentences.wiki.token_min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:19:47.558649Z",
     "start_time": "2022-09-26T17:03:42.939992Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.info('Training model %s', 'wordnet')\n",
    "model = word2vec.Word2Vec(sentences, window=10, sg=1, hs=0, negative=5, size=300, workers=40, iter=5)\n",
    "logging.info('Training done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:19:47.567151Z",
     "start_time": "2022-09-27T12:19:47.561283Z"
    }
   },
   "outputs": [],
   "source": [
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc1_epoch5_300_filtered_sample.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_w2v_mc1_epoch5_300_sample.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2R_mc1_epoch5_300_filtered.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2w2v_mc1_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc1_epoch5_300_con1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc1_epoch5_300_reversed.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc100_epoch5_300_reversed.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc100_epoch5_300_neg10.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc100_epoch5_300_neg10_w3.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2S_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2B_mc100_epoch5_300_sub3.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2TB_mc100_epoch5_300_LR.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2POS_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2DEP_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2LRM3_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2LOC_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_w1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_reversed.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx_mc100_epoch5_300_loc.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_w2v_mc100_epoch5_300_w1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_pos.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx_mc100_epoch5_300_ent_w10.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_dep2_w1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_ent_static_w3.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_uns.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_unsem.txt'\n",
    "#emb_file = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300_em.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_uns_w1.txt'\n",
    "#emb_file = '/home/manni/embs/en_wiki_wnet_epoch5_300_w10.txt'\n",
    "emb_file = '/home/manni/embs/en_wiki_wnet_epoch5_300_w10_exclusive_noun.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:19:47.611756Z",
     "start_time": "2022-09-27T12:19:47.568626Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = model.wv.vocab #dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:19:47.638459Z",
     "start_time": "2022-09-27T12:19:47.613597Z"
    }
   },
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:19:47.655143Z",
     "start_time": "2022-09-27T12:19:47.641660Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab.pop('[', None)\n",
    "vocab.pop(']', None)\n",
    "len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T12:19:49.949463Z",
     "start_time": "2022-09-27T12:19:47.656777Z"
    }
   },
   "outputs": [],
   "source": [
    "_vocab = list(vocab.keys())\n",
    "vocab = set()\n",
    "for word in _vocab:\n",
    "    if '§' in word:\n",
    "        continue\n",
    "    vocab.add(word)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T14:46:01.175944Z",
     "start_time": "2022-09-27T14:28:38.594791Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.info('Save trained word vectors')\n",
    "with open(emb_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('%d %d\\n' % (len(vocab), 300))\n",
    "    for word in tqdm(vocab, position=0):\n",
    "        f.write('%s %s\\n' % (word, ' '.join([str(v) for v in model.wv[word]])))\n",
    "logging.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
