{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:48:56.765366Z",
     "start_time": "2022-03-13T05:48:54.016030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing word2vec_inner...\n",
      "CYTHON IMPORTED SUCCESSFULLY!! (Normal)\n",
      "cbound : False\n",
      "tbound : False\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "#import wiki_old as w # old wiki\n",
    "import wiki as w # changed wiki to include '[]'\n",
    " \n",
    "#from gensim.models import word2vec # for orignal w2v\n",
    "from localgensim.gensim2.models import word2vec #remmember to change flags in word2vec.py  161-162\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from gensim.models.fasttext import FastText\n",
    "#from gensim.models.word2vec import Word2Vec # not in use\n",
    "#from localgensim.gensim2.models.word2vec import Word2Vec # not in use\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "WIKIXML = '/home/manni/data/wiki/enwiki-20211120-pages-articles-multistream.xml.bz2'\n",
    "#WIKIXML = '/home/manni/data/wiki/enwiki-20211120-pages-articles-multistream1.xml-p1p41242.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:48:56.774184Z",
     "start_time": "2022-03-13T05:48:56.768684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manni/ner-s2s/word_embedding/wiki.py\n",
      "/home/manni/ner-s2s/word_embedding/localgensim/gensim2/models/word2vec.py\n"
     ]
    }
   ],
   "source": [
    "print(w.__file__)\n",
    "print(word2vec.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:48:56.859085Z",
     "start_time": "2022-03-13T05:48:56.777528Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../imports/\")\n",
    "import saver as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:48:56.925693Z",
     "start_time": "2022-03-13T05:48:56.861873Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] %(message)s', level=logging.INFO)\n",
    "os.makedirs('data/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip if sentence made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-07T19:09:32.868Z"
    }
   },
   "outputs": [],
   "source": [
    "# loc = 'num'|'lr'|'ent'\n",
    "# pos = True|False\n",
    "# download latest wiki dump\n",
    "#w.download_wiki_dump('en', WIKIXML)\n",
    "\n",
    "# parse wiki dump\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',lower=True) # Orignal\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='EM',lower=True,pos=False,loc=False)\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='DEP',lower=True,pos=False,loc=False)\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='UNS',lower=True,pos=False,loc=False)\n",
    "#wiki_sentences = w.WikiSentences(WIKIXML, 'en',tokenizer_func='UNSEM',lower=True,pos=False,loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-07T19:09:34.083Z"
    }
   },
   "outputs": [],
   "source": [
    "#sv.save(wiki_sentences,\"wiki_sentences_pos_sample\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_pos\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_dep\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp_loc\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp_ent\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_sp_ent_sample\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences\") # orignal\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_dep2\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_uns\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_unsem\")\n",
    "#sv.save(wiki_sentences,\"wiki_sentences_em\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T18:50:46.815932Z",
     "start_time": "2021-05-29T18:50:46.810808Z"
    }
   },
   "outputs": [],
   "source": [
    "#from gensim.test.utils import datapath\n",
    "#from gensim.models.phrases import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T22:24:31.858045Z",
     "start_time": "2021-05-29T18:51:21.445049Z"
    }
   },
   "outputs": [],
   "source": [
    "#phrases = Phrases(sentences, min_count=100, threshold=1)\n",
    "#frozen_phrases = phrases.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T11:41:54.697897Z",
     "start_time": "2021-05-30T11:41:38.608475Z"
    }
   },
   "outputs": [],
   "source": [
    "#sv.save(phrases,\"gensim_phrases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:06:13.397797Z",
     "start_time": "2020-03-16T22:06:13.394080Z"
    }
   },
   "source": [
    "# Train procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:49:02.663973Z",
     "start_time": "2022-03-13T05:49:01.181727Z"
    }
   },
   "outputs": [],
   "source": [
    "#sentences = sv.load(\"wiki_sentences_no\")\n",
    "#temp_sens are cased!!\n",
    "#sentences = sv.load(\"temp_sens\")\n",
    " \n",
    "#sentences = sv.load(\"wiki_sentences\") #Normal sentences using wiki_old.py\n",
    "\n",
    "#Wiki_Sentences_SP are cased\n",
    "#sentences = sv.load(\"Wiki_Sentences_SP\")\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_sp_loc\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_sp\") #New\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_pos\") # not to be used\n",
    "#sentences = sv.load(\"Wiki_sentences_pos_sample\")\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_sp_ent\") # New\n",
    "#sentences = sv.load(\"wiki_sentences_sp_ent_sample\") # New\n",
    "\n",
    "#sentences = sv.load(\"wiki_sentences_dep\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_dep2\") #New\n",
    "\n",
    "#wiki english sample Cased \n",
    "#sentences = sv.load(\"Wiki_sentences_sp_sample\")\n",
    "#sentences = sv.load(\"wiki_sentences_uns\") #New\n",
    "#sentences = sv.load(\"wiki_sentences_unsem\") #New\n",
    "sentences = sv.load(\"wiki_sentences_em\") #New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T05:49:02.672912Z",
     "start_time": "2022-03-13T05:49:02.667329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length of token: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum length of token:\",sentences.wiki.token_min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T05:49:09.005Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-13 05:49:09,131] Training model spxM100EMw5\n",
      "[2022-03-13 05:49:09,134] collecting all words and their counts\n",
      "[2022-03-13 05:49:11,895] PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "[2022-03-13 05:49:53,864] PROGRESS: at sentence #10000, processed 39879308 words, keeping 612371 word types\n",
      "[2022-03-13 05:50:31,720] PROGRESS: at sentence #20000, processed 75617823 words, keeping 879423 word types\n",
      "[2022-03-13 05:51:03,144] PROGRESS: at sentence #30000, processed 104143127 words, keeping 1073861 word types\n",
      "[2022-03-13 05:51:31,182] PROGRESS: at sentence #40000, processed 129451193 words, keeping 1240266 word types\n",
      "[2022-03-13 05:51:51,956] PROGRESS: at sentence #50000, processed 147710151 words, keeping 1351778 word types\n",
      "[2022-03-13 05:53:37,031] PROGRESS: at sentence #110000, processed 240957295 words, keeping 1787566 word types\n",
      "[2022-03-13 05:53:59,186] PROGRESS: at sentence #120000, processed 260563383 words, keeping 1894031 word types\n",
      "[2022-03-13 05:54:21,391] PROGRESS: at sentence #130000, processed 279343089 words, keeping 1988802 word types\n",
      "[2022-03-13 05:54:45,116] PROGRESS: at sentence #140000, processed 299456004 words, keeping 2092116 word types\n",
      "[2022-03-13 05:55:06,386] PROGRESS: at sentence #150000, processed 317108572 words, keeping 2202929 word types\n",
      "[2022-03-13 05:55:29,489] PROGRESS: at sentence #160000, processed 335360791 words, keeping 2303815 word types\n",
      "[2022-03-13 05:55:50,625] PROGRESS: at sentence #170000, processed 352398031 words, keeping 2391770 word types\n",
      "[2022-03-13 05:56:13,140] PROGRESS: at sentence #180000, processed 368610615 words, keeping 2459865 word types\n",
      "[2022-03-13 05:56:30,145] PROGRESS: at sentence #190000, processed 383523928 words, keeping 2537308 word types\n",
      "[2022-03-13 05:56:48,548] PROGRESS: at sentence #200000, processed 397948660 words, keeping 2610326 word types\n",
      "[2022-03-13 05:57:07,955] PROGRESS: at sentence #210000, processed 412624479 words, keeping 2674596 word types\n",
      "[2022-03-13 05:57:25,106] PROGRESS: at sentence #220000, processed 427494886 words, keeping 2735948 word types\n",
      "[2022-03-13 05:57:43,222] PROGRESS: at sentence #230000, processed 441440424 words, keeping 2800989 word types\n",
      "[2022-03-13 05:58:00,785] PROGRESS: at sentence #240000, processed 455294619 words, keeping 2864239 word types\n",
      "[2022-03-13 05:58:20,811] PROGRESS: at sentence #250000, processed 469197262 words, keeping 2920186 word types\n",
      "[2022-03-13 05:58:38,848] PROGRESS: at sentence #260000, processed 483004410 words, keeping 2979765 word types\n",
      "[2022-03-13 05:58:57,792] PROGRESS: at sentence #270000, processed 495833654 words, keeping 3033833 word types\n",
      "[2022-03-13 05:59:20,153] PROGRESS: at sentence #280000, processed 509154185 words, keeping 3093726 word types\n",
      "[2022-03-13 05:59:35,978] PROGRESS: at sentence #290000, processed 521506212 words, keeping 3153992 word types\n",
      "[2022-03-13 05:59:51,530] PROGRESS: at sentence #300000, processed 533889412 words, keeping 3208817 word types\n",
      "[2022-03-13 06:00:07,551] PROGRESS: at sentence #310000, processed 545873072 words, keeping 3264926 word types\n",
      "[2022-03-13 06:00:25,103] PROGRESS: at sentence #320000, processed 558158397 words, keeping 3324774 word types\n",
      "[2022-03-13 06:00:40,651] PROGRESS: at sentence #330000, processed 570158845 words, keeping 3374099 word types\n",
      "[2022-03-13 06:00:54,744] PROGRESS: at sentence #340000, processed 581532115 words, keeping 3420559 word types\n",
      "[2022-03-13 06:01:09,988] PROGRESS: at sentence #350000, processed 593474503 words, keeping 3462914 word types\n",
      "[2022-03-13 06:01:24,596] PROGRESS: at sentence #360000, processed 604819470 words, keeping 3503772 word types\n",
      "[2022-03-13 06:01:39,122] PROGRESS: at sentence #370000, processed 615854676 words, keeping 3546544 word types\n",
      "[2022-03-13 06:01:54,214] PROGRESS: at sentence #380000, processed 627062248 words, keeping 3591491 word types\n",
      "[2022-03-13 06:02:09,598] PROGRESS: at sentence #390000, processed 637806500 words, keeping 3630655 word types\n",
      "[2022-03-13 06:02:24,900] PROGRESS: at sentence #400000, processed 648847955 words, keeping 3671593 word types\n",
      "[2022-03-13 06:02:39,276] PROGRESS: at sentence #410000, processed 659597964 words, keeping 3716675 word types\n",
      "[2022-03-13 06:02:56,111] PROGRESS: at sentence #420000, processed 670665143 words, keeping 3764267 word types\n",
      "[2022-03-13 06:03:10,114] PROGRESS: at sentence #430000, processed 681053606 words, keeping 3802614 word types\n",
      "[2022-03-13 06:03:24,628] PROGRESS: at sentence #440000, processed 692106746 words, keeping 3844424 word types\n",
      "[2022-03-13 06:03:38,983] PROGRESS: at sentence #450000, processed 702697429 words, keeping 3890584 word types\n",
      "[2022-03-13 06:03:54,528] PROGRESS: at sentence #460000, processed 713123838 words, keeping 3931093 word types\n",
      "[2022-03-13 06:04:09,428] PROGRESS: at sentence #470000, processed 723711245 words, keeping 3970679 word types\n",
      "[2022-03-13 06:04:22,667] PROGRESS: at sentence #480000, processed 733523529 words, keeping 4006418 word types\n",
      "[2022-03-13 06:04:38,033] PROGRESS: at sentence #490000, processed 743636396 words, keeping 4045716 word types\n",
      "[2022-03-13 06:04:51,748] PROGRESS: at sentence #500000, processed 753710807 words, keeping 4082016 word types\n",
      "[2022-03-13 06:05:05,774] PROGRESS: at sentence #510000, processed 763928522 words, keeping 4120810 word types\n",
      "[2022-03-13 06:05:24,650] PROGRESS: at sentence #520000, processed 774196223 words, keeping 4159339 word types\n",
      "[2022-03-13 06:05:39,515] PROGRESS: at sentence #530000, processed 784216529 words, keeping 4197160 word types\n",
      "[2022-03-13 06:05:53,497] PROGRESS: at sentence #540000, processed 793963576 words, keeping 4232367 word types\n",
      "[2022-03-13 06:06:08,001] PROGRESS: at sentence #550000, processed 803711146 words, keeping 4272464 word types\n",
      "[2022-03-13 06:06:21,574] PROGRESS: at sentence #560000, processed 813322076 words, keeping 4308154 word types\n",
      "[2022-03-13 06:06:34,484] PROGRESS: at sentence #570000, processed 822802875 words, keeping 4343574 word types\n",
      "[2022-03-13 06:06:47,971] PROGRESS: at sentence #580000, processed 832265841 words, keeping 4375439 word types\n",
      "[2022-03-13 06:07:01,029] PROGRESS: at sentence #590000, processed 841180358 words, keeping 4405547 word types\n",
      "[2022-03-13 06:07:14,018] PROGRESS: at sentence #600000, processed 850415762 words, keeping 4437625 word types\n",
      "[2022-03-13 06:07:28,109] PROGRESS: at sentence #610000, processed 859628878 words, keeping 4472483 word types\n",
      "[2022-03-13 06:07:40,734] PROGRESS: at sentence #620000, processed 868627251 words, keeping 4506997 word types\n",
      "[2022-03-13 06:07:54,319] PROGRESS: at sentence #630000, processed 877609762 words, keeping 4539884 word types\n",
      "[2022-03-13 06:08:06,459] PROGRESS: at sentence #640000, processed 886241473 words, keeping 4574292 word types\n",
      "[2022-03-13 06:08:20,444] PROGRESS: at sentence #650000, processed 895122459 words, keeping 4605913 word types\n",
      "[2022-03-13 06:08:32,819] PROGRESS: at sentence #660000, processed 903357086 words, keeping 4635011 word types\n",
      "[2022-03-13 06:08:45,600] PROGRESS: at sentence #670000, processed 911937261 words, keeping 4665579 word types\n",
      "[2022-03-13 06:08:57,626] PROGRESS: at sentence #680000, processed 920190696 words, keeping 4708267 word types\n",
      "[2022-03-13 06:09:08,516] PROGRESS: at sentence #690000, processed 928361789 words, keeping 4735729 word types\n",
      "[2022-03-13 06:09:24,903] PROGRESS: at sentence #700000, processed 936609063 words, keeping 4763563 word types\n",
      "[2022-03-13 06:09:36,624] PROGRESS: at sentence #710000, processed 944960584 words, keeping 4792198 word types\n",
      "[2022-03-13 06:09:49,892] PROGRESS: at sentence #720000, processed 953495999 words, keeping 4839730 word types\n",
      "[2022-03-13 06:10:03,025] PROGRESS: at sentence #730000, processed 961839535 words, keeping 4869809 word types\n",
      "[2022-03-13 06:10:15,373] PROGRESS: at sentence #740000, processed 970186374 words, keeping 4894689 word types\n",
      "[2022-03-13 06:10:31,123] PROGRESS: at sentence #750000, processed 979007589 words, keeping 4923876 word types\n",
      "[2022-03-13 06:10:44,671] PROGRESS: at sentence #760000, processed 987347005 words, keeping 4953020 word types\n",
      "[2022-03-13 06:10:57,347] PROGRESS: at sentence #770000, processed 995475844 words, keeping 4982410 word types\n",
      "[2022-03-13 06:11:09,997] PROGRESS: at sentence #780000, processed 1003680481 words, keeping 5009097 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-13 06:11:23,582] PROGRESS: at sentence #790000, processed 1011854665 words, keeping 5038717 word types\n",
      "[2022-03-13 06:11:35,105] PROGRESS: at sentence #800000, processed 1019652828 words, keeping 5063502 word types\n",
      "[2022-03-13 06:11:46,815] PROGRESS: at sentence #810000, processed 1027600284 words, keeping 5093339 word types\n",
      "[2022-03-13 06:12:00,626] PROGRESS: at sentence #820000, processed 1035593893 words, keeping 5123292 word types\n",
      "[2022-03-13 06:12:14,103] PROGRESS: at sentence #830000, processed 1043527215 words, keeping 5150359 word types\n",
      "[2022-03-13 06:12:27,224] PROGRESS: at sentence #840000, processed 1051489094 words, keeping 5176917 word types\n",
      "[2022-03-13 06:12:39,716] PROGRESS: at sentence #850000, processed 1059176271 words, keeping 5206291 word types\n",
      "[2022-03-13 06:12:51,412] PROGRESS: at sentence #860000, processed 1066926750 words, keeping 5233510 word types\n",
      "[2022-03-13 06:13:03,706] PROGRESS: at sentence #870000, processed 1074762327 words, keeping 5260431 word types\n",
      "[2022-03-13 06:13:15,862] PROGRESS: at sentence #880000, processed 1082556612 words, keeping 5288616 word types\n",
      "[2022-03-13 06:13:28,022] PROGRESS: at sentence #890000, processed 1090028721 words, keeping 5315349 word types\n",
      "[2022-03-13 06:13:39,776] PROGRESS: at sentence #900000, processed 1097602585 words, keeping 5339265 word types\n",
      "[2022-03-13 06:13:52,546] PROGRESS: at sentence #910000, processed 1105115370 words, keeping 5368457 word types\n",
      "[2022-03-13 06:14:05,457] PROGRESS: at sentence #920000, processed 1112819924 words, keeping 5392138 word types\n",
      "[2022-03-13 06:14:17,696] PROGRESS: at sentence #930000, processed 1120441019 words, keeping 5416575 word types\n",
      "[2022-03-13 06:14:30,717] PROGRESS: at sentence #940000, processed 1128175984 words, keeping 5442027 word types\n",
      "[2022-03-13 06:14:41,888] PROGRESS: at sentence #950000, processed 1135369385 words, keeping 5467588 word types\n"
     ]
    }
   ],
   "source": [
    "logging.info('Training model %s', 'spxM100EMw5')\n",
    "model = word2vec.Word2Vec(sentences, cbound=False, tbound=False, bound_type='lr', window=5, sg=1, hs=0, negative=5, size=300, sample=1e-3, workers=40, iter=5, min_count=100)\n",
    "#model = word2vec.Word2Vec(sentences, window=1, sg=1, hs=0, negative=5, size=300, sample=1e-3, workers=40, iter=5, min_count=100)\n",
    "logging.info('Training done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T05:49:14.273Z"
    }
   },
   "outputs": [],
   "source": [
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc1_epoch5_300_filtered_sample.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_w2v_mc1_epoch5_300_sample.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2R_mc1_epoch5_300_filtered.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2w2v_mc1_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc1_epoch5_300_con1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc1_epoch5_300_reversed.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc100_epoch5_300_reversed.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc100_epoch5_300_neg10.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2_mc100_epoch5_300_neg10_w3.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2S_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_SPX2B_mc100_epoch5_300_sub3.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2TB_mc100_epoch5_300_LR.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2POS_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2DEP_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2LRM3_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2LOC_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_w1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_reversed.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx_mc100_epoch5_300_loc.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_w2v_mc100_epoch5_300_w1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_pos.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx_mc100_epoch5_300_ent_w10.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_dep2_w1.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_ent_static_w3.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_uns.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_unsem.txt'\n",
    "emb_file = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300_em.txt'\n",
    "#emb_file = '/mnt/nfs/resdata0/manni/wiki/en_wiki_spx2_mc100_epoch5_300_uns_w1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T05:49:15.305Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T05:49:15.784Z"
    }
   },
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T05:49:16.191Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab.pop('[', None)\n",
    "vocab.pop(']', None)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T05:49:16.590Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.info('Save trained word vectors')\n",
    "with open(emb_file, 'w', encoding='utf-8') as f:\n",
    "    f.write('%d %d\\n' % (len(vocab), 300))\n",
    "    for word in tqdm(vocab, position=0):\n",
    "        f.write('%s %s\\n' % (word, ' '.join([str(v) for v in model.wv[word]])))\n",
    "logging.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
