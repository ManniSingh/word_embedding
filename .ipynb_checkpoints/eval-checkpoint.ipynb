{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T06:44:48.475622Z",
     "start_time": "2022-04-26T06:44:47.556007Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T06:50:00.439824Z",
     "start_time": "2022-04-26T06:45:05.240501Z"
    }
   },
   "outputs": [],
   "source": [
    "spxEM = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300_em.txt'\n",
    "spxEM_model = KeyedVectors.load_word2vec_format(spxEM, binary=False)\n",
    "w2v = '/home/manni/embs/en_wiki_w2v_mc100_epoch5_300.txt'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v, binary=False)\n",
    "spx = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300.txt'\n",
    "spx_model = KeyedVectors.load_word2vec_format(spx, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T06:50:37.430214Z",
     "start_time": "2022-04-26T06:50:37.424930Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [w2v_model,spx_model,spxEM_model]\n",
    "model_names = ['Word2vec','EWEM-MIX','EWEM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T06:50:25.869159Z",
     "start_time": "2022-04-26T06:50:00.448627Z"
    }
   },
   "outputs": [],
   "source": [
    "spxEM = '/home/manni/embs/en_wiki_spx_mc100_epoch5_300_em_w1.txt'\n",
    "spxEM_model = KeyedVectors.load_word2vec_format(spxEM, binary=False)\n",
    "w2v = '/home/manni/embs/en_wiki_w2v_mc100_epoch5_300_w1.txt'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T06:50:25.871025Z",
     "start_time": "2022-04-26T06:50:25.870996Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [w2v_model,spxEM_model]\n",
    "model_names = ['Word2vec','EWEM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:06.862890Z",
     "start_time": "2022-04-26T07:02:06.856228Z"
    }
   },
   "outputs": [],
   "source": [
    "scws_file = '/home/manni/data/wordsim/SCWS/ratings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:07.295362Z",
     "start_time": "2022-04-26T07:02:07.274792Z"
    }
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "with open(scws_file) as fin:\n",
    "    lines = fin.readlines()\n",
    "    for l in lines:\n",
    "        l = l.lower().split('\\t')\n",
    "        w1 = l[1]\n",
    "        w2 = l[3]\n",
    "        c1 = l[5]\n",
    "        c2 = l[6]\n",
    "        score = float(l[7])\n",
    "        data.append([w1,w2,c1,c2,score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:08.746728Z",
     "start_time": "2022-04-26T07:02:08.739853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brazil',\n",
       " 'nut',\n",
       " 'gap in income between blacks and other non-whites is relatively small compared to the large gap between whites and non-whites . other factors such as illiteracy and education level show the same patterns . unlike in the us where african americans were united in the civil rights struggle , in <b> brazil </b> the philosophy of whitening has helped divide blacks from other non-whites and prevented a more active civil rights movement . though afro-brazilians make up half the population there are very few black politicians . the city of salvador , bahia for instance is 80 % afro-brazilian but has never',\n",
       " 'of the neck , bridge , and pickups , there are features which are found in almost every guitar . the photo below shows the different parts of an electric guitar . the headstock ( 1 ) contains the metal machine heads , which are used for tuning ; the <b> nut </b> ( 1.4 ) , a thin fret-like strip of metal , plastic , graphite or bone which the strings pass over as they first go onto the fingerboard ; the machine heads ( 1.1 ) , which are worm gears which the player turns to change the string tension',\n",
       " 1.1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:13.100415Z",
     "start_time": "2022-04-26T07:02:12.040048Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_sent(sent):\n",
    "    '''\n",
    "    parameters:\n",
    "        sent: str\n",
    "    returns:\n",
    "        tokens: list(str)     \n",
    "    '''\n",
    "    return [word for word in sent.split() if word not in stop_words]\n",
    "\n",
    "def sent_words(sent):\n",
    "    '''\n",
    "    parameters:\n",
    "        sent: str\n",
    "    returns:\n",
    "        tokens: list(str) \n",
    "    '''\n",
    "    sent = re.sub(r'[^\\w\\s]', '', sent)\n",
    "    left = sent.split('<b>')[0]\n",
    "    right = sent.split('</b>')[-1]\n",
    "    sentA = clean_sent(left)[-5:]\n",
    "    sentB = clean_sent(right)[:5]\n",
    "    return sentA+sentB\n",
    "\n",
    "def avgsim(w1,w2,c1,c2,model,verbose=False):\n",
    "    '''\n",
    "    Computes average similarity score.\n",
    "\n",
    "    parameters:\n",
    "        w1 : str\n",
    "        w2 : str\n",
    "        c1 : str\n",
    "        c2 : str\n",
    "        model : gensim.keyedvectors\n",
    "    returns:\n",
    "        score : float\n",
    "    '''\n",
    "    if w1 not in model.vocab or w2 not in model.vocab:\n",
    "        return None\n",
    "    a = [w1] + sent_words(c1)\n",
    "    _a = [word+'#E' for word in a] \n",
    "    a+=_a\n",
    "    b = [w2] + sent_words(c2)\n",
    "    _b = [word+'#E' for word in b] \n",
    "    b+=_b\n",
    "    a = [word for word in a if word in model.vocab]\n",
    "    b = [word for word in b if word in model.vocab]\n",
    "    if verbose:\n",
    "        print(a)\n",
    "        print(b)\n",
    "    div = len(a)*len(b)\n",
    "    sims = 0\n",
    "    for i in a:\n",
    "        for j in b:\n",
    "            sim = model.similarity(i,j)\n",
    "            if verbose:\n",
    "                print(i,j,sim)\n",
    "            sims+= sim\n",
    "    return sims/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:13.177746Z",
     "start_time": "2022-04-26T07:02:13.170147Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_corr(model):\n",
    "    sims = list()\n",
    "    scores = list()\n",
    "    for dat in tqdm(data,position=0):\n",
    "        sim = avgsim(dat[0],dat[1],dat[2],dat[3],model)\n",
    "        if sim:\n",
    "            score = dat[4]\n",
    "            sims.append(sim)\n",
    "            scores.append(score)\n",
    "    corr, _ = pearsonr(sims, scores)\n",
    "    print('Pearsons correlation: %.2f' % (corr*100))\n",
    "    corr, _ = spearmanr(sims, scores)\n",
    "    print('Spearmans correlation: %.2f' % (corr*100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr(spxEM_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr(spx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_corr(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:16.448562Z",
     "start_time": "2022-04-26T07:02:16.440159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19745755\n",
      "0.15671067\n",
      "0.15111805\n",
      "0.18348204\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.similarity('brazil','nut'))\n",
    "print(spx_model.similarity('brazil','nut'))\n",
    "print(spxEM_model.similarity('brazil','nut'))\n",
    "print(spxEM_model.similarity('brazil#E','nut#E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:17.568594Z",
     "start_time": "2022-04-26T07:02:17.559976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5839992\n",
      "0.60688496\n",
      "0.5302377\n",
      "0.862124\n"
     ]
    }
   ],
   "source": [
    "print(spx_model.similarity('new','york'))\n",
    "print(w2v_model.similarity('new','york'))\n",
    "print(spxEM_model.similarity('new','york'))\n",
    "print(spxEM_model.similarity('new#E','york#E'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T07:02:27.519284Z",
     "start_time": "2022-04-26T07:02:27.469994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brazil', 'bahia', 'instance', 'never', 'gap', 'income', 'blacks', 'nonwhites', 'relatively']\n",
      "['nut', 'player', 'turns', 'change', 'string', 'tension', 'neck', 'bridge', 'pickups', 'features', 'found']\n",
      "brazil nut 0.19745755\n",
      "brazil player 0.130856\n",
      "brazil turns 0.0463257\n",
      "brazil change 0.16854647\n",
      "brazil string 0.073782526\n",
      "brazil tension 0.053863127\n",
      "brazil neck 0.06356639\n",
      "brazil bridge 0.07224046\n",
      "brazil pickups 0.043330412\n",
      "brazil features 0.1246864\n",
      "brazil found 0.25188786\n",
      "bahia nut 0.18450944\n",
      "bahia player 0.11996905\n",
      "bahia turns 0.008881014\n",
      "bahia change 0.12484312\n",
      "bahia string 0.08254954\n",
      "bahia tension 0.013918953\n",
      "bahia neck 0.04056377\n",
      "bahia bridge 0.076342374\n",
      "bahia pickups 0.0072754477\n",
      "bahia features 0.12120576\n",
      "bahia found 0.142302\n",
      "instance nut 0.101189315\n",
      "instance player 0.12255697\n",
      "instance turns 0.15928455\n",
      "instance change 0.22907887\n",
      "instance string 0.26618966\n",
      "instance tension 0.14873882\n",
      "instance neck 0.027811175\n",
      "instance bridge 0.077633396\n",
      "instance pickups 0.06914475\n",
      "instance features 0.1726237\n",
      "instance found 0.28768176\n",
      "never nut 0.029978108\n",
      "never player 0.06796168\n",
      "never turns 0.17264912\n",
      "never change 0.30204475\n",
      "never string 0.14153972\n",
      "never tension 0.16727482\n",
      "never neck 0.21739858\n",
      "never bridge 0.16116312\n",
      "never pickups 0.11128724\n",
      "never features 0.13408853\n",
      "never found 0.23450842\n",
      "gap nut 0.12961519\n",
      "gap player 0.027621169\n",
      "gap turns 0.19106564\n",
      "gap change 0.23470443\n",
      "gap string 0.113996714\n",
      "gap tension 0.2698013\n",
      "gap neck 0.22798723\n",
      "gap bridge 0.31673777\n",
      "gap pickups 0.15009595\n",
      "gap features 0.096334845\n",
      "gap found 0.08273373\n",
      "income nut 0.09288674\n",
      "income player 0.10932237\n",
      "income turns 0.033182792\n",
      "income change 0.16374986\n",
      "income string 0.08356456\n",
      "income tension 0.09833116\n",
      "income neck 0.0441414\n",
      "income bridge 0.04420974\n",
      "income pickups 0.036386922\n",
      "income features 0.037912965\n",
      "income found 0.113247015\n",
      "blacks nut 0.061494175\n",
      "blacks player 0.20609294\n",
      "blacks turns 0.09008452\n",
      "blacks change 0.12610686\n",
      "blacks string -0.008103378\n",
      "blacks tension 0.16640548\n",
      "blacks neck 0.124925815\n",
      "blacks bridge 0.09675077\n",
      "blacks pickups 0.13257286\n",
      "blacks features 0.08135184\n",
      "blacks found 0.11979319\n",
      "nonwhites nut 0.021687122\n",
      "nonwhites player 0.18218929\n",
      "nonwhites turns 0.081511214\n",
      "nonwhites change 0.20301704\n",
      "nonwhites string 0.026322449\n",
      "nonwhites tension 0.15329002\n",
      "nonwhites neck 0.08223437\n",
      "nonwhites bridge 0.06096026\n",
      "nonwhites pickups 0.11653416\n",
      "nonwhites features 0.08477588\n",
      "nonwhites found 0.14959686\n",
      "relatively nut 0.09461162\n",
      "relatively player 0.041816834\n",
      "relatively turns 0.16734552\n",
      "relatively change 0.20078367\n",
      "relatively string 0.16654162\n",
      "relatively tension 0.16316111\n",
      "relatively neck 0.19683596\n",
      "relatively bridge 0.14137147\n",
      "relatively pickups 0.07920047\n",
      "relatively features 0.23933949\n",
      "relatively found 0.34488636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12569543208005002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgsim(data[0][0],data[0][1],data[0][2],data[0][3],w2v_model,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsim(data[0][0],data[0][1],data[0][2],data[0][3],spx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsim(data[0][0],data[0][1],data[0][2],data[0][3],spxEM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in model.vocab:\n",
    "    if '#' in w:\n",
    "        print(w)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wiki as w\n",
    "import sys\n",
    "sys.path.append(\"../../imports/\")\n",
    "import saver as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sv.load(\"wiki_sentences_spx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentences:\n",
    "    print(sent[:105])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0][0])\n",
    "print(sent_words(data[0][2]))\n",
    "print(data[0][1])\n",
    "print(sent_words(data[0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spxEM_model.similarity('brazil','nut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spxEM_model.similarity('brazil#E','nut#E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.similarity('brazil','nut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_words(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-context similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws353A = '/home/manni/data/wordsim/EN-WS353.txt'\n",
    "ws353R = '/home/manni/data/wordsim/EN-WSR353.txt'\n",
    "ws353S = '/home/manni/data/wordsim/EN-WSS353.txt'\n",
    "rw = '/home/manni/data/wordsim/rw.txt'\n",
    "sim999 = '/home/manni/data/wordsim/EN-SIM999.txt'\n",
    "turk = '/home/manni/data/wordsim/EN_TRUK.txt'\n",
    "mturk = '/home/manni/data/wordsim/MTURK-771.csv'\n",
    "rg = '/home/manni/data/wordsim/EN-RG-65.txt'\n",
    "men = '/home/manni/data/wordsim/EN-MEN-LEM.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sim999) as fin:\n",
    "    lines = fin.readlines()\n",
    "    with open(sim999+'_new','w') as fout:\n",
    "        for line in lines:\n",
    "            line = line.split('\\t')\n",
    "            try:\n",
    "                float(line[3])\n",
    "                fout.write(\"{} {} {} \\n\".format(line[0],line[1],line[3])) \n",
    "            except:\n",
    "                continue   \n",
    "sim999 = sim999+'_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mturk) as fin:\n",
    "    lines = fin.readlines()\n",
    "    with open(mturk+'_new','w') as fout:\n",
    "        for line in lines:\n",
    "            line = line.split(',')\n",
    "            try:\n",
    "                fout.write(\"{} {} {} \\n\".format(line[0],line[1],line[2])) \n",
    "            except:\n",
    "                continue   \n",
    "mturk = mturk+'_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(men) as fin:\n",
    "    lines = fin.readlines()\n",
    "    with open(men+'_new','w') as fout:\n",
    "        for line in lines:\n",
    "            line = line.split()\n",
    "            try:\n",
    "                fout.write(\"{} {} {} \\n\".format(line[0].split('-')[0],line[1].split('-')[0],line[2])) \n",
    "            except:\n",
    "                continue   \n",
    "men = men+'_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "with open(mturk) as fin:\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line= line.split()\n",
    "        print(line)\n",
    "        continue\n",
    "        try:\n",
    "            if line[0] in model.vocab and line[1] in model.vocab:\n",
    "                continue\n",
    "        except:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [ws353A,ws353R,ws353S,rw,sim999,turk,mturk,rg,men]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sim(w1,w2,model):\n",
    "    s1 = [w1,w1+'#E']\n",
    "    s2 = [w2,w2+'#E']\n",
    "    a = [w for w in s1 if w in model.vocab]\n",
    "    b = [w for w in s2 if w in model.vocab]\n",
    "    div = len(a)*len(b)\n",
    "    sims = 0\n",
    "    for i in a:\n",
    "        for j in b:\n",
    "            sims+=model.similarity(i,j)\n",
    "    return sims/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ds in datasets:\n",
    "    name = ds.split('/')[-1].split('.')[0]\n",
    "    print(r'\\begin{subsection}{'+name+r'}')\n",
    "    print(r'\\begin{table}[!h]')\n",
    "    print(r'\\begin{tabular}{|l|c|c|}')\n",
    "    print('\\hline')\n",
    "    print(\"Model & Pearsons & Spearmans\"+r\"\\\\\")\n",
    "    print('\\hline')\n",
    "    with open(ds) as fin:\n",
    "        lines = fin.readlines()\n",
    "        for i, model in enumerate(models):\n",
    "            print(model_names[i],end=' & ')\n",
    "            sims = list()\n",
    "            scores = list()\n",
    "            for line in lines:\n",
    "                line = line.split()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if line[0] in model.vocab and line[1] in model.vocab:\n",
    "                    sim = avg_sim(line[0],line[1],model) \n",
    "                else:\n",
    "                    continue\n",
    "                if sim:\n",
    "                    score = float(line[2])\n",
    "                    sims.append(sim)\n",
    "                    scores.append(score)\n",
    "            corr, _ = pearsonr(sims, scores)\n",
    "            print('%.2f' % (corr*100),end=' & ')\n",
    "            corr, _ = spearmanr(sims, scores)\n",
    "            print('%.2f' % (corr*100),end=r'\\\\') \n",
    "            print()\n",
    "    print('\\hline')\n",
    "    print('\\end{tabular}')\n",
    "    print('\\end{table}')\n",
    "    print(r'\\end{subsection}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
