{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8d5c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T02:49:47.220484Z",
     "start_time": "2022-10-27T02:49:46.776464Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import sys\n",
    "sys.path.append(\"../../imports/\")\n",
    "import saver as sv\n",
    "import numpy as np\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "word2desc = sv.load(\"word2desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eab6cb55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T02:49:49.232733Z",
     "start_time": "2022-10-27T02:49:49.230118Z"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0ff4a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T02:50:06.998622Z",
     "start_time": "2022-10-27T02:49:52.495307Z"
    }
   },
   "outputs": [],
   "source": [
    "#w2v = '/home/manni/embs/word2vec-google-news-300.gz'\n",
    "#timeit model = KeyedVectors.load_word2vec_format(w2v, binary=True)\n",
    "model = KeyedVectors.load('/home/manni/embs/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd5a39f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T10:33:51.326177Z",
     "start_time": "2022-10-27T10:33:51.319259Z"
    }
   },
   "outputs": [],
   "source": [
    "def sense_vec(word,model,max_numsenses,pad):\n",
    "    '''\n",
    "    Computes average vectors from all sense descriptions. \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        Unicode or utf-8 encoded string.\n",
    "    model : KeyedVectors\n",
    "        gensim KeyedVectors object\n",
    "    max_numsenses: int \n",
    "        maximum number of sense\n",
    "    pad : 2D numpy array\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of [Vector,Vector,....].\n",
    "    '''\n",
    "    dim = model.vector_size\n",
    "    v = list()\n",
    "    if word not in word2desc:\n",
    "        return pad\n",
    "    for words in word2desc[word]:\n",
    "        if not words:\n",
    "            continue\n",
    "        _v = list()\n",
    "        for _word in words:\n",
    "            if _word in model.vocab:\n",
    "                _v.append(model.get_vector(_word))\n",
    "        if not _v:\n",
    "            _v = pad[0]\n",
    "        else:\n",
    "            _v = np.sum(_v,axis=0)\n",
    "        v.append(_v)\n",
    "    if len(v)<1:\n",
    "        return pad\n",
    "    v = np.append(v,pad,axis=0)[:max_numsenses]\n",
    "    assert np.asarray(v).ndim == 2, 'SenseVec is not 2D, instead:'+str(v.shape)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68309ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T10:35:07.750202Z",
     "start_time": "2022-10-27T10:33:51.852963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the data\n",
      "Saved the data\n",
      "Saved the data\n"
     ]
    }
   ],
   "source": [
    "#save to numpy array\n",
    "max_numsenses = 0\n",
    "#compute maximum number of senses for padding\n",
    "for word,data in word2desc.items():\n",
    "    if len(data)>max_numsenses:\n",
    "        max_numsenses = len(data)\n",
    "sensevecs = np.zeros((len(word2desc),max_numsenses,model.vector_size),dtype=np.float32)\n",
    "pad = np.zeros((max_numsenses, model.vector_size),dtype=np.float32)\n",
    "for i,word in enumerate(word2desc):\n",
    "    v = sense_vec(word,model,max_numsenses,pad)\n",
    "    sensevecs[i]=v\n",
    "sensevecs_dict = dict()   \n",
    "for i,word in enumerate(word2desc.keys()):\n",
    "    sensevecs_dict[word]=i\n",
    "sv.save(sensevecs_dict,\"sensevecs_dict\")\n",
    "sv.save(sensevecs,\"sensevecs\")\n",
    "sv.save(max_numsenses,'max_numsenses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc1e758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T10:35:07.755878Z",
     "start_time": "2022-10-27T10:35:07.752855Z"
    }
   },
   "outputs": [],
   "source": [
    "WINDOW = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a1596",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## no jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8c325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T09:36:43.989942Z",
     "start_time": "2022-10-26T09:36:43.982042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tokenize(tokens,WINDOW,model):\n",
    "    to_replace = dict()\n",
    "    for i,token in enumerate(tokens):\n",
    "        if token in word2desc:\n",
    "            left = tokens[i-WINDOW:i]\n",
    "            right = tokens[i+1:i+WINDOW+1]\n",
    "            context = set(left+right)\n",
    "            tsvecs = sense_vec(token,model)\n",
    "            maxi = 0\n",
    "            tag = -1 #index in wordsense\n",
    "            for si,v in enumerate(tsvecs):\n",
    "                for con in context:\n",
    "                    if con == token:\n",
    "                        continue\n",
    "                    _svecs = sense_vec(con,model)\n",
    "                    for sj,_v in enumerate(_svecs):\n",
    "                        if np.sum(_v)==0:\n",
    "                            continue\n",
    "                        sim = model.cosine_similarities(v, [_v])[0]\n",
    "                        if sim>maxi:\n",
    "                            maxi = sim\n",
    "                            tag = si\n",
    "            if tag>=0:\n",
    "                to_replace[i]=token+'#'+str(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2414597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-25T06:20:48.505805Z",
     "start_time": "2022-10-25T06:20:48.503487Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokens = 'part river where current very fast forward'\n",
    "tokens = tokens.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d283f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-25T06:21:00.660019Z",
     "start_time": "2022-10-25T06:20:51.145211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit tokenize(tokens,3,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc1f4f",
   "metadata": {},
   "source": [
    "## numba version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d491691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T10:35:07.775550Z",
     "start_time": "2022-10-27T10:35:07.757218Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vecs(tokens,WINDOW,model,max_numsenses,pad):\n",
    "    token_vecs = np.ascontiguousarray(np.zeros((len(tokens),max_numsenses,model.vector_size),dtype=np.float32))\n",
    "    token_con_vecs = np.ascontiguousarray(np.zeros((len(tokens),WINDOW*2,max_numsenses,model.vector_size),dtype=np.float32))\n",
    "    for i,token in enumerate(tokens):\n",
    "        if token in word2desc and token in sensevecs_dict:\n",
    "            left = tokens[i-WINDOW:i]\n",
    "            right = tokens[i+1:i+WINDOW+1]\n",
    "            context = set(left+right)\n",
    "            context = [con for con in context if con in sensevecs_dict]\n",
    "            tsvecs = sensevecs[sensevecs_dict[token]]\n",
    "            #tsvecs = sense_vec(token,model,max_numsenses,pad)\n",
    "            token_vecs[i]=tsvecs\n",
    "            for j,con in enumerate(context):\n",
    "                csvecs = sensevecs[sensevecs_dict[con]] # sense vectors for current context\n",
    "                #csvecs = sense_vec(con,model,max_numsenses,pad)\n",
    "                token_con_vecs[i][j]=csvecs\n",
    "    return np.ascontiguousarray(token_vecs),np.ascontiguousarray(token_con_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5cb321af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T07:21:31.987959Z",
     "start_time": "2022-10-27T07:21:31.981887Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "tokens = [token for token in tokens if token not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "16d7ae53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T09:51:50.310369Z",
     "start_time": "2022-10-27T09:51:49.888084Z"
    }
   },
   "outputs": [],
   "source": [
    "tv,tcv =  get_vecs(tokens,WINDOW,model,max_numsenses,pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b20b50d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T09:51:51.945776Z",
     "start_time": "2022-10-27T09:51:51.941508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 88, 300)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8bcdce29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T09:51:52.225124Z",
     "start_time": "2022-10-27T09:51:52.221473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 6, 88, 300)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f43235b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T10:21:11.009783Z",
     "start_time": "2022-10-27T10:21:10.999453Z"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def get_tags(token_vecs,token_con_vecs):\n",
    "    #token_vecs,token_con_vecs = get_vecs(tokens,WINDOW,model)\n",
    "    to_replace = np.full((token_vecs.shape[0]), -1)\n",
    "    for i in range(token_vecs.shape[0]):\n",
    "        maxi = 0\n",
    "        tag = -1 #index in wordsense\n",
    "        tvecs = token_vecs[i] #current token sense vecs\n",
    "        # vecs for all context words for the current token\n",
    "        for wvecs in token_con_vecs[i]:\n",
    "            # current context word sense vecs\n",
    "            for vec in wvecs:\n",
    "                if np.sum(vec)==0:\n",
    "                    break\n",
    "                for j,tvec in enumerate(tvecs):\n",
    "                    if np.sum(tvec)==0:\n",
    "                        break\n",
    "                    norm = np.linalg.norm(tvec) * np.linalg.norm(vec)\n",
    "                    sim = np.dot(tvec,vec)/ norm\n",
    "                    if sim>maxi:\n",
    "                        maxi = sim\n",
    "                        tag = j \n",
    "        to_replace[i]=tag\n",
    "    return to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "71dfcc3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T10:21:15.407595Z",
     "start_time": "2022-10-27T10:21:15.404265Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenise(tokens,WINDOW,model):\n",
    "    token_vecs,token_con_vecs = get_vecs(tokens,WINDOW,model,max_numsenses,pad)\n",
    "    to_replace = get_tags(token_vecs,token_con_vecs)\n",
    "    return to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bcdfd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-27T10:21:15.366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46642/3488280532.py:19: NumbaPerformanceWarning: np.dot() is faster on contiguous arrays, called on (array(float32, 1d, A), array(float32, 1d, A))\n",
      "  sim = np.dot(tvec,vec)/ norm\n"
     ]
    }
   ],
   "source": [
    "%timeit to_replace = tokenise(tokens,3,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72f461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-25T06:51:16.799435Z",
     "start_time": "2022-10-25T06:51:16.795436Z"
    }
   },
   "outputs": [],
   "source": [
    "to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(to_replace):\n",
    "    if v !=-1:\n",
    "        tokens[i]+='#'+str(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c78eee",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c211da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T07:27:14.566005Z",
     "start_time": "2022-10-23T07:27:14.561754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_shape(seq):\n",
    "    try:\n",
    "        len_ = len(seq)\n",
    "    except TypeError:\n",
    "        return ()\n",
    "    shapes = [find_shape(subseq) for subseq in seq]\n",
    "    return (len_,) + tuple(max(sizes) for sizes in itertools.zip_longest(*shapes, fillvalue=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512d1f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T08:11:44.443072Z",
     "start_time": "2022-10-24T08:11:44.426908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def traversal(a):\n",
    "    '''\n",
    "    parameter:\n",
    "    ---------\n",
    "    a: a multidimentional list\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    list\n",
    "    \n",
    "    a single dimention list containing \n",
    "    dimentions of the provided list without \n",
    "    the first dimention.\n",
    "    '''\n",
    "    m = 0\n",
    "    level = list()\n",
    "    for i,branch in enumerate(a):\n",
    "        #print(branch)\n",
    "        try:\n",
    "            #_m = get_max(branch)\n",
    "            _m = len(branch)\n",
    "            if _m > m:\n",
    "                m = _m\n",
    "            for _branch in branch:\n",
    "                level.append(_branch)\n",
    "        except:\n",
    "            return []\n",
    "    return [m]+traversal(level)\n",
    "\n",
    "def get_dims(a):\n",
    "    '''\n",
    "    parameter:\n",
    "    ---------\n",
    "    a: a multidimentional list\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    _d: (list)\n",
    "    \n",
    "    a single dimention list containing \n",
    "    dimentions of the provided list.\n",
    "    '''\n",
    "    _d = traversal(a)\n",
    "    _d = [len(a)]+_d\n",
    "    return _d\n",
    "\n",
    "def get_padded(a):\n",
    "    '''\n",
    "    Pads a multidimentional list with constant.\n",
    "    **Note: asssumes the last dimention symmetric. \n",
    "    parameter:\n",
    "    ---------\n",
    "    a: a multidimentional list\n",
    "    constant: a constant number provided\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    a single dimention list containing \n",
    "    dimentions of the provided list.\n",
    "    '''\n",
    "    dims = get_dims(a)\n",
    "    depth = 0 #need global depth counter\n",
    "    def padder(a,prev_depth=0,dat=list(),data=list(),deff=1,total=0):\n",
    "        #global depth\n",
    "        for i,branch in enumerate(a):\n",
    "            if type(branch)==list:\n",
    "                total=len(a)\n",
    "                get_padded.depth+=1\n",
    "                print('i:',i)\n",
    "                print('depth:',get_padded.depth)\n",
    "                print('branch:',branch)\n",
    "                if deff>1 and get_padded.depth!=prev_depth:\n",
    "                    deff*=dims[get_padded.depth]\n",
    "                    print('deff_a:',deff)\n",
    "                if len(branch)<dims[get_padded.depth]:\n",
    "                    deff*=dims[get_padded.depth]\n",
    "                    print('deff_b:',deff)\n",
    "                print('prev_depth',prev_depth)\n",
    "                prev_depth = get_padded.depth\n",
    "                padder(branch,prev_depth,dat,data,deff,total) #### \n",
    "            else:\n",
    "                #leaf\n",
    "                print('leaf:',branch)\n",
    "                dat.append(branch) \n",
    "        else:\n",
    "            get_padded.depth-=1\n",
    "            print('inf dep:',get_padded.depth)\n",
    "            print('dat:',dat)\n",
    "            if not dat:\n",
    "                print('inf dep ret:',get_padded.depth)\n",
    "                print('-----')\n",
    "                return\n",
    "            if i == total-1:\n",
    "                data.extend(dat+[0]*(deff-len(dat)))\n",
    "                print('data:',data)\n",
    "                dat = []\n",
    "                deff = 1\n",
    "                print('-----')\n",
    "    padder(a)\n",
    "    return np.reshape(data,dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fffe04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T12:49:42.491773Z",
     "start_time": "2022-10-23T12:49:42.485900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = [\n",
    "    [[[1, 2, 3]],[[1, 2, 3], [4, 5, 6]]],\n",
    "    [[[1, 2, 3], [4, 5, 6]]]\n",
    "    ]\n",
    "_a = [1, 2, 3, 0, 0, 0, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 0, 0, 0, 0, 0, 0]\n",
    "np.reshape(_a,(2,2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6417e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(tokens[0])\n",
    "tv,tcv = get_vecs(tokens,3,model)\n",
    "tv = np.asarray(tv)\n",
    "print(tv.shape)\n",
    "'''\n",
    "\n",
    "a = [\n",
    "    [[[1, 2, 3]],[[1, 2, 3], [4, 5, 6]]],\n",
    "    [[[1, 2, 3], [4, 5, 6]]]\n",
    "    ]\n",
    "\n",
    "dims = [2,2,2,3]\n",
    "#dims = [d*dims[i-1] for i,d in enumerate(dims) if i>0]\n",
    "\n",
    "out = list()\n",
    "tlen = 1\n",
    "dat = list()\n",
    "data = list()\n",
    "\n",
    "depth = 0\n",
    "prev_depth = 0\n",
    "\n",
    "def padder(a):\n",
    "    global tlen\n",
    "    global out\n",
    "    global depth\n",
    "    global prev_depth\n",
    "    global data\n",
    "    global dat\n",
    "    for i,branch in enumerate(a):\n",
    "        if type(branch)==list:\n",
    "            depth+=1\n",
    "            print('i:',i)\n",
    "            print('depth:',depth)\n",
    "            print('prev_depth:',prev_depth)\n",
    "            if depth<prev_depth:\n",
    "                tlen=dims[depth]\n",
    "                print('tlen:',tlen)\n",
    "            print('branch:',branch)\n",
    "            # check if same level\n",
    "            if prev_depth < depth:\n",
    "                tlen*=dims[depth]\n",
    "                print('tlen:',tlen)\n",
    "            prev_depth = depth\n",
    "            padder(branch)\n",
    "        else:\n",
    "            #leaf\n",
    "            dat.append(branch)\n",
    "    print('dat:',dat)\n",
    "    depth-=1\n",
    "    print('reduced depth:',depth)\n",
    "    if depth == 0:\n",
    "        data.append(dat+[0]*(12-len(dat)))\n",
    "        print(data)\n",
    "        dat = []\n",
    "    print('-----')\n",
    "padder(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
