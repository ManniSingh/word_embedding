{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8d5c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:22:12.418865Z",
     "start_time": "2022-10-26T12:22:11.164635Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import sys\n",
    "sys.path.append(\"../../imports/\")\n",
    "import saver as sv\n",
    "import numpy as np\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "word2desc = sv.load(\"word2desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab6cb55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:22:12.978993Z",
     "start_time": "2022-10-26T12:22:12.420536Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manni/.local/lib/python3.8/site-packages/numba/core/errors.py:175: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ff4a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:22:24.512048Z",
     "start_time": "2022-10-26T12:22:12.980565Z"
    }
   },
   "outputs": [],
   "source": [
    "#w2v = '/home/manni/embs/word2vec-google-news-300.gz'\n",
    "#timeit model = KeyedVectors.load_word2vec_format(w2v, binary=True)\n",
    "model = KeyedVectors.load('/home/manni/embs/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc1e758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:22:24.516780Z",
     "start_time": "2022-10-26T12:22:24.514256Z"
    }
   },
   "outputs": [],
   "source": [
    "WINDOW = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e44277d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:22:24.683925Z",
     "start_time": "2022-10-26T12:22:24.518225Z"
    }
   },
   "outputs": [],
   "source": [
    "def sense_vec(word,model):\n",
    "    '''\n",
    "    Computes average vectors from all sense descriptions. \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        Unicode or utf-8 encoded string.\n",
    "    model : KeyedVectors\n",
    "        gensim KeyedVectors object\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of [Vector,Vector,....].\n",
    "    '''\n",
    "    dim = model.vector_size\n",
    "    v = list()\n",
    "    pad = np.zeros((1, model.vector_size),dtype=np.float32)\n",
    "    if word not in word2desc:\n",
    "        return pad\n",
    "    for words in word2desc[word]:\n",
    "        if not words:\n",
    "            continue\n",
    "        _v = list()\n",
    "        for _word in words:\n",
    "            if _word in model.vocab:\n",
    "                _v.append(model.get_vector(_word))\n",
    "        if not _v:\n",
    "            _v = pad\n",
    "        _v = np.sum(_v,axis=0)\n",
    "        v.append(_v)\n",
    "    if len(v)<1:\n",
    "        return pad\n",
    "    assert np.asarray(v).ndim == 2, 'SenseVec is not 2D.'\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8c325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T09:36:43.989942Z",
     "start_time": "2022-10-26T09:36:43.982042Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(tokens,WINDOW,model):\n",
    "    to_replace = dict()\n",
    "    for i,token in enumerate(tokens):\n",
    "        if token in word2desc:\n",
    "            left = tokens[i-WINDOW:i]\n",
    "            right = tokens[i+1:i+WINDOW+1]\n",
    "            context = set(left+right)\n",
    "            tsvecs = sense_vec(token,model)\n",
    "            maxi = 0\n",
    "            tag = -1 #index in wordsense\n",
    "            for si,v in enumerate(tsvecs):\n",
    "                for con in context:\n",
    "                    if con == token:\n",
    "                        continue\n",
    "                    _svecs = sense_vec(con,model)\n",
    "                    for sj,_v in enumerate(_svecs):\n",
    "                        if np.sum(_v)==0:\n",
    "                            continue\n",
    "                        sim = model.cosine_similarities(v, [_v])[0]\n",
    "                        if sim>maxi:\n",
    "                            maxi = sim\n",
    "                            tag = si\n",
    "            if tag>=0:\n",
    "                to_replace[i]=token+'#'+str(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2414597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-25T06:20:48.505805Z",
     "start_time": "2022-10-25T06:20:48.503487Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = 'part river where current very fast forward'\n",
    "tokens = tokens.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d283f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-25T06:21:00.660019Z",
     "start_time": "2022-10-25T06:20:51.145211Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit tokenize(tokens,3,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959d649",
   "metadata": {},
   "source": [
    "## numba version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f118eea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:22:24.696083Z",
     "start_time": "2022-10-26T12:22:24.685652Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_max(tokens,WINDOW,model):\n",
    "    tmax = 0\n",
    "    for i,token in enumerate(tokens):\n",
    "        if token in word2desc:\n",
    "            tsvecs = sense_vec(token,model) # sense vectors for current token\n",
    "            _tmax=len(tsvecs)\n",
    "            if _tmax>tmax:\n",
    "                tmax=_tmax\n",
    "    return tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d491691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:23:22.988696Z",
     "start_time": "2022-10-26T12:23:22.976059Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vecs(tokens,WINDOW,model):\n",
    "    tmax = get_max(tokens,WINDOW,model)\n",
    "    pad = np.zeros((model.vector_size),dtype=np.float32)\n",
    "    token_vecs = list()\n",
    "    token_con_vecs = list()\n",
    "    for i,token in enumerate(tokens):\n",
    "        if token in word2desc:\n",
    "            left = tokens[i-WINDOW:i]\n",
    "            right = tokens[i+1:i+WINDOW+1]\n",
    "            context = set(left+right)\n",
    "            tsvecs = sense_vec(token,model) # sense vectors for current token\n",
    "            tsvecs = tsvecs + [pad]*(tmax-len(tsvecs)) \n",
    "            csvecs = list()\n",
    "            for j,con in enumerate(context):\n",
    "                if con == token:\n",
    "                    _csvecs = [pad]*tmax\n",
    "                    continue\n",
    "                _csvecs = sense_vec(con,model) # sense vectors for current context\n",
    "                _csvecs = np.asarray(_csvecs)\n",
    "                adder = np.asarray([pad]*(tmax-len(_csvecs)))\n",
    "                if len(adder)>0:\n",
    "                    _csvecs = np.concatenate((_csvecs, adder), axis=0)\n",
    "                csvecs.append(_csvecs)  \n",
    "        else:\n",
    "            tsvecs = [pad]*tmax\n",
    "            csvecs = [[pad]*tmax]*(WINDOW*2)\n",
    "        csvecs = csvecs + [[pad]*tmax]*((WINDOW*2)-len(csvecs)) \n",
    "        assert len(csvecs)==WINDOW*2\n",
    "        token_vecs.append(tsvecs)\n",
    "        token_con_vecs.append(csvecs)\n",
    "    assert np.asarray(token_vecs).ndim == 3, 'token_vecs is not 3D, with shape:'\\\n",
    "    +str(np.asarray(token_vecs).shape)+':'+str(tokens)\n",
    "    return np.asarray(token_vecs),np.asarray(token_con_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d7ae53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:23:39.693398Z",
     "start_time": "2022-10-26T12:23:35.624940Z"
    }
   },
   "outputs": [],
   "source": [
    "tv,tcv =  get_vecs(tokens,WINDOW,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62c5867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:23:02.316818Z",
     "start_time": "2022-10-26T12:23:02.304377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa8eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:09:09.992549Z",
     "start_time": "2022-10-26T12:09:09.988699Z"
    }
   },
   "outputs": [],
   "source": [
    "np.asarray(tv[957]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52725a9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:04:51.203802Z",
     "start_time": "2022-10-26T12:04:51.200337Z"
    }
   },
   "outputs": [],
   "source": [
    "len(tv[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b20b50d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:23:07.610224Z",
     "start_time": "2022-10-26T12:23:07.493970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697, 60, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(tv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71dd596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T12:06:19.240723Z",
     "start_time": "2022-10-26T12:06:18.927236Z"
    }
   },
   "outputs": [],
   "source": [
    "for i,d in enumerate(tv):\n",
    "    print(i)\n",
    "    assert np.asarray(d).shape[0]==60,np.asarray(d).shape[0]\n",
    "    assert np.asarray(d).shape[1]==300\n",
    "    if np.asarray(d).ndim!=2:\n",
    "        print(np.asarray(d).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43235b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:08:26.750894Z",
     "start_time": "2022-10-26T10:08:26.744219Z"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def get_tags(token_vecs,token_con_vecs):\n",
    "    #token_vecs,token_con_vecs = get_vecs(tokens,WINDOW,model)\n",
    "    to_replace = np.full((token_vecs.shape[0]), -1)\n",
    "    for i in range(token_vecs.shape[0]):\n",
    "        maxi = 0\n",
    "        tag = -1 #index in wordsense\n",
    "        tvecs = token_vecs[i] #current token sense vecs\n",
    "        # vecs for all context words for the current token\n",
    "        for wvecs in token_con_vecs[i]:\n",
    "            # current context word sense vecs\n",
    "            for vec in wvecs:\n",
    "                if np.sum(vec)==0:\n",
    "                    break\n",
    "                for j,tvec in enumerate(tvecs):\n",
    "                    if np.sum(tvec)==0:\n",
    "                        break\n",
    "                    norm = np.linalg.norm(tvec) * np.linalg.norm(vec)\n",
    "                    sim = np.dot(tvec,vec)/ norm\n",
    "                    if sim>maxi:\n",
    "                        maxi = sim\n",
    "                        tag = j \n",
    "        to_replace[i]=tag\n",
    "    return to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfcc3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:08:27.853922Z",
     "start_time": "2022-10-26T10:08:27.851037Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenise(tokens,WINDOW,model):\n",
    "    token_vecs,token_con_vecs = get_vecs(tokens,WINDOW,model)\n",
    "    to_replace = get_tags(token_vecs,token_con_vecs)\n",
    "    return to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bcdfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T10:18:52.126701Z",
     "start_time": "2022-10-26T10:15:13.595067Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit to_replace = tokenise(tokens,3,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72f461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-25T06:51:16.799435Z",
     "start_time": "2022-10-25T06:51:16.795436Z"
    }
   },
   "outputs": [],
   "source": [
    "to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(to_replace):\n",
    "    if v !=-1:\n",
    "        tokens[i]+='#'+str(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c78eee",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c211da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T07:27:14.566005Z",
     "start_time": "2022-10-23T07:27:14.561754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_shape(seq):\n",
    "    try:\n",
    "        len_ = len(seq)\n",
    "    except TypeError:\n",
    "        return ()\n",
    "    shapes = [find_shape(subseq) for subseq in seq]\n",
    "    return (len_,) + tuple(max(sizes) for sizes in itertools.zip_longest(*shapes, fillvalue=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512d1f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T08:11:44.443072Z",
     "start_time": "2022-10-24T08:11:44.426908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def traversal(a):\n",
    "    '''\n",
    "    parameter:\n",
    "    ---------\n",
    "    a: a multidimentional list\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    list\n",
    "    \n",
    "    a single dimention list containing \n",
    "    dimentions of the provided list without \n",
    "    the first dimention.\n",
    "    '''\n",
    "    m = 0\n",
    "    level = list()\n",
    "    for i,branch in enumerate(a):\n",
    "        #print(branch)\n",
    "        try:\n",
    "            #_m = get_max(branch)\n",
    "            _m = len(branch)\n",
    "            if _m > m:\n",
    "                m = _m\n",
    "            for _branch in branch:\n",
    "                level.append(_branch)\n",
    "        except:\n",
    "            return []\n",
    "    return [m]+traversal(level)\n",
    "\n",
    "def get_dims(a):\n",
    "    '''\n",
    "    parameter:\n",
    "    ---------\n",
    "    a: a multidimentional list\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    _d: (list)\n",
    "    \n",
    "    a single dimention list containing \n",
    "    dimentions of the provided list.\n",
    "    '''\n",
    "    _d = traversal(a)\n",
    "    _d = [len(a)]+_d\n",
    "    return _d\n",
    "\n",
    "def get_padded(a):\n",
    "    '''\n",
    "    Pads a multidimentional list with constant.\n",
    "    **Note: asssumes the last dimention symmetric. \n",
    "    parameter:\n",
    "    ---------\n",
    "    a: a multidimentional list\n",
    "    constant: a constant number provided\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    a single dimention list containing \n",
    "    dimentions of the provided list.\n",
    "    '''\n",
    "    dims = get_dims(a)\n",
    "    depth = 0 #need global depth counter\n",
    "    def padder(a,prev_depth=0,dat=list(),data=list(),deff=1,total=0):\n",
    "        #global depth\n",
    "        for i,branch in enumerate(a):\n",
    "            if type(branch)==list:\n",
    "                total=len(a)\n",
    "                get_padded.depth+=1\n",
    "                print('i:',i)\n",
    "                print('depth:',get_padded.depth)\n",
    "                print('branch:',branch)\n",
    "                if deff>1 and get_padded.depth!=prev_depth:\n",
    "                    deff*=dims[get_padded.depth]\n",
    "                    print('deff_a:',deff)\n",
    "                if len(branch)<dims[get_padded.depth]:\n",
    "                    deff*=dims[get_padded.depth]\n",
    "                    print('deff_b:',deff)\n",
    "                print('prev_depth',prev_depth)\n",
    "                prev_depth = get_padded.depth\n",
    "                padder(branch,prev_depth,dat,data,deff,total) #### \n",
    "            else:\n",
    "                #leaf\n",
    "                print('leaf:',branch)\n",
    "                dat.append(branch) \n",
    "        else:\n",
    "            get_padded.depth-=1\n",
    "            print('inf dep:',get_padded.depth)\n",
    "            print('dat:',dat)\n",
    "            if not dat:\n",
    "                print('inf dep ret:',get_padded.depth)\n",
    "                print('-----')\n",
    "                return\n",
    "            if i == total-1:\n",
    "                data.extend(dat+[0]*(deff-len(dat)))\n",
    "                print('data:',data)\n",
    "                dat = []\n",
    "                deff = 1\n",
    "                print('-----')\n",
    "    padder(a)\n",
    "    return np.reshape(data,dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fffe04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T12:49:42.491773Z",
     "start_time": "2022-10-23T12:49:42.485900Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = [\n",
    "    [[[1, 2, 3]],[[1, 2, 3], [4, 5, 6]]],\n",
    "    [[[1, 2, 3], [4, 5, 6]]]\n",
    "    ]\n",
    "_a = [1, 2, 3, 0, 0, 0, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 0, 0, 0, 0, 0, 0]\n",
    "np.reshape(_a,(2,2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6417e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(tokens[0])\n",
    "tv,tcv = get_vecs(tokens,3,model)\n",
    "tv = np.asarray(tv)\n",
    "print(tv.shape)\n",
    "'''\n",
    "\n",
    "a = [\n",
    "    [[[1, 2, 3]],[[1, 2, 3], [4, 5, 6]]],\n",
    "    [[[1, 2, 3], [4, 5, 6]]]\n",
    "    ]\n",
    "\n",
    "dims = [2,2,2,3]\n",
    "#dims = [d*dims[i-1] for i,d in enumerate(dims) if i>0]\n",
    "\n",
    "out = list()\n",
    "tlen = 1\n",
    "dat = list()\n",
    "data = list()\n",
    "\n",
    "depth = 0\n",
    "prev_depth = 0\n",
    "\n",
    "def padder(a):\n",
    "    global tlen\n",
    "    global out\n",
    "    global depth\n",
    "    global prev_depth\n",
    "    global data\n",
    "    global dat\n",
    "    for i,branch in enumerate(a):\n",
    "        if type(branch)==list:\n",
    "            depth+=1\n",
    "            print('i:',i)\n",
    "            print('depth:',depth)\n",
    "            print('prev_depth:',prev_depth)\n",
    "            if depth<prev_depth:\n",
    "                tlen=dims[depth]\n",
    "                print('tlen:',tlen)\n",
    "            print('branch:',branch)\n",
    "            # check if same level\n",
    "            if prev_depth < depth:\n",
    "                tlen*=dims[depth]\n",
    "                print('tlen:',tlen)\n",
    "            prev_depth = depth\n",
    "            padder(branch)\n",
    "        else:\n",
    "            #leaf\n",
    "            dat.append(branch)\n",
    "    print('dat:',dat)\n",
    "    depth-=1\n",
    "    print('reduced depth:',depth)\n",
    "    if depth == 0:\n",
    "        data.append(dat+[0]*(12-len(dat)))\n",
    "        print(data)\n",
    "        dat = []\n",
    "    print('-----')\n",
    "padder(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
